This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.claude/settings.local.json
.gitignore
.repomix.code.json
.repomix.json
backend/.env.example
backend/data/repositories.db
backend/database/index.js
backend/database/schema.sql
backend/package.json
backend/routes/collections.js
backend/routes/repositories.js
backend/seed.js
backend/server.js
backend/services/git-sync.js
backend/services/privacy-service.js
backend/services/repository-service.js
contracts/FinallicaGovernance.sol
contracts/FinallicaPrivacyRouter.sol
contracts/hardhat.config.js
contracts/package.json
docs/finallica/.git/COMMIT_EDITMSG
docs/finallica/.git/config
docs/finallica/.git/description
docs/finallica/.git/HEAD
docs/finallica/.git/hooks/applypatch-msg.sample
docs/finallica/.git/hooks/commit-msg.sample
docs/finallica/.git/hooks/fsmonitor-watchman.sample
docs/finallica/.git/hooks/post-update.sample
docs/finallica/.git/hooks/pre-applypatch.sample
docs/finallica/.git/hooks/pre-commit.sample
docs/finallica/.git/hooks/pre-merge-commit.sample
docs/finallica/.git/hooks/pre-push.sample
docs/finallica/.git/hooks/pre-rebase.sample
docs/finallica/.git/hooks/pre-receive.sample
docs/finallica/.git/hooks/prepare-commit-msg.sample
docs/finallica/.git/hooks/push-to-checkout.sample
docs/finallica/.git/hooks/sendemail-validate.sample
docs/finallica/.git/hooks/update.sample
docs/finallica/.git/index
docs/finallica/.git/info/exclude
docs/finallica/.git/logs/HEAD
docs/finallica/.git/logs/refs/heads/master
docs/finallica/.git/objects/06/77ebeb87f0ed26dd54812e94d53c91344538f9
docs/finallica/.git/objects/09/6f09dbac0d45a861fb51e2da560e14924d4b04
docs/finallica/.git/objects/09/e379aa58a5ec69e1f9cc817333d70c141c3261
docs/finallica/.git/objects/0a/412e6416d8d5483b94743e8b1deed89b2ccc84
docs/finallica/.git/objects/1e/6f0692f43086bedb16619e67bf2bcacc0d2101
docs/finallica/.git/objects/32/e0cab6aa50bfc2f694f1da6555990641af525c
docs/finallica/.git/objects/3c/2361557fdc2e2a3ecf671cbb5fb44413ec1f75
docs/finallica/.git/objects/45/7410b558d6a33b35c1fe04c6c7e54fd7c8b6bb
docs/finallica/.git/objects/58/c82cb7a6bc5442333750c2d249b63d5f939693
docs/finallica/.git/objects/62/9fbdec2051e9011766a5963964549b2aa70e55
docs/finallica/.git/objects/93/1ee4b40ceaf16a568e49431e9a2d76627ee78c
docs/finallica/.git/objects/aa/39b1deb0f04e0a08174a6edd0c5a7201d5c59e
docs/finallica/.git/objects/b8/d9703d8cbf78ad10548f1ac396fccd0128cee4
docs/finallica/.git/objects/c0/ca29c8d032d99961cb450c16ca627d5c225918
docs/finallica/.git/refs/heads/master
docs/finallica/ARCHITECTURE_OVERVIEW.md
docs/finallica/CONSENSUS_MECHANISM.md
docs/finallica/CONSTANTS_REFERENCE.md
docs/finallica/CRYPTOGRAPHIC_DETAILS.md
docs/finallica/LIQUIDITY_MANAGEMENT.md
docs/finallica/OPERATIONAL_METRICS.md
docs/finallica/PERFORMANCE_ANALYSIS.md
docs/finallica/PROTOCOL_SPECIFICATION.md
docs/finallica/README.md
docs/finallica/RESEARCH_PROPOSALS.md
docs/finallica/SECURITY_ANALYSIS.md
docs/finallica/TOR_FINALLIKA_MAPPING.md
frontend/app.js
frontend/ARCHITECTURE_OVERVIEW.md
frontend/CONSENSUS_MECHANISM.md
frontend/CONSTANTS_REFERENCE.md
frontend/CRYPTOGRAPHIC_DETAILS.md
frontend/index.html
frontend/LIQUIDITY_MANAGEMENT.md
frontend/OPERATIONAL_METRICS.md
frontend/PERFORMANCE_ANALYSIS.md
frontend/PROTOCOL_SPECIFICATION.md
frontend/README.md
frontend/RESEARCH_PROPOSALS.md
frontend/SECURITY_ANALYSIS.md
frontend/styles.css
frontend/TOR_FINALLIKA_MAPPING.md
package.json
README.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path=".claude/settings.local.json">
{
  "permissions": {
    "allow": [
      "WebSearch"
    ]
  }
}
</file>

<file path=".gitignore">
# Dependencies
node_modules/
**/node_modules/

# Build outputs
dist/
build/
artifacts/
cache/
coverage/

# Environment
.env
.env.local
.env.*.local

# Repomix outputs
repomix-output.xml
repomix-code.xml
repomix-*.xml
repomix-*.txt
.repomix.cache/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
Thumbs.db

# Logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*

# Misc
.cache/
tmp/
temp/
</file>

<file path=".repomix.code.json">
{
  "output": "repomix-code.xml",
  "include": [
    "frontend/**/*.{js,html,css}",
    "backend/**/*.{js,json}",
    "contracts/**/*.{sol,json,js}",
    "shared/**/*",
    "package.json",
    ".env.example",
    ".gitignore",
    ".repomix.*"
  ],
  "ignore": [
    "node_modules/**",
    "**/node_modules/**",
    ".git/**",
    "**/.git/**",
    "docs/finallica/.git/**",
    "**/*.db",
    "**/*.lock",
    "dist/**",
    "build/**",
    "artifacts/**",
    "cache/**",
    "coverage/**",
    ".DS_Store",
    "*.log",
    ".claude/**",
    "repomix*.xml",
    "repomix*.txt",
    "**/*.md"
  ],
  "style": {
    "directoryStructure": true,
    "removeComments": false,
    "removeEmptyLines": false,
    "showLineNumbers": false
  }
}
</file>

<file path=".repomix.json">
{
  "output": "repomix-output.xml",
  "include": [
    "frontend/**/*.{js,html,css,md}",
    "backend/**/*.{js,json}",
    "contracts/**/*.{sol,json,js}",
    "docs/**/*.md",
    "shared/**/*",
    "package.json",
    "README.md",
    ".env.example",
    ".gitignore",
    ".repomix.json"
  ],
  "ignore": [
    "node_modules/**",
    "**/node_modules/**",
    ".git/**",
    "**/.git/**",
    "docs/finallica/.git/**",
    "**/*.db",
    "**/*.lock",
    "dist/**",
    "build/**",
    "artifacts/**",
    "cache/**",
    "coverage/**",
    ".DS_Store",
    "*.log",
    ".claude/**",
    "repomix*.xml",
    "repomix*.txt"
  ],
  "style": {
    "directoryStructure": true,
    "removeComments": false,
    "removeEmptyLines": false,
    "showLineNumbers": false
  }
}
</file>

<file path="backend/.env.example">
# Finallica Backend Environment Configuration

# ============================================
# AI PROVIDER CONFIGURATION
# ============================================

# Default AI Provider (anthropic, openai, openrouter, groq)
AI_PROVIDER=anthropic

# Default Model (examples below)
# Anthropic: claude-sonnet-4-20250514, claude-3-5-sonnet-20241022, claude-3-5-haiku-20241022
# OpenAI: gpt-4o, gpt-4o-mini, gpt-4-turbo, gpt-3.5-turbo
# OpenRouter: anthropic/claude-sonnet-4, openai/gpt-4o, google/gemini-pro-1.5
# Groq: llama-3.3-70b-versatile, llama-3.1-70b-versatile, mixtral-8x7b-32768
AI_MODEL=claude-3-5-sonnet-20241022

# ============================================
# API KEYS
# ============================================

# Anthropic Claude API Keys
# Single key:
# ANTHROPIC_API_KEY=sk-ant-xxxxx
# Multiple keys (comma-separated for load balancing):
ANTHROPIC_API_KEYS=sk-ant-xxxxx,sk-ant-yyyyy,sk-ant-zzzzz

# OpenAI API Keys
# OPENAI_API_KEY=sk-proj-xxxxx
OPENAI_API_KEYS=sk-proj-xxxxx,sk-proj-yyyyy

# OpenRouter API Keys
# OPENROUTER_API_KEY=sk-or-xxxxx
OPENROUTER_API_KEYS=sk-or-xxxxx,sk-or-yyyyy

# Groq API Keys (free tier available)
# GROQ_API_KEY=gsk_xxxxx
GROQ_API_KEYS=gsk_xxxxx,gsk_yyyyy

# ============================================
# SERVER CONFIGURATION
# ============================================

# Port configuration
PORT=3000

# CORS origins (comma-separated)
CORS_ORIGINS=http://localhost:8080,http://localhost:3000

# ============================================
# GIT CONFIGURATION
# ============================================

# Git author for commits
GIT_AUTHOR=Finallica System
GIT_EMAIL=system@finallica.io

# ============================================
# CONSENSUS CONFIGURATION
# ============================================

# Voting period (milliseconds)
VOTING_PERIOD=604800000

# Quorum percentage (0-1)
QUORUM_PCT=0.67

# Minimum stakes
MIN_STAKE_PROPOSAL=1000
MIN_STAKE_VR=500000
MIN_STAKE_SE=2000000

# ============================================
# PRIVACY CONFIGURATION (Tornado Cash Integration)
# ============================================

# Enable privacy features (true/false)
PRIVACY_ENABLED=false

# Ethereum RPC URL (for interacting with Tornado Cash contracts)
RPC_URL=https://mainnet.infura.io/v3/YOUR_INFURA_KEY

# Finallica Privacy Router Contract Address
PRIVACY_ROUTER_ADDRESS=0x...

# Relayer URL (optional - for private withdrawals)
# If not provided, users must withdraw directly (less private)
RELAYER_URL=https://relayer.finallica.io

# ============================================
# TORNADO CASH INSTANCES
# ============================================

# Mainnet Tornado Cash Instance Addresses
# Get latest addresses from: https://docs.tornado.ws/

# ETH Pools
TORNADO_ETH_0_1=0x...
TORNADO_ETH_1=0x...
TORNADO_ETH_10=0x...
TORNADO_ETH_100=0x...

# USDC Pool (Ethereum mainnet)
TORNADO_USDC_100=0x...

# ============================================
# CUSTOM BLF PRIVACY POOLS
# ============================================

# BLF Token Privacy Pools (deploy separately for Finallica)
# These are custom Tornado instances configured for BLF token
TORNADO_BLF_100=0x...
TORNADO_BLF_1000=0x...
TORNADO_BLF_10000=0x...

# ============================================
# TOKEN ADDRESSES
# ============================================

# BLF Governance Token Address
BLF_TOKEN_ADDRESS=0x...

# USDC Token Address (Ethereum mainnet)
USDC_ADDRESS=0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48

# USDT Token Address (Ethereum mainnet)
USDT_ADDRESS=0xdAC17F958D2ee523a2206206994597C13D831ec7
</file>

<file path="backend/database/index.js">
// Database module for Finallica Multi-Repository Platform
// Uses sql.js (pure JavaScript SQLite)

const initSqlJs = require('sql.js');
const fs = require('fs').promises;
const path = require('path');

const DB_PATH = path.join(__dirname, '../data/repositories.db');
const DATA_DIR = path.join(__dirname, '../data');
const REPOS_DIR = path.join(__dirname, '../data/repos');

class DatabaseManager {
    constructor() {
        this.db = null;
        this.SQL = null;
    }

    async initialize() {
        // Ensure directories exist
        await fs.mkdir(DATA_DIR, { recursive: true });
        await fs.mkdir(REPOS_DIR, { recursive: true });

        // Initialize SQL.js
        this.SQL = await initSqlJs();

        // Load or create database
        try {
            const dbBuffer = await fs.readFile(DB_PATH);
            this.db = new this.SQL.Database(dbBuffer);
        } catch {
            // Create new database
            this.db = new this.SQL.Database();
            await this.loadSchema();
        }

        console.log(`Database initialized: ${DB_PATH}`);
    }

    async loadSchema() {
        const schemaPath = path.join(__dirname, 'schema.sql');
        const schema = await fs.readFile(schemaPath, 'utf8');

        // Split schema by semicolons and execute each statement
        const statements = schema
            .split(';')
            .map(s => s.trim())
            .filter(s => s.length > 0);

        for (const stmt of statements) {
            this.db.run(stmt);
        }

        await this.save();
    }

    async save() {
        const data = this.db.export();
        const buffer = Buffer.from(data);
        await fs.writeFile(DB_PATH, buffer);
    }

    // ============================================
    // REPOSITORY OPERATIONS
    // ============================================

    async createRepository(repo) {
        // Ensure all values are defined
        const values = [
            repo.id || ('repo_' + Math.random().toString(36).substr(2, 16)),
            repo.name || 'Unknown',
            repo.sourceType || repo.source_type || 'github',
            repo.url || '',
            repo.cloneUrl || repo.url || '',
            repo.branch || repo.branch || 'main',
            repo.description || '',
            JSON.stringify(repo.tags || []),
            (repo.isPrivate || repo.is_private) ? 1 : 0,
            repo.authTokenId || null,
            repo.localPath || null,
            repo.status || 'pending'
        ];

        this.db.run(`
            INSERT INTO repositories (
                id, name, source_type, url, clone_url, branch,
                description, tags, is_private, auth_token_id,
                local_path, status
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        `, values);
        await this.save();
    }

    getRepository(id) {
        const stmt = this.db.prepare('SELECT * FROM repositories WHERE id = :id');
        const result = stmt.getAsObject({ ':id': id });

        if (result && result.id) {
            try {
                result.tags = JSON.parse(result.tags || '[]');
                result.stats = JSON.parse(result.stats || '{}');
                result.is_private = Boolean(result.is_private);
            } catch {
                result.tags = [];
                result.stats = {};
                result.is_private = false;
            }
            return result;
        }
        return null;
    }

    getAllRepositories(options = {}) {
        let query = 'SELECT * FROM repositories';
        const params = {};

        if (options.status) {
            query += ' WHERE status = :status';
            params[':status'] = options.status;
        }

        query += ' ORDER BY created_at DESC';

        if (options.limit) {
            query += ' LIMIT :limit';
            params[':limit'] = options.limit;
        }

        const stmt = this.db.prepare(query);
        stmt.bind(params);

        const repos = [];
        while (stmt.step()) {
            const repo = stmt.getAsObject();
            try {
                repo.tags = JSON.parse(repo.tags || '[]');
                repo.stats = JSON.parse(repo.stats || '{}');
                repo.is_private = Boolean(repo.is_private);
            } catch {
                repo.tags = [];
                repo.stats = {};
                repo.is_private = false;
            }
            repos.push(repo);
        }
        stmt.free();

        return repos;
    }

    async updateRepository(id, updates) {
        const fields = [];
        const values = [];
        let hasUpdate = false;

        if (updates.name !== undefined) {
            fields.push('name = ?');
            values.push(updates.name);
            hasUpdate = true;
        }
        if (updates.status !== undefined) {
            fields.push('status = ?');
            values.push(updates.status);
            hasUpdate = true;
        }
        if (updates.last_commit_hash !== undefined) {
            fields.push('last_commit_hash = ?');
            values.push(updates.last_commit_hash);
            hasUpdate = true;
        }
        if (updates.last_sync_at !== undefined) {
            fields.push('last_sync_at = ?');
            values.push(updates.last_sync_at);
            hasUpdate = true;
        }
        if (updates.stats !== undefined) {
            fields.push('stats = ?');
            values.push(JSON.stringify(updates.stats));
            hasUpdate = true;
        }
        if (updates.description !== undefined) {
            fields.push('description = ?');
            values.push(updates.description);
            hasUpdate = true;
        }
        if (updates.tags !== undefined) {
            fields.push('tags = ?');
            values.push(JSON.stringify(updates.tags));
            hasUpdate = true;
        }
        if (updates.branch !== undefined) {
            fields.push('branch = ?');
            values.push(updates.branch);
            hasUpdate = true;
        }

        if (hasUpdate) {
            fields.push('updated_at = ?');
            values.push(Math.floor(Date.now() / 1000));
            values.push(id);

            this.db.run(`
                UPDATE repositories SET ${fields.join(', ')} WHERE id = ?
            `, values);
            await this.save();
        }
    }

    async deleteRepository(id) {
        this.db.run('DELETE FROM repositories WHERE id = :id', { ':id': id });
        await this.save();
    }

    // ============================================
    // COLLECTION OPERATIONS
    // ============================================

    async createCollection(collection) {
        const values = [
            collection.id || ('col_' + Math.random().toString(36).substr(2, 16)),
            collection.name || 'Unknown Collection',
            collection.slug || collection.name?.toLowerCase().replace(/\s+/g, '-') || 'unknown',
            collection.description || '',
            (collection.isFeatured || collection.is_featured) ? 1 : 0,
            JSON.stringify(collection.repositoryIds || collection.repository_ids || []),
            JSON.stringify(collection.tags || []),
            collection.sortOrder || collection.sort_order || 0
        ];

        this.db.run(`
            INSERT INTO collections (
                id, name, slug, description, is_featured,
                repository_ids, tags, sort_order
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        `, values);
        await this.save();
    }

    getCollection(id) {
        const stmt = this.db.prepare('SELECT * FROM collections WHERE id = :id');
        const col = stmt.getAsObject({ ':id': id });
        stmt.free();

        if (col && col.id) {
            try {
                col.repository_ids = JSON.parse(col.repository_ids || '[]');
                col.tags = JSON.parse(col.tags || '[]');
                col.is_featured = Boolean(col.is_featured);
                col.is_public = Boolean(col.is_public);
            } catch {
                col.repository_ids = [];
                col.tags = [];
            }
            return col;
        }
        return null;
    }

    getCollectionBySlug(slug) {
        const stmt = this.db.prepare('SELECT * FROM collections WHERE slug = :slug');
        const col = stmt.getAsObject({ ':slug': slug });
        stmt.free();

        if (col && col.id) {
            try {
                col.repository_ids = JSON.parse(col.repository_ids || '[]');
                col.tags = JSON.parse(col.tags || '[]');
                col.is_featured = Boolean(col.is_featured);
                col.is_public = Boolean(col.is_public);
            } catch {
                col.repository_ids = [];
                col.tags = [];
            }
            return col;
        }
        return null;
    }

    getAllCollections() {
        const stmt = this.db.prepare('SELECT * FROM collections ORDER BY sort_order, created_at DESC');
        const collections = [];

        while (stmt.step()) {
            const col = stmt.getAsObject();
            try {
                col.repository_ids = JSON.parse(col.repository_ids || '[]');
                col.tags = JSON.parse(col.tags || '[]');
                col.is_featured = Boolean(col.is_featured);
                col.is_public = Boolean(col.is_public);
            } catch {
                col.repository_ids = [];
                col.tags = [];
            }
            collections.push(col);
        }
        stmt.free();

        return collections;
    }

    async updateCollection(id, updates) {
        const fields = [];
        const values = [];
        let hasUpdate = false;

        if (updates.name !== undefined) {
            fields.push('name = ?');
            values.push(updates.name);
            hasUpdate = true;
        }
        if (updates.description !== undefined) {
            fields.push('description = ?');
            values.push(updates.description);
            hasUpdate = true;
        }
        if (updates.repository_ids !== undefined) {
            fields.push('repository_ids = ?');
            values.push(JSON.stringify(updates.repository_ids));
            hasUpdate = true;
        }
        if (updates.tags !== undefined) {
            fields.push('tags = ?');
            values.push(JSON.stringify(updates.tags));
            hasUpdate = true;
        }
        if (updates.is_featured !== undefined) {
            fields.push('is_featured = ?');
            values.push(updates.is_featured ? 1 : 0);
            hasUpdate = true;
        }

        if (hasUpdate) {
            fields.push('updated_at = ?');
            values.push(Math.floor(Date.now() / 1000));
            values.push(id);

            this.db.run(`
                UPDATE collections SET ${fields.join(', ')} WHERE id = ?
            `, values);
            await this.save();
        }
    }

    async deleteCollection(id) {
        this.db.run('DELETE FROM collections WHERE id = :id', { ':id': id });
        await this.save();
    }

    // ============================================
    // SYNC JOB OPERATIONS
    // ============================================

    async createSyncJob(job) {
        this.db.run(`
            INSERT INTO sync_jobs (
                id, repository_id, status, trigger_type
            ) VALUES (?, ?, ?, ?)
        `, [job.id, job.repositoryId, job.status || 'queued', job.triggerType || 'manual']);
        await this.save();
    }

    async updateSyncJob(id, updates) {
        const fields = [];
        const values = [];

        if (updates.status !== undefined) {
            fields.push('status = ?');
            values.push(updates.status);
        }
        if (updates.started_at !== undefined) {
            fields.push('started_at = ?');
            values.push(updates.started_at);
        }
        if (updates.completed_at !== undefined) {
            fields.push('completed_at = ?');
            values.push(updates.completed_at);
        }
        if (updates.duration_ms !== undefined) {
            fields.push('duration_ms = ?');
            values.push(updates.duration_ms);
        }
        if (updates.files_added !== undefined) {
            fields.push('files_added = ?');
            values.push(updates.files_added);
        }
        if (updates.files_modified !== undefined) {
            fields.push('files_modified = ?');
            values.push(updates.files_modified);
        }
        if (updates.files_deleted !== undefined) {
            fields.push('files_deleted = ?');
            values.push(updates.files_deleted);
        }
        if (updates.error_message !== undefined) {
            fields.push('error_message = ?');
            values.push(updates.error_message);
        }

        if (fields.length > 0) {
            values.push(id);
            this.db.run(`
                UPDATE sync_jobs SET ${fields.join(', ')} WHERE id = ?
            `, values);
            await this.save();
        }
    }

    getSyncJob(id) {
        const stmt = this.db.prepare('SELECT * FROM sync_jobs WHERE id = :id');
        const job = stmt.getAsObject({ ':id': id });
        stmt.free();
        return job && job.id ? job : null;
    }

    getActiveSyncJobs() {
        const stmt = this.db.prepare(`
            SELECT sj.*, r.name as repository_name
            FROM sync_jobs sj
            JOIN repositories r ON sj.repository_id = r.id
            WHERE sj.status IN ('queued', 'running')
            ORDER BY sj.started_at DESC
        `);
        const jobs = [];
        while (stmt.step()) {
            jobs.push(stmt.getAsObject());
        }
        stmt.free();
        return jobs;
    }

    getRecentSyncJobs(limit = 50) {
        const stmt = this.db.prepare(`
            SELECT sj.*, r.name as repository_name
            FROM sync_jobs sj
            JOIN repositories r ON sj.repository_id = r.id
            WHERE sj.status IN ('completed', 'failed')
            ORDER BY sj.completed_at DESC
            LIMIT :limit
        `);
        stmt.bind({ ':limit': limit });
        const jobs = [];
        while (stmt.step()) {
            jobs.push(stmt.getAsObject());
        }
        stmt.free();
        return jobs;
    }

    // ============================================
    // SUBMISSION OPERATIONS
    // ============================================

    async createSubmission(submission) {
        this.db.run(`
            INSERT INTO submissions (
                id, submitter_name, submitter_email, submitter_note,
                repo_url, repo_name, repo_description
            ) VALUES (?, ?, ?, ?, ?, ?, ?)
        `, [
            submission.id,
            submission.submitterName,
            submission.submitterEmail,
            submission.submitterNote,
            submission.repoUrl,
            submission.repoName,
            submission.repoDescription
        ]);
        await this.save();
    }

    getSubmission(id) {
        const stmt = this.db.prepare('SELECT * FROM submissions WHERE id = :id');
        const sub = stmt.getAsObject({ ':id': id });
        stmt.free();
        return sub && sub.id ? sub : null;
    }

    getAllSubmissions(filters = {}) {
        let query = 'SELECT * FROM submissions';
        const conditions = [];
        const params = {};

        if (filters.status) {
            conditions.push('status = :status');
            params[':status'] = filters.status;
        }

        if (conditions.length > 0) {
            query += ' WHERE ' + conditions.join(' AND ');
        }

        query += ' ORDER BY submitted_at DESC';

        if (filters.limit) {
            query += ' LIMIT :limit';
            params[':limit'] = filters.limit;
        }

        const stmt = this.db.prepare(query);
        stmt.bind(params);
        const submissions = [];
        while (stmt.step()) {
            submissions.push(stmt.getAsObject());
        }
        stmt.free();
        return submissions;
    }

    async updateSubmission(id, updates) {
        const fields = [];
        const values = [];

        if (updates.status !== undefined) {
            fields.push('status = ?');
            values.push(updates.status);
        }
        if (updates.repository_id !== undefined) {
            fields.push('repository_id = ?');
            values.push(updates.repository_id);
        }
        if (updates.reviewed_by !== undefined) {
            fields.push('reviewed_by = ?');
            values.push(updates.reviewed_by);
        }
        if (updates.review_note !== undefined) {
            fields.push('review_note = ?');
            values.push(updates.review_note);
        }
        if (updates.status && updates.status !== 'pending') {
            fields.push('reviewed_at = ?');
            values.push(Math.floor(Date.now() / 1000));
        }

        if (fields.length > 0) {
            values.push(id);
            this.db.run(`
                UPDATE submissions SET ${fields.join(', ')} WHERE id = ?
            `, values);
            await this.save();
        }
    }

    // ============================================
    // AUTH TOKEN OPERATIONS
    // ============================================

    async createAuthToken(token) {
        this.db.run(`
            INSERT INTO auth_tokens (
                id, provider, token_name, token_value_encrypted,
                iv, auth_tag, username, scope
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        `, [
            token.id,
            token.provider,
            token.tokenName,
            token.tokenValueEncrypted,
            token.iv,
            token.authTag,
            token.username,
            JSON.stringify(token.scope || [])
        ]);
        await this.save();
    }

    getAuthToken(id) {
        const stmt = this.db.prepare('SELECT * FROM auth_tokens WHERE id = :id AND is_active = 1');
        const token = stmt.getAsObject({ ':id': id });
        stmt.free();

        if (token && token.id) {
            try {
                token.scope = JSON.parse(token.scope || '[]');
                token.is_active = Boolean(token.is_active);
            } catch {
                token.scope = [];
            }
            return token;
        }
        return null;
    }

    getAllAuthTokens() {
        const stmt = this.db.prepare('SELECT id, provider, token_name, username, scope, is_active, created_at, last_used_at FROM auth_tokens ORDER BY created_at DESC');
        const tokens = [];
        while (stmt.step()) {
            const token = stmt.getAsObject();
            try {
                token.scope = JSON.parse(token.scope || '[]');
                token.is_active = Boolean(token.is_active);
            } catch {
                token.scope = [];
            }
            tokens.push(token);
        }
        stmt.free();
        return tokens;
    }

    async deleteAuthToken(id) {
        this.db.run('DELETE FROM auth_tokens WHERE id = :id', { ':id': id });
        await this.save();
    }

    async updateAuthTokenLastUsed(id) {
        this.db.run(`
            UPDATE auth_tokens SET last_used_at = :timestamp WHERE id = :id
        `, {
            ':timestamp': Math.floor(Date.now() / 1000),
            ':id': id
        });
        await this.save();
    }

    // ============================================
    // ACTIVITY LOG
    // ============================================

    async logActivity(action, entityType, entityId, userId, details = {}) {
        this.db.run(`
            INSERT INTO activity_log (action, entity_type, entity_id, user_id, details)
            VALUES (?, ?, ?, ?, ?)
        `, [action, entityType, entityId, userId, JSON.stringify(details)]);
        await this.save();
    }

    getRecentActivity(limit = 100) {
        const stmt = this.db.prepare(`
            SELECT * FROM activity_log
            ORDER BY created_at DESC
            LIMIT :limit
        `);
        stmt.bind({ ':limit': limit });
        const activities = [];
        while (stmt.step()) {
            const activity = stmt.getAsObject();
            try {
                activity.details = JSON.parse(activity.details || '{}');
            } catch {
                activity.details = {};
            }
            activities.push(activity);
        }
        stmt.free();
        return activities;
    }

    // ============================================
    // UTILITY
    // ============================================

    getReposPath() {
        return REPOS_DIR;
    }

    close() {
        if (this.db) {
            this.db.close();
        }
    }
}

// Singleton instance
const db = new DatabaseManager();

module.exports = db;
</file>

<file path="backend/database/schema.sql">
-- Finallica Multi-Repository Documentation Platform
-- Database Schema

-- ============================================
-- REPOSITORIES
-- ============================================
CREATE TABLE IF NOT EXISTS repositories (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    source_type TEXT NOT NULL, -- 'github', 'gitlab', 'bitbucket', 'https', 'ssh', 'zip', 'api'
    url TEXT,
    clone_url TEXT,
    branch TEXT DEFAULT 'main',
    description TEXT,
    tags TEXT, -- JSON array
    status TEXT DEFAULT 'pending', -- 'pending', 'cloning', 'active', 'error', 'archived'
    is_private BOOLEAN DEFAULT 0,
    auth_token_id TEXT,
    local_path TEXT,
    last_commit_hash TEXT,
    last_sync_at INTEGER,
    created_at INTEGER DEFAULT (strftime('%s', 'now')),
    updated_at INTEGER DEFAULT (strftime('%s', 'now')),
    stats TEXT -- JSON: {fileCount, markdownCount, totalSize}
);

CREATE INDEX idx_repos_status ON repositories(status);
CREATE INDEX idx_repos_source_type ON repositories(source_type);

-- ============================================
-- REPOSITORY FILES (indexed documents)
-- ============================================
CREATE TABLE IF NOT EXISTS repository_files (
    id TEXT PRIMARY KEY,
    repository_id TEXT NOT NULL,
    path TEXT NOT NULL,
    filename TEXT NOT NULL,
    extension TEXT,
    content_hash TEXT,
    size INTEGER,
    title TEXT,
    indexed_at INTEGER DEFAULT (strftime('%s', 'now')),
    is_document BOOLEAN DEFAULT 1,
    FOREIGN KEY (repository_id) REFERENCES repositories(id) ON DELETE CASCADE
);

CREATE INDEX idx_repo_files_repo ON repository_files(repository_id);
CREATE INDEX idx_repo_files_path ON repository_files(path);

-- ============================================
-- COLLECTIONS (curated repo groups)
-- ============================================
CREATE TABLE IF NOT EXISTS collections (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL UNIQUE,
    slug TEXT NOT NULL UNIQUE,
    description TEXT,
    is_featured BOOLEAN DEFAULT 0,
    is_public BOOLEAN DEFAULT 1,
    repository_ids TEXT, -- JSON array
    tags TEXT, -- JSON array
    sort_order INTEGER DEFAULT 0,
    created_at INTEGER DEFAULT (strftime('%s', 'now')),
    updated_at INTEGER DEFAULT (strftime('%s', 'now'))
);

-- ============================================
-- SUBMISSIONS (user-submitted repos)
-- ============================================
CREATE TABLE IF NOT EXISTS submissions (
    id TEXT PRIMARY KEY,
    repository_id TEXT,
    submitter_name TEXT,
    submitter_email TEXT,
    submitter_note TEXT,
    repo_url TEXT NOT NULL,
    repo_name TEXT,
    repo_description TEXT,
    status TEXT DEFAULT 'pending', -- 'pending', 'approved', 'rejected', 'needs_review'
    submitted_at INTEGER DEFAULT (strftime('%s', 'now')),
    reviewed_at INTEGER,
    reviewed_by TEXT,
    review_note TEXT,
    FOREIGN KEY (repository_id) REFERENCES repositories(id) ON DELETE SET NULL
);

CREATE INDEX idx_submissions_status ON submissions(status);

-- ============================================
-- SYNC JOBS (background sync tracking)
-- ============================================
CREATE TABLE IF NOT EXISTS sync_jobs (
    id TEXT PRIMARY KEY,
    repository_id TEXT NOT NULL,
    status TEXT DEFAULT 'queued', -- 'queued', 'running', 'completed', 'failed'
    started_at INTEGER,
    completed_at INTEGER,
    duration_ms INTEGER,
    files_added INTEGER DEFAULT 0,
    files_modified INTEGER DEFAULT 0,
    files_deleted INTEGER DEFAULT 0,
    error_message TEXT,
    trigger_type TEXT, -- 'scheduled', 'manual', 'webhook'
    FOREIGN KEY (repository_id) REFERENCES repositories(id) ON DELETE CASCADE
);

CREATE INDEX idx_sync_jobs_repo ON sync_jobs(repository_id);
CREATE INDEX idx_sync_jobs_status ON sync_jobs(status);

-- ============================================
-- SYNC SCHEDULE (scheduler configuration)
-- ============================================
CREATE TABLE IF NOT EXISTS sync_schedule (
    id INTEGER PRIMARY KEY,
    is_enabled BOOLEAN DEFAULT 1,
    interval_minutes INTEGER DEFAULT 30,
    max_concurrent_jobs INTEGER DEFAULT 3,
    retry_attempts INTEGER DEFAULT 3,
    retry_delay_minutes INTEGER DEFAULT 5,
    last_run_at INTEGER,
    next_run_at INTEGER
);

-- Insert default schedule
INSERT OR IGNORE INTO sync_schedule (id, is_enabled, interval_minutes, max_concurrent_jobs)
VALUES (1, 1, 30, 3);

-- ============================================
-- AUTH TOKENS (for private repos)
-- ============================================
CREATE TABLE IF NOT EXISTS auth_tokens (
    id TEXT PRIMARY KEY,
    provider TEXT NOT NULL, -- 'github', 'gitlab', 'bitbucket', 'notion', 'confluence'
    token_name TEXT,
    token_value_encrypted TEXT,
    iv TEXT,
    auth_tag TEXT,
    username TEXT,
    scope TEXT, -- JSON array
    is_active BOOLEAN DEFAULT 1,
    created_at INTEGER DEFAULT (strftime('%s', 'now')),
    last_used_at INTEGER
);

-- ============================================
-- DISCOVERY RULES (auto-import rules)
-- ============================================
CREATE TABLE IF NOT EXISTS discovery_rules (
    id TEXT PRIMARY KEY,
    name TEXT NOT NULL,
    source TEXT NOT NULL, -- 'github', 'gitlab'
    query TEXT NOT NULL,
    topics TEXT, -- JSON array
    language TEXT,
    stars_min INTEGER,
    forks_min INTEGER,
    updated_within_days INTEGER,
    auto_add BOOLEAN DEFAULT 0,
    target_collection_id TEXT,
    last_run_at INTEGER,
    is_active BOOLEAN DEFAULT 1,
    FOREIGN KEY (target_collection_id) REFERENCES collections(id) ON DELETE SET NULL
);

-- ============================================
-- ACTIVITY LOG (audit trail)
-- ============================================
CREATE TABLE IF NOT EXISTS activity_log (
    id TEXT PRIMARY KEY,
    action TEXT NOT NULL,
    entity_type TEXT,
    entity_id TEXT,
    user_id TEXT,
    details TEXT, -- JSON
    created_at INTEGER DEFAULT (strftime('%s', 'now'))
);

CREATE INDEX idx_activity_log_entity ON activity_log(entity_type, entity_id);
CREATE INDEX idx_activity_log_created ON activity_log(created_at);
</file>

<file path="backend/package.json">
{
  "name": "finallica-backend",
  "version": "1.0.0",
  "description": "Backend API for Finallica documentation system",
  "main": "server.js",
  "scripts": {
    "start": "node server.js",
    "dev": "nodemon server.js"
  },
  "dependencies": {
    "adm-zip": "^0.5.10",
    "cors": "^2.8.5",
    "diff": "^5.1.0",
    "ethers": "^6.16.0",
    "express": "^4.18.2",
    "marked": "^9.1.6",
    "octokit": "^3.1.2",
    "simple-git": "^3.19.1",
    "sql.js": "^1.10.3",
    "tar": "^6.2.0",
    "ws": "^8.14.2"
  },
  "devDependencies": {
    "nodemon": "^3.0.1"
  }
}
</file>

<file path="backend/routes/collections.js">
// Collection API Routes

const express = require('express');
const crypto = require('crypto');
const router = express.Router();

function createCollectionRoutes(db) {
    // GET /api/collections - List all collections
    router.get('/', (req, res) => {
        try {
            const collections = db.getAllCollections();
            res.json({ collections });
        } catch (error) {
            console.error('Error listing collections:', error);
            res.status(500).json({ error: 'Failed to list collections' });
        }
    });

    // GET /api/collections/:id - Get collection by ID
    router.get('/:id', (req, res) => {
        try {
            const collection = db.getCollection(req.params.id);
            if (!collection) {
                return res.status(404).json({ error: 'Collection not found' });
            }

            // Get full repository details for each repo
            const repos = [];
            if (collection.repository_ids) {
                for (const repoId of collection.repository_ids) {
                    const repo = db.getRepository(repoId);
                    if (repo) {
                        repos.push({
                            id: repo.id,
                            name: repo.name,
                            description: repo.description,
                            tags: repo.tags,
                            status: repo.status
                        });
                    }
                }
            }

            res.json({
                collection: {
                    ...collection,
                    repositories: repos
                }
            });
        } catch (error) {
            console.error('Error getting collection:', error);
            res.status(500).json({ error: 'Failed to get collection' });
        }
    });

    // GET /api/collections/slug/:slug - Get collection by slug
    router.get('/slug/:slug', (req, res) => {
        try {
            const collection = db.getCollectionBySlug(req.params.slug);
            if (!collection) {
                return res.status(404).json({ error: 'Collection not found' });
            }
            res.json({ collection });
        } catch (error) {
            console.error('Error getting collection by slug:', error);
            res.status(500).json({ error: 'Failed to get collection' });
        }
    });

    // POST /api/collections - Create new collection (admin)
    router.post('/', async (req, res) => {
        try {
            const { name, slug, description, repositoryIds, tags, isFeatured } = req.body;

            if (!name) {
                return res.status(400).json({ error: 'Name is required' });
            }

            const collection = {
                id: 'col_' + crypto.randomBytes(16).toString('hex'),
                name,
                slug: slug || name.toLowerCase().replace(/\s+/g, '-'),
                description: description || '',
                repositoryIds: repositoryIds || [],
                tags: tags || [],
                isFeatured: isFeatured || false
            };

            await db.createCollection(collection);

            res.status(201).json({ collection });
        } catch (error) {
            console.error('Error creating collection:', error);
            res.status(500).json({ error: error.message });
        }
    });

    // PUT /api/collections/:id - Update collection
    router.put('/:id', async (req, res) => {
        try {
            const { name, description, repositoryIds, tags, isFeatured } = req.body;

            await db.updateCollection(req.params.id, {
                name,
                description,
                repositoryIds,
                tags,
                isFeatured
            });

            const collection = db.getCollection(req.params.id);
            res.json({ collection });
        } catch (error) {
            console.error('Error updating collection:', error);
            res.status(500).json({ error: error.message });
        }
    });

    // DELETE /api/collections/:id - Delete collection
    router.delete('/:id', async (req, res) => {
        try {
            await db.deleteCollection(req.params.id);
            res.json({ success: true });
        } catch (error) {
            console.error('Error deleting collection:', error);
            res.status(500).json({ error: error.message });
        }
    });

    return router;
}

module.exports = createCollectionRoutes;
</file>

<file path="backend/routes/repositories.js">
// Repository API Routes

const express = require('express');
const crypto = require('crypto');
const router = express.Router();

function createRepositoryRoutes(db, repositoryService, gitSync) {
    // GET /api/repositories - List all repositories
    router.get('/', (req, res) => {
        try {
            const { status, tag, search } = req.query;

            let repos;

            if (search) {
                repos = repositoryService.searchRepositories(search);
            } else if (tag) {
                repos = repositoryService.getRepositoriesByTag(tag);
            } else {
                repos = repositoryService.listRepositories({ status });
            }

            res.json({
                repositories: repos,
                total: repos.length,
                stats: repositoryService.getStatsSummary()
            });
        } catch (error) {
            console.error('Error listing repositories:', error);
            res.status(500).json({ error: 'Failed to list repositories' });
        }
    });

    // GET /api/repositories/stats - Get repository statistics
    router.get('/stats', (req, res) => {
        try {
            const stats = repositoryService.getStatsSummary();
            res.json(stats);
        } catch (error) {
            console.error('Error getting stats:', error);
            res.status(500).json({ error: 'Failed to get statistics' });
        }
    });

    // POST /api/repositories - Add new repository
    router.post('/', async (req, res) => {
        try {
            const { url, name, branch, description, tags, isPrivate, authTokenId } = req.body;

            if (!url) {
                return res.status(400).json({ error: 'URL is required' });
            }

            // Create repository
            const repo = await repositoryService.createRepository({
                url,
                name,
                branch,
                description,
                tags: tags || [],
                isPrivate: isPrivate || false,
                authTokenId
            });

            // Start initial sync in background
            setImmediate(async () => {
                try {
                    await repositoryService.syncRepository(repo.id);
                } catch (error) {
                    console.error('Initial sync error:', error);
                }
            });

            res.status(201).json({
                repository: repo,
                message: 'Repository added. Initial sync started.'
            });
        } catch (error) {
            console.error('Error creating repository:', error);
            res.status(500).json({ error: error.message });
        }
    });

    // GET /api/repositories/:id - Get repository details
    router.get('/:id', (req, res) => {
        try {
            const { id } = req.params;
            const repo = repositoryService.getRepository(id);

            if (!repo) {
                return res.status(404).json({ error: 'Repository not found' });
            }

            res.json({ repository: repo });
        } catch (error) {
            console.error('Error getting repository:', error);
            res.status(500).json({ error: 'Failed to get repository' });
        }
    });

    // PUT /api/repositories/:id - Update repository
    router.put('/:id', (req, res) => {
        try {
            const { id } = req.params;
            const { name, description, tags, branch } = req.body;

            const updates = {};
            if (name !== undefined) updates.name = name;
            if (description !== undefined) updates.description = description;
            if (tags !== undefined) updates.tags = tags;
            if (branch !== undefined) updates.branch = branch;

            repositoryService.updateRepository(id, updates);

            const repo = repositoryService.getRepository(id);
            res.json({ repository: repo });
        } catch (error) {
            console.error('Error updating repository:', error);
            res.status(500).json({ error: 'Failed to update repository' });
        }
    });

    // DELETE /api/repositories/:id - Remove repository
    router.delete('/:id', async (req, res) => {
        try {
            const { id } = req.params;
            await repositoryService.deleteRepository(id);
            res.json({ success: true, message: 'Repository deleted' });
        } catch (error) {
            console.error('Error deleting repository:', error);
            res.status(500).json({ error: error.message });
        }
    });

    // POST /api/repositories/:id/sync - Trigger manual sync
    router.post('/:id/sync', async (req, res) => {
        try {
            const { id } = req.params;

            // Create sync job
            const jobId = 'sync_' + crypto.randomBytes(16).toString('hex');
            db.createSyncJob({
                id: jobId,
                repositoryId: id,
                status: 'queued',
                triggerType: 'manual'
            });

            // Start sync in background
            setImmediate(async () => {
                try {
                    db.updateSyncJob(jobId, { status: 'running', started_at: Math.floor(Date.now() / 1000) });

                    const result = await repositoryService.syncRepository(id);

                    db.updateSyncJob(jobId, {
                        status: result.success ? 'completed' : 'failed',
                        completed_at: Math.floor(Date.now() / 1000),
                        duration_ms: result.duration,
                        files_added: result.filesAdded,
                        files_modified: result.filesModified,
                        error_message: result.error
                    });
                } catch (error) {
                    db.updateSyncJob(jobId, {
                        status: 'failed',
                        completed_at: Math.floor(Date.now() / 1000),
                        error_message: error.message
                    });
                }
            });

            res.json({
                success: true,
                message: 'Sync job queued',
                jobId
            });
        } catch (error) {
            console.error('Error queuing sync:', error);
            res.status(500).json({ error: error.message });
        }
    });

    // GET /api/repositories/:id/files - List repository files
    router.get('/:id/files', async (req, res) => {
        try {
            const { id } = req.params;
            const { path = '' } = req.query;

            const result = await repositoryService.getRepositoryFiles(id, path);

            if (!result.success) {
                return res.status(500).json({ error: result.error });
            }

            res.json({ files: result.files });
        } catch (error) {
            console.error('Error listing files:', error);
            res.status(500).json({ error: 'Failed to list files' });
        }
    });

    // GET /api/repositories/:id/files/* - Get file content
    router.get('/:id/files/*', async (req, res) => {
        try {
            const { id } = req.params;
            const filePath = req.params[0]; // Everything after /files/

            const result = await repositoryService.getFileContent(id, filePath);

            if (!result.success) {
                return res.status(404).json({ error: result.error || 'File not found' });
            }

            res.json({
                path: filePath,
                content: result.content
            });
        } catch (error) {
            console.error('Error getting file:', error);
            res.status(500).json({ error: 'Failed to get file content' });
        }
    });

    // GET /api/repositories/:id/history - Get sync history
    router.get('/:id/history', (req, res) => {
        try {
            const { id } = req.params;

            // Get sync jobs for this repository
            const stmt = db.db.prepare(`
                SELECT * FROM sync_jobs
                WHERE repository_id = ?
                ORDER BY started_at DESC
                LIMIT 20
            `);

            const jobs = stmt.all(id);

            res.json({ history: jobs });
        } catch (error) {
            console.error('Error getting history:', error);
            res.status(500).json({ error: 'Failed to get history' });
        }
    });

    return router;
}

module.exports = createRepositoryRoutes;
</file>

<file path="backend/seed.js">
// Seed script for initial repositories and collections

const db = require('./database');
const crypto = require('crypto');

const INITIAL_REPOSITORIES = [
    // Privacy Networks
    {
        name: 'torproject/tor',
        url: 'https://github.com/torproject/tor',
        branch: 'main',
        description: 'Core Tor implementation providing the foundation for onion services and privacy networks',
        tags: ['privacy', 'anonymous', 'onion-routing', 'foundational'],
        sourceType: 'github'
    },
    {
        name: 'torproject/privacy-docs',
        url: 'https://github.com/torproject/privacy-docs',
        branch: 'main',
        description: 'Official Tor privacy documentation with onion-service guides',
        tags: ['privacy', 'documentation', 'guides'],
        sourceType: 'github'
    },
    {
        name: 'i2p/i2p.i2p',
        url: 'https://github.com/i2p/i2p.i2p',
        branch: 'main',
        description: 'I2P anonymous network with emphasis on censorship resistance',
        tags: ['privacy', 'anonymous', 'p2p', 'censorship-resistant'],
        sourceType: 'github'
    },
    // Cryptography
    {
        name: 'ethereum/consensus-specs',
        url: 'https://github.com/ethereum/consensus-specs',
        branch: 'master',
        description: 'Official Ethereum consensus specs with BLS signature implementations',
        tags: ['cryptography', 'bls', 'consensus', 'ethereum'],
        sourceType: 'github'
    },
    {
        name: 'matter-labs/awesome-zero-knowledge-proofs',
        url: 'https://github.com/matter-labs/awesome-zero-knowledge-proofs',
        branch: 'master',
        description: 'Comprehensive ZKP knowledge base with library comparisons',
        tags: ['cryptography', 'zk-snark', 'zk-stark', 'zero-knowledge'],
        sourceType: 'github'
    },
    {
        name: 'ethereum/awesome-privacy-sig',
        url: 'https://github.com/ethereum/awesome-privacy-sig',
        branch: 'master',
        description: 'Research resources for privacy-preserving signatures and protocols',
        tags: ['cryptography', 'privacy', 'signatures', 'research'],
        sourceType: 'github'
    },
    // P2P Networking
    {
        name: 'libp2p/specs',
        url: 'https://github.com/libp2p/specs',
        branch: 'master',
        description: 'Official libp2p P2P networking specifications',
        tags: ['p2p', 'networking', 'protocol-specs', 'libp2p'],
        sourceType: 'github'
    },
    {
        name: 'ipfs/ipfs',
        url: 'https://github.com/ipfs/ipfs',
        branch: 'master',
        description: 'IPFS implementation - practical P2P file system',
        tags: ['p2p', 'ipfs', 'storage', 'distributed'],
        sourceType: 'github'
    },
    // Consensus
    {
        name: 'hot-stuff/libhotstuff',
        url: 'https://github.com/hot-stuff/libhotstuff',
        branch: 'master',
        description: 'Production-ready HotStuff BFT consensus engine',
        tags: ['consensus', 'bft', 'hotstuff', 'leader-based'],
        sourceType: 'github'
    },
    {
        name: 'cometbft/cometbft',
        url: 'https://github.com/cometbft/cometbft',
        branch: 'main',
        description: 'CometBFT (formerly Tendermint Core) BFT consensus implementation',
        tags: ['consensus', 'bft', 'tendermint', 'production'],
        sourceType: 'github'
    },
    // Payment Channels
    {
        name: 'lightningnetwork/lnd',
        url: 'https://github.com/lightningnetwork/lnd',
        branch: 'master',
        description: 'Lightning Network reference implementation',
        tags: ['lightning', 'payment-channels', 'bitcoin', 'layer2'],
        sourceType: 'github'
    },
    {
        name: 'raiden-network/raiden',
        url: 'https://github.com/raiden-network/raiden',
        branch: 'master',
        description: 'Ethereum state channels implementation for scaling',
        tags: ['payment-channels', 'ethereum', 'state-channels', 'scaling'],
        sourceType: 'github'
    }
];

const INITIAL_COLLECTIONS = [
    {
        id: 'col_privacy_foundations',
        name: 'Privacy Foundations',
        slug: 'privacy-foundations',
        description: 'Core privacy-preserving technologies and protocols including Tor, I2P, and onion routing.',
        isFeatured: true,
        tags: ['privacy', 'anonymous', 'foundational'],
        sortOrder: 1
    },
    {
        id: 'col_cryptography',
        name: 'Cryptography Libraries',
        slug: 'cryptography-libraries',
        description: 'Cryptographic primitives including BLS signatures, zero-knowledge proofs, and privacy-preserving signatures.',
        isFeatured: true,
        tags: ['cryptography', 'zk-snark', 'bls', 'privacy'],
        sortOrder: 2
    },
    {
        id: 'col_p2p_networking',
        name: 'P2P Networking',
        slug: 'p2p-networking',
        description: 'Peer-to-peer network protocols and implementations including libp2p and IPFS.',
        isFeatured: true,
        tags: ['p2p', 'networking', 'distributed', 'protocols'],
        sortOrder: 3
    },
    {
        id: 'col_consensus',
        name: 'Blockchain Consensus',
        slug: 'blockchain-consensus',
        description: 'Consensus algorithm implementations including HotStuff BFT, Tendermint/CometBFT, and Ethereum specifications.',
        isFeatured: true,
        tags: ['consensus', 'bft', 'hotstuff', 'tendermint'],
        sortOrder: 4
    },
    {
        id: 'col_payment_channels',
        name: 'Payment Channels',
        slug: 'payment-channels',
        description: 'Layer 2 scaling solutions including Lightning Network and state channels for both Bitcoin and Ethereum.',
        isFeatured: true,
        tags: ['lightning', 'payment-channels', 'layer2', 'scaling'],
        sortOrder: 5
    }
];

async function generateId(prefix) {
    return (prefix || 'id') + '_' + crypto.randomBytes(16).toString('hex');
}

async function seed() {
    console.log('Starting database seed...');

    await db.initialize();

    // Add repositories
    const repoMap = {};
    for (const repoData of INITIAL_REPOSITORIES) {
        const repo = {
            id: await generateId('repo'),
            ...repoData
        };
        await db.createRepository(repo);
        repoMap[repo.name] = repo.id;
        console.log(`  Added repository: ${repo.name}`);
    }

    // Add collections with repository mappings
    const collectionRepos = {
        'col_privacy_foundations': ['torproject/tor', 'torproject/privacy-docs', 'i2p/i2p.i2p'],
        'col_cryptography': ['ethereum/consensus-specs', 'matter-labs/awesome-zero-knowledge-proofs', 'ethereum/awesome-privacy-sig'],
        'col_p2p_networking': ['libp2p/specs', 'ipfs/ipfs'],
        'col_consensus': ['hot-stuff/libhotstuff', 'cometbft/cometbft'],
        'col_payment_channels': ['lightningnetwork/lnd', 'raiden-network/raiden']
    };

    for (const colData of INITIAL_COLLECTIONS) {
        const collection = {
            ...colData,
            repositoryIds: (collectionRepos[colData.id] || []).map(name => repoMap[name]).filter(id => id)
        };
        await db.createCollection(collection);
        console.log(`  Added collection: ${collection.name} (${collection.repositoryIds.length} repos)`);
    }

    console.log('Seed complete!');
    console.log(`  Repositories: ${INITIAL_REPOSITORIES.length}`);
    console.log(`  Collections: ${INITIAL_COLLECTIONS.length}`);

    await db.close();
}

seed().catch(console.error);
</file>

<file path="backend/server.js">
// Finallica Documentation System - Backend Server
// This handles API routes, WebSocket, Git integration, and consensus logic

const express = require('express');
const cors = require('cors');
const http = require('http');
const WebSocket = require('ws');
const simpleGit = require('simple-git');
const diff = require('diff');
const fs = require('fs').promises;
const path = require('path');

// Multi-Repository System
const db = require('./database');
const GitSyncService = require('./services/git-sync');
const RepositoryService = require('./services/repository-service');
const createRepositoryRoutes = require('./routes/repositories');
const createCollectionRoutes = require('./routes/collections');

// Privacy Service
const PrivacyService = require('./services/privacy-service');

const app = express();
const server = http.createServer(app);
const wss = new WebSocket.Server({ server });

const PORT = 3000;
const DOCS_PATH = path.join(__dirname, '../docs/finallica');

// Configuration
const CONFIG = {
    VOTING_PERIOD: 7 * 24 * 60 * 60 * 1000, // 7 days
    QUORUM_PCT: 0.67, // 67%
    MIN_STAKE_PROPOSAL: 1000,
    MIN_STAKE_VR: 500000,
    MIN_STAKE_SE: 2000000,
    // AI Provider: 'claude' (Anthropic), 'openai', or 'demo'
    AI_PROVIDER: process.env.AI_PROVIDER || 'demo',
    ANTHROPIC_API_KEY: process.env.ANTHROPIC_API_KEY || '',
    OPENAI_API_KEY: process.env.OPENAI_API_KEY || '',
    // Privacy Configuration
    PRIVACY_ENABLED: process.env.PRIVACY_ENABLED === 'true',
    PRIVACY_ROUTER_ADDRESS: process.env.PRIVACY_ROUTER_ADDRESS || '',
    RPC_URL: process.env.RPC_URL || 'http://localhost:8545',
    RELAYER_URL: process.env.RELAYER_URL || ''
};

// State
const state = {
    documents: {},
    proposals: {},
    consensus: {
        blockNumber: 18492,
        epoch: 1,
        totalStake: 18432000, // BLF
        votesFor: 12345000,
        votesAgainst: 2100000,
        quorum: 12345600, // 67% of total
        totalVotes: 14445000,
        items: []
    },
    activity: [],
    clients: new Set()
};

// ============================================
// MULTI-REPOSITORY SYSTEM INITIALIZATION
// ============================================

let gitSync, repositoryService;

async function initializeRepositorySystem() {
    try {
        // Initialize database
        await db.initialize();

        // Initialize services
        gitSync = new GitSyncService(db);
        repositoryService = new RepositoryService(db, gitSync);

        // Register routes
        app.use('/api/repositories', createRepositoryRoutes(db, repositoryService, gitSync));
        app.use('/api/collections', createCollectionRoutes(db));

        console.log('Multi-repository system initialized');
    } catch (error) {
        console.error('Failed to initialize repository system:', error);
    }
}

// Middleware
app.use(cors());
app.use(express.json({ limit: '10mb' }));

// ============================================
// DOCUMENT ROUTES
// ============================================

app.get('/api/documents', async (req, res) => {
    try {
        await loadDocuments();
        res.json({ documents: state.documents });
    } catch (error) {
        console.error('Error loading documents:', error);
        res.status(500).json({ error: 'Failed to load documents' });
    }
});

app.get('/api/documents/:docName', async (req, res) => {
    try {
        const { docName } = req.params;
        const content = state.documents[docName];

        if (!content) {
            return res.status(404).json({ error: 'Document not found' });
        }

        res.json({ content, docName });
    } catch (error) {
        res.status(500).json({ error: 'Failed to load document' });
    }
});

app.put('/api/documents/:docName', async (req, res) => {
    try {
        const { docName } = req.params;
        const { content, committer } = req.body;

        // Write to file
        const filePath = path.join(DOCS_PATH, docName);
        await fs.writeFile(filePath, content, 'utf8');

        // Git commit
        const git = simpleGit(DOCS_PATH);
        await git.add(docName);
        await git.commit(`Update ${docName}`, {
            '--author': `${committer || 'Anonymous'} <>`
        });

        // Update state
        state.documents[docName] = content;

        // Broadcast update
        broadcast({
            type: 'document_update',
            doc: docName,
            content,
            committer
        });

        res.json({ success: true });
    } catch (error) {
        console.error('Error updating document:', error);
        res.status(500).json({ error: 'Failed to update document' });
    }
});

app.get('/api/documents/:docName/history', async (req, res) => {
    try {
        const { docName } = req.params;
        const git = simpleGit(DOCS_PATH);
        const log = await git.log({ file: docName });

        const history = log.all.map(commit => ({
            hash: commit.hash,
            message: commit.message,
            author: commit.author_name,
            date: commit.date,
            diff: commit.hash.substring(0, 7)
        }));

        res.json({ history });
    } catch (error) {
        res.status(500).json({ error: 'Failed to load history' });
    }
});

// ============================================
// PROPOSAL ROUTES
// ============================================

app.get('/api/proposals', (req, res) => {
    res.json({ proposals: state.proposals });
});

app.post('/api/proposals', async (req, res) => {
    try {
        const proposal = req.body;

        // Validate
        if (!proposal.title || !proposal.type) {
            return res.status(400).json({ error: 'Missing required fields' });
        }

        if (proposal.stake < 1000) {
            return res.status(400).json({ error: 'Minimum stake is 1000 BLF' });
        }

        // Store proposal
        state.proposals[proposal.id] = proposal;

        // Add to consensus
        state.consensus.items.push({
            id: proposal.id,
            title: proposal.title,
            description: proposal.rationale || proposal.diff?.substring(0, 100),
            status: 'pending',
            deadline: Date.now() + (7 * 24 * 60 * 60 * 1000), // 7 days
            votesFor: proposal.stake,
            votesAgainst: 0,
            votesAbstain: 0
        });

        // Broadcast
        broadcast({
            type: 'new_proposal',
            proposal
        });

        res.json({ success: true, proposal });
    } catch (error) {
        res.status(500).json({ error: 'Failed to create proposal' });
    }
});

app.get('/api/proposals/:proposalId', (req, res) => {
    const { proposalId } = req.params;
    const proposal = state.proposals[proposalId];

    if (!proposal) {
        return res.status(404).json({ error: 'Proposal not found' });
    }

    res.json({ proposal });
});

// ============================================
// VOTING ROUTES
// ============================================

app.post('/api/vote', async (req, res) => {
    try {
        const { proposalId, voter, direction, stake } = req.body;

        const proposal = state.proposals[proposalId];
        if (!proposal) {
            return res.status(404).json({ error: 'Proposal not found' });
        }

        // Check if already voted
        if (proposal.voters[voter]) {
            return res.status(400).json({ error: 'Already voted' });
        }

        // Record vote
        proposal.voters[voter] = { direction, stake, timestamp: Date.now() };

        // Update totals
        if (direction === 'for') {
            proposal.votesFor += stake;
        } else if (direction === 'against') {
            proposal.votesAgainst += stake;
        } else {
            proposal.votesAbstain = (proposal.votesAbstain || 0) + stake;
        }

        proposal.totalStake += stake;

        // Check consensus
        const totalVotes = proposal.votesFor + proposal.votesAgainst + (proposal.votesAbstain || 0);
        const quorumMet = totalVotes >= (state.consensus.totalStake * CONFIG.QUORUM_PCT);

        if (quorumMet && proposal.votesFor > proposal.votesAgainst) {
            // Proposal approved - apply changes
            await applyProposal(proposal);
            proposal.status = 'approved';
        } else if (proposal.votesAgainst > proposal.votesFor) {
            proposal.status = 'rejected';
        }

        // Broadcast
        broadcast({
            type: 'vote_cast',
            proposalId,
            proposal,
            direction,
            voter
        });

        res.json({ success: true, proposal });
    } catch (error) {
        console.error('Voting error:', error);
        res.status(500).json({ error: 'Failed to cast vote' });
    }
});

// ============================================
// CONSENSUS ROUTES
// ============================================

app.get('/api/consensus', (req, res) => {
    // Calculate consensus state
    const totalVotes = Object.values(state.proposals).reduce((sum, p) =>
        sum + (p.votesFor || 0) + (p.votesAgainst || 0), 0
    );

    state.consensus.totalVotes = totalVotes;
    state.consensus.items = Object.values(state.proposals)
        .filter(p => p.status === 'pending')
        .map(p => ({
            id: p.id,
            title: p.title,
            description: p.rationale || 'No description',
            status: p.status,
            deadline: new Date(p.createdAt + CONFIG.VOTING_PERIOD),
            votesFor: p.votesFor,
            votesAgainst: p.votesAgainst
        }));

    res.json(state.consensus);
});

// ============================================
// AI CHAT ROUTES
// ============================================

// AI Provider Configuration
const AI_PROVIDERS = {
    anthropic: {
        name: 'Anthropic Claude',
        baseUrl: 'https://api.anthropic.com/v1/messages',
        models: {
            'claude-sonnet-4-20250514': { name: 'Claude Sonnet 4', maxTokens: 200000, contextWindow: 200000 },
            'claude-3-5-sonnet-20241022': { name: 'Claude 3.5 Sonnet', maxTokens: 200000, contextWindow: 200000 },
            'claude-3-5-haiku-20241022': { name: 'Claude 3.5 Haiku', maxTokens: 200000, contextWindow: 200000 },
            'claude-3-opus-20240229': { name: 'Claude 3 Opus', maxTokens: 200000, contextWindow: 200000 }
        },
        headers: (apiKey) => ({
            'x-api-key': apiKey,
            'anthropic-version': '2023-06-01',
            'content-type': 'application/json'
        })
    },
    openai: {
        name: 'OpenAI GPT',
        baseUrl: 'https://api.openai.com/v1/chat/completions',
        models: {
            'gpt-4o': { name: 'GPT-4o', maxTokens: 128000, contextWindow: 128000 },
            'gpt-4o-mini': { name: 'GPT-4o Mini', maxTokens: 128000, contextWindow: 128000 },
            'gpt-4-turbo': { name: 'GPT-4 Turbo', maxTokens: 128000, contextWindow: 128000 },
            'gpt-3.5-turbo': { name: 'GPT-3.5 Turbo', maxTokens: 16385, contextWindow: 16385 }
        },
        headers: (apiKey) => ({
            'Authorization': `Bearer ${apiKey}`,
            'content-type': 'application/json'
        })
    },
    openrouter: {
        name: 'OpenRouter',
        baseUrl: 'https://openrouter.ai/api/v1/chat/completions',
        models: {
            'anthropic/claude-sonnet-4': { name: 'Claude Sonnet 4 (via OpenRouter)', maxTokens: 200000, contextWindow: 200000 },
            'anthropic/claude-3.5-sonnet': { name: 'Claude 3.5 Sonnet (via OpenRouter)', maxTokens: 200000, contextWindow: 200000 },
            'openai/gpt-4o': { name: 'GPT-4o (via OpenRouter)', maxTokens: 128000, contextWindow: 128000 },
            'google/gemini-pro-1.5': { name: 'Gemini Pro 1.5 (via OpenRouter)', maxTokens: 1000000, contextWindow: 1000000 },
            'meta-llama/llama-3.1-70b-instruct': { name: 'Llama 3.1 70B (via OpenRouter)', maxTokens: 131072, contextWindow: 131072 }
        },
        headers: (apiKey) => ({
            'Authorization': `Bearer ${apiKey}`,
            'content-type': 'application/json',
            'HTTP-Referer': 'https://finallica.io',
            'X-Title': 'Finallica Documentation'
        })
    },
    groq: {
        name: 'Groq',
        baseUrl: 'https://api.groq.com/openai/v1/chat/completions',
        models: {
            'llama-3.3-70b-versatile': { name: 'Llama 3.3 70B', maxTokens: 131072, contextWindow: 131072 },
            'llama-3.1-70b-versatile': { name: 'Llama 3.1 70B', maxTokens: 131072, contextWindow: 131072 },
            'mixtral-8x7b-32768': { name: 'Mixtral 8x7b', maxTokens: 32768, contextWindow: 32768 }
        },
        headers: (apiKey) => ({
            'Authorization': `Bearer ${apiKey}`,
            'content-type': 'application/json'
        })
    }
};

// API Key Management (with rotation)
class APIKeyManager {
    constructor() {
        this.keys = this.loadKeys();
        this.currentIndex = {};
        this.usageStats = {};
        this.failedKeys = new Set();
    }

    loadKeys() {
        const keys = {
            anthropic: (process.env.ANTHROPIC_API_KEYS || '').split(',').filter(k => k.trim()),
            openai: (process.env.OPENAI_API_KEYS || '').split(',').filter(k => k.trim()),
            openrouter: (process.env.OPENROUTER_API_KEYS || '').split(',').filter(k => k.trim()),
            groq: (process.env.GROQ_API_KEYS || '').split(',').filter(k => k.trim())
        };
        // Support single key format too
        if (process.env.ANTHROPIC_API_KEY && !keys.anthropic.length) {
            keys.anthropic = [process.env.ANTHROPIC_API_KEY];
        }
        if (process.env.OPENAI_API_KEY && !keys.openai.length) {
            keys.openai = [process.env.OPENAI_API_KEY];
        }
        if (process.env.OPENROUTER_API_KEY && !keys.openrouter.length) {
            keys.openrouter = [process.env.OPENROUTER_API_KEY];
        }
        if (process.env.GROQ_API_KEY && !keys.groq.length) {
            keys.groq = [process.env.GROQ_API_KEY];
        }
        return keys;
    }

    getNextKey(provider) {
        const providerKeys = this.keys[provider];
        if (!providerKeys || providerKeys.length === 0) {
            return null;
        }

        // Skip failed keys
        const availableKeys = providerKeys.filter(k => !this.failedKeys.has(k));
        if (availableKeys.length === 0) {
            // Reset failed keys and try again
            this.failedKeys.clear();
            return providerKeys[0];
        }

        if (!this.currentIndex[provider]) {
            this.currentIndex[provider] = 0;
        }

        // Round-robin selection
        const key = availableKeys[this.currentIndex[provider] % availableKeys.length];
        this.currentIndex[provider] = (this.currentIndex[provider] + 1) % availableKeys.length;

        return key;
    }

    markFailed(key) {
        this.failedKeys.add(key);
    }

    recordUsage(provider, model, inputTokens, outputTokens) {
        const key = `${provider}:${model}`;
        if (!this.usageStats[key]) {
            this.usageStats[key] = { requests: 0, inputTokens: 0, outputTokens: 0 };
        }
        this.usageStats[key].requests++;
        this.usageStats[key].inputTokens += inputTokens;
        this.usageStats[key].outputTokens += outputTokens;
    }

    getStats() {
        return this.usageStats;
    }

    hasKeys(provider) {
        return this.keys[provider] && this.keys[provider].length > 0;
    }

    getAvailableProviders() {
        return Object.entries(this.keys)
            .filter(([_, keys]) => keys.length > 0)
            .map(([provider, _]) => provider);
    }
}

const keyManager = new APIKeyManager();

// Default model configuration
const DEFAULT_MODEL = process.env.AI_MODEL || 'claude-3-5-sonnet-20241022';
const DEFAULT_PROVIDER = process.env.AI_PROVIDER || 'anthropic';

// Chat endpoint with model selection
app.post('/api/chat', async (req, res) => {
    try {
        const { message, context, provider, model, stream = false } = req.body;

        const selectedProvider = provider || DEFAULT_PROVIDER;
        const selectedModel = model || DEFAULT_MODEL;

        // Check if provider has keys
        if (!keyManager.hasKeys(selectedProvider)) {
            return res.status(400).json({
                error: `No API keys configured for provider: ${selectedProvider}`,
                availableProviders: keyManager.getAvailableProviders()
            });
        }

        // Build system prompt with document context
        const systemPrompt = buildSystemPrompt();

        // Get conversation history from context if available
        const messages = context && context.history ? context.history : [];

        // Call the appropriate AI provider
        const response = await callAIProvider(selectedProvider, selectedModel, systemPrompt, message, messages);

        res.json({
            response: response.content,
            model: response.model,
            provider: selectedProvider,
            tokensUsed: response.tokens
        });
    } catch (error) {
        console.error('AI chat error:', error);
        res.status(500).json({
            error: error.message,
            fallback: await generateDemoResponse(message)
        });
    }
});

// Get available models endpoint
app.get('/api/ai/models', (req, res) => {
    const available = {};
    const providers = keyManager.getAvailableProviders();

    for (const provider of providers) {
        available[provider] = {
            name: AI_PROVIDERS[provider].name,
            models: AI_PROVIDERS[provider].models
        };
    }

    res.json({ providers: available, defaults: { provider: DEFAULT_PROVIDER, model: DEFAULT_MODEL } });
});

// Get AI usage stats endpoint
app.get('/api/ai/stats', (req, res) => {
    res.json({ stats: keyManager.getStats(), availableProviders: keyManager.getAvailableProviders() });
});

// ============================================
// PRIVACY ROUTES
// ============================================

// Initialize privacy service if enabled
let privacyService = null;

if (CONFIG.PRIVACY_ENABLED && CONFIG.RPC_URL) {
    try {
        privacyService = new PrivacyService({
            rpcUrl: CONFIG.RPC_URL,
            privacyRouterAddress: CONFIG.PRIVACY_ROUTER_ADDRESS,
            relayerUrl: CONFIG.RELAYER_URL,
            tornadoInstances: {
                ETH_0_1: process.env.TORNADO_ETH_0_1,
                ETH_1: process.env.TORNADO_ETH_1,
                ETH_10: process.env.TORNADO_ETH_10,
                ETH_100: process.env.TORNADO_ETH_100,
                USDC_100: process.env.TORNADO_USDC_100,
                BLF_100: process.env.TORNADO_BLF_100,
                BLF_1000: process.env.TORNADO_BLF_1000
            }
        });
        console.log('Privacy service initialized');
    } catch (error) {
        console.error('Failed to initialize privacy service:', error.message);
    }
}

// Get privacy service status
app.get('/api/privacy/status', (req, res) => {
    res.json({
        enabled: CONFIG.PRIVACY_ENABLED,
        available: privacyService !== null,
        routerAddress: CONFIG.PRIVACY_ROUTER_ADDRESS,
        relayerUrl: CONFIG.RELAYER_URL || null
    });
});

// Get available privacy pools
app.get('/api/privacy/pools', async (req, res) => {
    if (!privacyService) {
        return res.status(503).json({ error: 'Privacy service not available' });
    }

    try {
        const pools = await privacyService.getAvailablePools();
        res.json({ pools });
    } catch (error) {
        console.error('Error fetching pools:', error);
        res.status(500).json({ error: 'Failed to fetch pools' });
    }
});

// Generate a privacy note
app.post('/api/privacy/note', async (req, res) => {
    if (!privacyService) {
        return res.status(503).json({ error: 'Privacy service not available' });
    }

    try {
        const { token, amount } = req.body;

        if (!token || !amount) {
            return res.status(400).json({ error: 'Token and amount are required' });
        }

        const note = await privacyService.generateNote(token, amount);

        // Broadcast to connected clients
        broadcast({
            type: 'privacy_note_generated',
            token,
            amount,
            poolId: note.poolId
        });

        res.json({ success: true, note });
    } catch (error) {
        console.error('Note generation error:', error);
        res.status(500).json({ error: error.message });
    }
});

// Validate a privacy note
app.post('/api/privacy/note/validate', async (req, res) => {
    if (!privacyService) {
        return res.status(503).json({ error: 'Privacy service not available' });
    }

    try {
        const { note } = req.body;

        if (!note) {
            return res.status(400).json({ error: 'Note string is required' });
        }

        const isValid = privacyService.validateNote(note);
        const parsed = privacyService.parseNote(note);

        res.json({
            success: true,
            valid: isValid,
            token: parsed.token,
            amount: parsed.amount
        });
    } catch (error) {
        res.json({ success: true, valid: false, error: error.message });
    }
});

// Private deposit
app.post('/api/privacy/deposit', async (req, res) => {
    if (!privacyService) {
        return res.status(503).json({ error: 'Privacy service not available' });
    }

    try {
        const { note, privateKey, useRouter } = req.body;

        if (!note) {
            return res.status(400).json({ error: 'Note is required' });
        }

        // Parse the note if it's a string, otherwise use as-is
        const noteData = typeof note === 'string'
            ? { ...privacyService.parseNote(note), fullNote: note }
            : note;

        const result = await privacyService.deposit(
            noteData,
            privateKey,
            { useRouter }
        );

        // Broadcast deposit event
        broadcast({
            type: 'privacy_deposit',
            txHash: result.txHash,
            poolId: noteData.poolId
        });

        res.json({ success: true, result });
    } catch (error) {
        console.error('Deposit error:', error);
        res.status(500).json({ error: error.message });
    }
});

// Calculate fees for privacy transaction
app.get('/api/privacy/fees', async (req, res) => {
    if (!privacyService) {
        return res.status(503).json({ error: 'Privacy service not available' });
    }

    try {
        const { token, amount } = req.query;

        if (!token || !amount) {
            return res.status(400).json({ error: 'Token and amount are required' });
        }

        const fees = privacyService.calculateFees(token, amount);
        res.json({ success: true, fees });
    } catch (error) {
        res.status(500).json({ error: error.message });
    }
});

// Get withdrawal status
app.get('/api/privacy/withdrawal/:txHash', async (req, res) => {
    if (!privacyService) {
        return res.status(503).json({ error: 'Privacy service not available' });
    }

    try {
        const status = await privacyService.getWithdrawalStatus(req.params.txHash);
        res.json({ success: true, status });
    } catch (error) {
        res.status(500).json({ error: error.message });
    }
});

// ============================================
// AI CHAT FUNCTIONS
// ============================================

function buildSystemPrompt() {
    const docList = Object.keys(state.documents).map(d => `- ${d}`).join('\n');

    // Get full content of key documents for context
    const keyDocs = ['README.md', 'ARCHITECTURE_OVERVIEW.md', 'CRYPTOGRAPHIC_DETAILS.md'];
    const relevantContext = keyDocs
        .filter(doc => state.documents[doc])
        .map(doc => `## ${doc}\n${state.documents[doc].substring(0, 3000)}`)
        .join('\n\n---\n\n');

    return `You are Finallica AI, an expert assistant for the Finallica global financial privacy network.

Your role is to help users understand the architecture, protocols, and technical specifications of Finallica.

Key concepts:
- Finallica is a global, trust-minimized payment overlay network with 127 jurisdictional shards
- ~12,000 Validator-Routers (VRs) form a clique mesh topology
- HotStuff BFT consensus with 8 notaries achieving 200ms finality
- Cryptography: BLS12-381 for signatures, Noise_XX for handshakes, ChaCha20-Poly1305 for encryption
- 3-hop payment channels with HTLC locks for privacy
- Pedersen commitments and Bulletproofs+ for amount hiding
- Anonymity set of ~1,200 users per transaction

Relevant documentation:
${relevantContext}

Available documents:
${docList}

Answer questions clearly and technically. Use code examples when helpful. Reference specific documents when citing information.
`;
}

async function callAIProvider(provider, model, systemPrompt, userMessage, history = []) {
    const providerConfig = AI_PROVIDERS[provider];
    const apiKey = keyManager.getNextKey(provider);

    if (!apiKey) {
        throw new Error(`No API key available for provider: ${provider}`);
    }

    // Build messages array
    let messages = [];
    let apiUrl = providerConfig.baseUrl;

    if (provider === 'anthropic') {
        // Anthropic format
        messages = [
            { role: 'user', content: `${systemPrompt}\n\nUser: ${userMessage}` }
        ];

        // Add conversation history if available
        if (history.length > 0) {
            const historyText = history.map(h => `${h.role}: ${h.content}`).join('\n\n');
            messages[0].content = `${systemPrompt}\n\nConversation history:\n${historyText}\n\nCurrent question: ${userMessage}`;
        }

        const requestBody = {
            model: model,
            max_tokens: 4096,
            messages: messages
        };

        const response = await fetch(apiUrl, {
            method: 'POST',
            headers: providerConfig.headers(apiKey),
            body: JSON.stringify(requestBody)
        });

        if (!response.ok) {
            const error = await response.text();
            if (response.status === 401 || response.status === 403) {
                keyManager.markFailed(apiKey);
            }
            throw new Error(`Anthropic API error: ${response.status} - ${error}`);
        }

        const data = await response.json();
        keyManager.recordUsage(provider, model, data.usage?.input_tokens || 0, data.usage?.output_tokens || 0);

        return {
            content: data.content[0].text,
            model: model,
            tokens: {
                input: data.usage?.input_tokens || 0,
                output: data.usage?.output_tokens || 0
            }
        };

    } else {
        // OpenAI-compatible format (OpenAI, OpenRouter, Groq)
        messages = [
            { role: 'system', content: systemPrompt },
            ...history.slice(-10), // Last 10 messages
            { role: 'user', content: userMessage }
        ];

        const requestBody = {
            model: model,
            messages: messages,
            max_tokens: 4096,
            temperature: 0.7
        };

        const response = await fetch(apiUrl, {
            method: 'POST',
            headers: providerConfig.headers(apiKey),
            body: JSON.stringify(requestBody)
        });

        if (!response.ok) {
            const error = await response.text();
            if (response.status === 401 || response.status === 403) {
                keyManager.markFailed(apiKey);
            }
            throw new Error(`${providerConfig.name} API error: ${response.status} - ${error}`);
        }

        const data = await response.json();
        keyManager.recordUsage(provider, model, data.usage?.prompt_tokens || 0, data.usage?.completion_tokens || 0);

        return {
            content: data.choices[0].message.content,
            model: model,
            tokens: {
                input: data.usage?.prompt_tokens || 0,
                output: data.usage?.completion_tokens || 0
            }
        };
    }
}

// Demo fallback response (when no API keys available)
async function generateDemoResponse(message) {
    return await generateAIResponse(message, null, '');
}

async function generateAIResponse(message, context, docContext) {
    // Simple demo response generator
    const lower = message.toLowerCase();

    // Check for document queries
    if (lower.includes('readme') || lower.includes('overview') || lower.includes('what is')) {
        return `Finallica is a global, trust-minimized payment overlay network that adapts Tor's anonymity architecture for financial value transfer.

**Key characteristics:**
- 127 jurisdictional shards with ~12,000 Validator-Routers (VRs)
- HotStuff BFT consensus with 8 notaries (200ms finality)
- BLS12-381 stake attestations, Noise_XX handshakes, ChaCha20-Poly1305 encryption
- 3-hop payment channels with HTLC locks
- Pedersen commitments for amount hiding
- Anonymity set of ~1,200 users

**Current metrics:**
- Total payments per epoch: 38.4M
- Transaction value: $4.27B
- Average payment: $111.20
- Estimated users: 4.2M daily

Would you like more details on any specific aspect?`;
    }

    if (lower.includes('architecture') || lower.includes('topology')) {
        return `## Network Architecture

The Finallica network operates as a 127-shard topology:

**Components:**
1. **Global Consensus Layer** (8 Notaries) - Sign state roots every 10 seconds
2. **Shards** (127) - Each with ~2,400 VRs in clique mesh topology
3. **Validator-Routers** (12,000 total):
   - Guard VRs (Entry): Top 30% by stake, persistent
   - Middle VRs: Pure forwarding
   - Settlement Executors (Exit): Connect to SWIFT/ACH/BTC
4. **Cross-Shard Bridges** (15,240 links): Top 5% stake in each shard

**Data Plane:** DPDK UDP on port 31337 (kernel bypass)
**Control Plane:** TLS 1.3 on port 31338`;
    }

    if (lower.includes('consensus') || lower.includes('bft')) {
        return `## HotStuff BFT Consensus

Finallica uses a 4-phase HotStuff BFT protocol:

**Phases:**
1. **PREPARE** (50ms RTT) - Leader proposes block
2. **PRE-COMMIT** (50ms RTT) - Nodes lock block
3. **COMMIT** (50ms RTT) - Nodes commit to ledger
4. **DECIDE** (50ms RTT) - Notaries sign state root

**Finality:** 200ms total (4 RTTs  50ms)

**Quorum:** 67% threshold (1,605 of 2,400 VRs per shard)

**State Root:** Published every 10 seconds by 8 notaries with BLS aggregated signatures`;
    }

    if (lower.includes('cryptography') || lower.includes('encryption') || lower.includes('bls')) {
        return `## Cryptographic Primitives

**Asymmetric:**
- **BLS12-381** - Stake attestations and signatures (48-byte pubkey, 96-byte sig)
- **X25519** - Noise_XX handshake ECDH
- **Ed25519** - Rekey signatures

**Symmetric:**
- **ChaCha20-Poly1305** - Payment cell encryption (1.2s per hop)
- **BLAKE2s** - Hash function for key derivation

**Commitments:**
- **Pedersen Commitment**: C = v*G + b*H (33 bytes compressed)
- **Bulletproofs+**: Range proofs (700 bytes, 5-10ms verify)

**Performance:**
- Cell processing: 0.8s per hop
- BLS batch verify (64): 0.15ms
- Channel build: 127-340ms`;
    }

    if (lower.includes('fee') || lower.includes('cost')) {
        return `## Fee Structure

**On a $100 payment:**

| Component | Fee | Notes |
|-----------|-----|-------|
| Guard VR (2 bps) | $0.020 | Stake: 15.7M BLF |
| Middle VR (3 bps) | $0.030 | Stake: 6.3M BLF |
| Exit SE (25 bps) | $0.250 | SWIFT rail |
| SWIFT Bank | $0.250 | Intermediary fees |
| Liquidity (85% util) | $0.030 | Dynamic |
| Padding overhead | $0.352 | Privacy cost |
| **Total** | **$0.932** | **0.93%** |

**Beneficiary receives:** $99.068

**Settlement time:** 1.8 days (SWIFT average)`;
    }

    if (lower.includes('security') || lower.includes('attack')) {
        return `## Security Analysis

**Attack Vectors:**

| Attack | Success Probability | Defense |
|--------|---------------------|---------|
| Timing Correlation | 12% | Padding + quantization |
| Guard Discovery | 0.31% per guard | 90-day rotation |
| Exit Compromise | 10% (20/200 exits) | 2-of-3 redundancy |
| Sybil Attack | Low | Stake^0.7 weighting |

**Anonymity Set:** ~1,200 users

**Staking Requirements:**
- VR: 500K BLF (~$2.25M)
- Settlement Executor: 2M BLF (~$9M)
- Notary: 10M BLF (~$45M)

**Slashing:**
- Double-sign: 100%
- Censorship: 10%
- Invalid settlement: 5%`;
    }

    if (lower.includes('help') || lower.includes('command')) {
        return `**Available Commands:**

- View documents: Click on any document in the sidebar
- Edit documents: Click "Edit" button, then "Propose Change"
- Create proposal: Click "Propose Change" and fill out the form
- Vote on proposals: Go to "Proposals" tab and click "Vote"
- Connect wallet: Click "Connect Wallet" (MetaMask or demo mode)

**Ask me about:**
- Architecture and topology
- Consensus mechanism (HotStuff BFT)
- Cryptographic primitives
- Fee structure
- Security analysis
- Protocol specifications`;
    }

    // Default response
    return `I can help you understand the Finallica system. You can ask me about:

- **Architecture** - Network topology, shards, VR roles
- **Consensus** - HotStuff BFT, notaries, state roots
- **Cryptography** - BLS signatures, encryption, commitments
- **Fees** - Cost breakdown, staking rewards
- **Security** - Attack vectors, defenses, anonymity

You said: "${message}"

For the most accurate information, please refer to the documentation in the sidebar.`;
}

// ============================================
// ACTIVITY ROUTES
// ============================================

app.post('/api/activity', (req, res) => {
    const activity = req.body;
    state.activity.unshift(activity);
    if (state.activity.length > 1000) state.activity.pop();
    res.json({ success: true });
});

app.get('/api/activity', (req, res) => {
    res.json({ activity: state.activity.slice(0, 100) });
});

// ============================================
// GIT ROUTES
// ============================================

app.post('/api/git/commit', async (req, res) => {
    try {
        const { docName, content, message, author } = req.body;

        const git = simpleGit(DOCS_PATH);
        await fs.writeFile(path.join(DOCS_PATH, docName), content);
        await git.add(docName);
        const result = await git.commit(message, {
            '--author': `${author || 'Anonymous'} <>`
        });

        res.json({ success: true, result });
    } catch (error) {
        res.status(500).json({ error: error.message });
    }
});

app.get('/api/git/status', async (req, res) => {
    try {
        const git = simpleGit(DOCS_PATH);
        const status = await git.status();
        const log = await git.log({ maxCount: 10 });

        res.json({ status, log: log.all });
    } catch (error) {
        res.status(500).json({ error: error.message });
    }
});

app.post('/api/git/merge', async (req, res) => {
    try {
        const { proposalId } = req.body;
        const proposal = state.proposals[proposalId];

        if (!proposal || proposal.status !== 'approved') {
            return res.status(400).json({ error: 'Proposal not approved' });
        }

        // Apply diff
        await applyProposal(proposal);

        res.json({ success: true });
    } catch (error) {
        res.status(500).json({ error: error.message });
    }
});

// ============================================
// UTILITY FUNCTIONS
// ============================================

async function loadDocuments() {
    const files = await fs.readdir(DOCS_PATH);
    const mdFiles = files.filter(f => f.endsWith('.md'));

    for (const file of mdFiles) {
        const content = await fs.readFile(path.join(DOCS_PATH, file), 'utf8');
        state.documents[file] = content;
    }
}

async function applyProposal(proposal) {
    if (proposal.type === 'document_edit' && proposal.diff) {
        const docPath = path.join(DOCS_PATH, proposal.document);
        const currentContent = await fs.readFile(docPath, 'utf8');
        const newContent = applyDiff(currentContent, proposal.diff);

        await fs.writeFile(docPath, newContent, 'utf8');
        state.documents[proposal.document] = newContent;

        // Git commit
        const git = simpleGit(DOCS_PATH);
        await git.add(proposal.document);
        await git.commit(`Merge proposal #${proposal.id.substring(0, 8)}: ${proposal.title}`);

        // Broadcast
        broadcast({
            type: 'proposal_merged',
            proposalId: proposal.id,
            document: proposal.document
        });
    }
}

function applyDiff(content, diffStr) {
    const lines = content.split('\n');
    const diffLines = diffStr.split('\n');

    let result = [...lines];
    let lineOffset = 0;

    for (const diffLine of diffLines) {
        if (diffLine.startsWith('@@')) {
            const match = diffLine.match(/@@ -(\d+),?\d* \+(\d+),?\d* @@/);
            if (match) {
                lineOffset = parseInt(match[1]) - parseInt(match[2]) - 1;
            }
        } else if (diffLine.startsWith('+')) {
            result.splice(lineOffset, 0, diffLine.substring(1));
            lineOffset++;
        } else if (diffLine.startsWith('-')) {
            result.splice(lineOffset, 1);
        } else {
            lineOffset++;
        }
    }

    return result.join('\n');
}

function broadcast(data) {
    const message = JSON.stringify(data);

    wss.clients.forEach(client => {
        if (client.readyState === WebSocket.OPEN) {
            client.send(message);
        }
    });
}

// ============================================
// WEBSOCKET HANDLER
// ============================================

wss.on('connection', (ws) => {
    state.clients.add(ws);

    // Send initial state
    ws.send(JSON.stringify({
        type: 'init',
        documents: Object.keys(state.documents),
        proposals: state.proposals,
        consensus: state.consensus
    }));

    ws.on('message', async (data) => {
        try {
            const message = JSON.parse(data);

            switch (message.type) {
                case 'subscribe':
                    ws.subscriptions = message.channels || [];
                    break;

                case 'ping':
                    ws.send(JSON.stringify({ type: 'pong' }));
                    break;
            }
        } catch (error) {
            console.error('WebSocket message error:', error);
        }
    });

    ws.on('close', () => {
        state.clients.delete(ws);
    });
});

// ============================================
// START SERVER
// ============================================

async function start() {
    // Initialize multi-repository system
    await initializeRepositorySystem();

    // Load documents on startup
    await loadDocuments();

    // Initialize demo proposals
    initializeDemoProposals();

    server.listen(PORT, () => {
        console.log(`

           Finallica Documentation System                      
                                                              
  Server running on: http://localhost:${PORT}                      
  Frontend: http://localhost:8080                            
                                                              
  Features:                                                   
   Multi-repository documentation platform                   
   Document management with Git integration                  
   Proposal system with blockchain voting                    
   AI chat assistant                                         
   Real-time collaboration via WebSocket                     
   Consensus voting on changes                               
                                                              
  Press Ctrl+C to stop                                        

        `);
    });
}

function initializeDemoProposals() {
    // Demo proposals for testing
    const demoProposals = [
        {
            id: '0x1234567890abcdef1234567890abcdef12345678',
            type: 'protocol_change',
            title: 'Increase HTLC Max Per Channel to 1000',
            document: 'PROTOCOL_SPECIFICATION.md',
            diff: '+ HTLC_MAX_PER_CHANNEL 1000',
            rationale: 'Current limit of 483 HTLCs constrains throughput. Increasing to 1000 would improve capacity.',
            stake: 50000,
            proposer: '0xdemo1234567890abcdef1234567890abcdef',
            createdAt: Date.now() - 86400000,
            status: 'pending',
            votesFor: 8500000,
            votesAgainst: 1200000,
            voters: {}
        },
        {
            id: '0xabcdef1234567890abcdef1234567890abcdef12',
            type: 'parameter_update',
            title: 'Reduce Guard Rotation to 60 Days',
            document: 'SECURITY_ANALYSIS.md',
            diff: '- GUARD_LIFETIME 7776000  # 90 days\n+ GUARD_LIFETIME 5184000   # 60 days',
            rationale: 'Faster rotation improves security against guard discovery attacks.',
            stake: 75000,
            proposer: '0xdemo0987654321fedcba0987654321fedcba',
            createdAt: Date.now() - 172800000,
            status: 'pending',
            votesFor: 12345000,
            votesAgainst: 2100000,
            voters: {}
        }
    ];

    for (const proposal of demoProposals) {
        state.proposals[proposal.id] = proposal;
    }

    // Add to consensus items
    state.consensus.items = Object.values(state.proposals)
        .filter(p => p.status === 'pending')
        .map(p => ({
            id: p.id,
            title: p.title,
            description: p.rationale,
            status: p.status,
            deadline: new Date(p.createdAt + CONFIG.VOTING_PERIOD),
            votesFor: p.votesFor,
            votesAgainst: p.votesAgainst
        }));
}

start();
</file>

<file path="backend/services/git-sync.js">
// Git Sync Service for Finallica Multi-Repository Platform
// Handles cloning, pulling, and indexing Git repositories

const simpleGit = require('simple-git');
const fs = require('fs').promises;
const path = require('path');
const crypto = require('crypto');

class GitSyncService {
    constructor(db) {
        this.db = db;
        this.reposDir = db.getReposPath();
    }

    /**
     * Generate a unique ID
     */
    generateId() {
        return crypto.randomBytes(16).toString('hex');
    }

    /**
     * Hash content for change detection
     */
    hashContent(content) {
        return crypto.createHash('sha256').update(content).digest('hex');
    }

    /**
     * Get the local path for a repository
     */
    getRepoPath(repoId) {
        return path.join(this.reposDir, repoId);
    }

    /**
     * Get authenticated clone URL
     */
    getAuthenticatedUrl(repo, authToken) {
        if (!repo.is_private || !authToken) {
            return repo.url;
        }

        try {
            const url = new URL(repo.url);

            switch (repo.source_type) {
                case 'github':
                    url.username = authToken.token_value_encrypted; // Will be decrypted by auth service
                    url.password = 'x-oauth-basic';
                    break;
                case 'gitlab':
                    url.username = 'oauth2';
                    url.password = authToken.token_value_encrypted;
                    break;
                case 'bitbucket':
                    url.username = authToken.token_value_encrypted;
                    url.password = 'x-token-auth';
                    break;
                default:
                    // For custom git URLs with token
                    url.username = authToken.token_value_encrypted;
                    url.password = 'x-oauth-basic';
            }

            return url.toString();
        } catch (e) {
            // If URL parsing fails, return original
            return repo.url;
        }
    }

    /**
     * Clone a repository
     */
    async cloneRepository(repo, authToken = null) {
        const repoPath = this.getRepoPath(repo.id);
        const cloneUrl = this.getAuthenticatedUrl(repo, authToken);

        try {
            // Create parent directory
            await fs.mkdir(path.dirname(repoPath), { recursive: true });

            const branch = repo.branch || 'main';
            const git = simpleGit();

            await git.clone(cloneUrl, repoPath, [
                '--branch',
                branch,
                '--depth',
                '1',
                '--single-branch'
            ]);

            return { success: true, path: repoPath };
        } catch (error) {
            throw new Error(`Clone failed: ${error.message}`);
        }
    }

    /**
     * Pull latest changes from a repository
     */
    async pullRepository(repo, authToken = null) {
        const repoPath = this.getRepoPath(repo.id);

        try {
            const git = simpleGit(repoPath);

            // Fetch and reset to origin branch
            const branch = repo.branch || 'main';
            await git.fetch('origin', branch);
            await git.reset(['--hard', `origin/${branch}`]);

            return { success: true };
        } catch (error) {
            throw new Error(`Pull failed: ${error.message}`);
        }
    }

    /**
     * Get current commit hash
     */
    async getCurrentCommit(repoId) {
        const repoPath = this.getRepoPath(repoId);
        const git = simpleGit(repoPath);
        const log = await git.log({ maxCount: 1 });
        return log.latest ? log.latest.hash : null;
    }

    /**
     * Analyze changes since last sync
     */
    async analyzeChanges(repoId, lastCommitHash) {
        const repoPath = this.getRepoPath(repoId);
        const git = simpleGit(repoPath);

        const changes = {
            added: [],
            modified: [],
            removed: [],
            all: []
        };

        try {
            // Get diff with last commit
            const diff = await git.diff([lastCommitHash, 'HEAD']);

            // Parse diff to find changed files
            const lines = diff.split('\n');
            let currentFile = null;
            let changeType = null;

            for (const line of lines) {
                if (line.startsWith('diff --git')) {
                    // Extract filename
                    const match = line.match(/b\/(.+)$/);
                    if (match) {
                        currentFile = match[1];
                    }
                } else if (line.startsWith('new file')) {
                    changeType = 'added';
                } else if (line.startsWith('deleted file')) {
                    changeType = 'removed';
                } else if (line.startsWith('index')) {
                    if (changeType !== 'removed') {
                        changeType = 'modified';
                    }

                    if (currentFile && changeType) {
                        // Only track markdown and documentation files
                        if (this.isDocumentationFile(currentFile)) {
                            changes[changeType].push(currentFile);
                            changes.all.push({ path: currentFile, type: changeType });
                        }
                    }
                    currentFile = null;
                    changeType = null;
                }
            }
        } catch (error) {
            // If no previous commit, scan all files
            await this.scanAllFiles(repoId, changes);
        }

        return changes;
    }

    /**
     * Scan all files in repository (for initial clone)
     */
    async scanAllFiles(repoId, changes) {
        const repoPath = this.getRepoPath(repoId);

        async function walkDir(dir, baseDir = dir) {
            const entries = await fs.readdir(dir, { withFileTypes: true });

            for (const entry of entries) {
                const fullPath = path.join(dir, entry.name);

                // Skip common directories
                if (entry.isDirectory()) {
                    if (['node_modules', '.git', 'dist', 'build', '.next', 'target', 'vendor', '__pycache__'].includes(entry.name)) {
                        continue;
                    }
                    await walkDir(fullPath, baseDir);
                } else if (entry.isFile()) {
                    const relativePath = path.relative(baseDir, fullPath);
                    if (this.isDocumentationFile(relativePath)) {
                        changes.added.push(relativePath);
                        changes.all.push({ path: relativePath, type: 'added' });
                    }
                }
            }
        }

        await walkDir.call(this, repoPath, repoPath);
    }

    /**
     * Check if file is a documentation file
     */
    isDocumentationFile(filePath) {
        const docExtensions = ['.md', '.mdx', '.markdown', '.txt', '.rst', '.adoc'];
        const docDirs = ['docs', 'doc', 'documentation', 'guide', 'guides', 'readme'];

        const ext = path.extname(filePath).toLowerCase();
        const dirname = path.dirname(filePath).toLowerCase();

        return docExtensions.includes(ext) ||
               docDirs.some(d => dirname.includes(d)) ||
               path.basename(filePath).toLowerCase().startsWith('readme');
    }

    /**
     * Extract title from markdown content
     */
    extractTitle(content, filename) {
        // Try to find first heading
        const headingMatch = content.match(/^#\s+(.+)$/m);
        if (headingMatch) {
            return headingMatch[1].trim();
        }

        // Try to extract from frontmatter
        const frontmatterMatch = content.match(/^---\n([\s\S]+?)\n---/);
        if (frontmatterMatch) {
            const yaml = frontmatterMatch[1];
            const titleMatch = yaml.match(/title:\s*["']?([^"'\n]+)["']?/);
            if (titleMatch) {
                return titleMatch[1].trim();
            }
        }

        // Use filename as fallback
        return path.basename(filename, path.extname(filename));
    }

    /**
     * Index files from repository
     */
    async indexFiles(repoId, changes) {
        const repoPath = this.getRepoPath(repoId);
        const indexedFiles = [];

        // Clear old file records for this repo
        this.db.db.prepare('DELETE FROM repository_files WHERE repository_id = ?').run(repoId);

        for (const file of changes.all) {
            const filePath = path.join(repoPath, file.path);

            try {
                const content = await fs.readFile(filePath, 'utf8');
                const stats = await fs.stat(filePath);

                const indexedFile = {
                    id: this.generateId(),
                    repository_id: repoId,
                    path: file.path,
                    filename: path.basename(file.path),
                    extension: path.extname(file.path),
                    content_hash: this.hashContent(content),
                    size: stats.size,
                    title: this.extractTitle(content, file.path),
                    is_document: 1,
                    indexed_at: Math.floor(Date.now() / 1000)
                };

                this.db.db.prepare(`
                    INSERT INTO repository_files (
                        id, repository_id, path, filename, extension,
                        content_hash, size, title, is_document, indexed_at
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                `).run(
                    indexedFile.id,
                    indexedFile.repository_id,
                    indexedFile.path,
                    indexedFile.filename,
                    indexedFile.extension,
                    indexedFile.content_hash,
                    indexedFile.size,
                    indexedFile.title,
                    indexedFile.is_document,
                    indexedFile.indexed_at
                );

                indexedFiles.push(indexedFile);
            } catch (error) {
                console.error(`Failed to index file ${file.path}:`, error.message);
            }
        }

        return indexedFiles;
    }

    /**
     * Get repository statistics
     */
    async getStats(repoId) {
        const repoPath = this.getRepoPath(repoId);

        let fileCount = 0;
        let markdownCount = 0;
        let totalSize = 0;

        try {
            async function walkDir(dir, baseDir = dir) {
                const entries = await fs.readdir(dir, { withFileTypes: true });

                for (const entry of entries) {
                    const fullPath = path.join(dir, entry.name);

                    if (entry.isDirectory()) {
                        if (['node_modules', '.git', 'dist', 'build', '.next', 'target', 'vendor', '__pycache__', '.next'].includes(entry.name)) {
                            continue;
                        }
                        await walkDir(fullPath, baseDir);
                    } else if (entry.isFile()) {
                        const stats = await fs.stat(fullPath);
                        fileCount++;
                        totalSize += stats.size;

                        if (entry.name.toLowerCase().endsWith('.md') ||
                            entry.name.toLowerCase().endsWith('.markdown')) {
                            markdownCount++;
                        }
                    }
                }
            }

            await walkDir(repoPath, repoPath);
        } catch (error) {
            console.error('Failed to get stats:', error.message);
        }

        return {
            fileCount,
            markdownCount,
            totalSize
        };
    }

    /**
     * Main sync function - clones or pulls and indexes
     */
    async syncRepository(repo, authToken = null) {
        const startTime = Date.now();
        const result = {
            success: false,
            filesAdded: 0,
            filesModified: 0,
            filesDeleted: 0,
            commitHash: null,
            stats: null,
            error: null
        };

        try {
            const repoPath = this.getRepoPath(repo.id);
            const exists = await this.pathExists(repoPath);

            let previousCommit = repo.last_commit_hash;

            if (exists) {
                // Pull latest changes
                await this.pullRepository(repo, authToken);
            } else {
                // Clone repository
                await this.cloneRepository(repo, authToken);
            }

            // Get current commit
            const currentCommit = await this.getCurrentCommit(repo.id);
            result.commitHash = currentCommit;

            // Analyze changes
            const changes = await this.analyzeChanges(repo.id, previousCommit);
            result.filesAdded = changes.added.length;
            result.filesModified = changes.modified.length;
            result.filesDeleted = changes.removed.length;

            // Index files
            await this.indexFiles(repo.id, changes);

            // Get stats
            result.stats = await this.getStats(repo.id);

            result.success = true;
        } catch (error) {
            result.error = error.message;
        }

        result.duration = Date.now() - startTime;
        return result;
    }

    /**
     * Check if path exists
     */
    async pathExists(filePath) {
        try {
            await fs.access(filePath);
            return true;
        } catch {
            return false;
        }
    }

    /**
     * Delete a cloned repository
     */
    async deleteRepository(repoId) {
        const repoPath = this.getRepoPath(repoId);

        try {
            await fs.rm(repoPath, { recursive: true, force: true });
            return { success: true };
        } catch (error) {
            return { success: false, error: error.message };
        }
    }

    /**
     * Get file content from repository
     */
    async getFileContent(repoId, filePath) {
        const repoPath = this.getRepoPath(repoId);
        const fullPath = path.join(repoPath, filePath);

        try {
            const content = await fs.readFile(fullPath, 'utf8');
            return { success: true, content };
        } catch (error) {
            return { success: false, error: error.message };
        }
    }

    /**
     * List all files in a repository
     */
    async listFiles(repoId, dirPath = '') {
        const repoPath = this.getRepoPath(repoId);
        const scanPath = dirPath ? path.join(repoPath, dirPath) : repoPath;

        const files = [];

        try {
            const entries = await fs.readdir(scanPath, { withFileTypes: true });

            for (const entry of entries) {
                if (entry.name === '.git') continue;

                const relativePath = dirPath ? path.join(dirPath, entry.name) : entry.name;

                if (entry.isDirectory()) {
                    files.push({
                        name: entry.name,
                        path: relativePath,
                        type: 'directory'
                    });
                } else {
                    files.push({
                        name: entry.name,
                        path: relativePath,
                        type: 'file',
                        extension: path.extname(entry.name)
                    });
                }
            }
        } catch (error) {
            return { success: false, error: error.message };
        }

        return { success: true, files };
    }
}

module.exports = GitSyncService;
</file>

<file path="backend/services/privacy-service.js">
/**
 * Privacy Service for Tornado Cash Integration
 * Handles ZK proof generation, note management, and Tornado Cash interactions
 *
 * @module services/privacy-service
 * @description Provides optional privacy layer for Finallica on-chain transactions
 */

const { ethers } = require('ethers');
const crypto = require('crypto');

// ABI snippets for Tornado Cash contracts
const TORNADO_ABI = [
    'function deposit(bytes32) external payable',
    'function withdraw(bytes,bytes32,bytes32,address,address,uint256,uint256) external payable',
    'event Deposit(bytes32 indexed commitment, uint32 leafIndex, uint256 timestamp)'
];

const ERC20_ABI = [
    'function approve(address,uint256) external returns (bool)',
    'function allowance(address,address) external view returns (uint256)',
    'function balanceOf(address) external view returns (uint256)'
];

const PRIVACY_ROUTER_ABI = [
    'function privateDepositETH(bytes32,bytes32) external payable',
    'function privateDepositERC20(bytes32,bytes32) external',
    'function privateWithdraw(bytes,bytes32,bytes32,bytes32,address,address,uint256,uint256) external',
    'function addPrivacyPool(bytes32,address,uint256,address) external',
    'function getPrivacyPool(bytes32) external view returns (address,uint256,address,bool)',
    'function getActivePools() external view returns (bytes32[])'
];

/**
 * Privacy Service Class
 */
class PrivacyService {
    /**
     * @param {Object} config - Configuration object
     * @param {string} config.rpcUrl - Ethereum RPC URL
     * @param {string} config.privacyRouterAddress - FinallicaPrivacyRouter contract address
     * @param {Object} config.tornadoInstances - Tornado Cash instance addresses
     * @param {string} config.relayerUrl - Optional relayer URL
     */
    constructor(config) {
        this.provider = new ethers.providers.JsonRpcProvider(config.rpcUrl);
        this.privacyRouterAddress = config.privacyRouterAddress;
        this.relayerUrl = config.relayerUrl;

        // Initialize contracts
        if (this.privacyRouterAddress) {
            this.privacyRouter = new ethers.Contract(
                this.privacyRouterAddress,
                PRIVACY_ROUTER_ABI,
                this.provider
            );
        }

        // Tornado Cash instance addresses (configurable per network)
        this.tornadoInstances = config.tornadoInstances || {
            // Mainnet (placeholder addresses - use actual deployed addresses)
            ETH_0_1: process.env.TORNADO_ETH_0_1 || '0x...',
            ETH_1: process.env.TORNADO_ETH_1 || '0x...',
            ETH_10: process.env.TORNADO_ETH_10 || '0x...',
            ETH_100: process.env.TORNADO_ETH_100 || '0x...',
            USDC_100: process.env.TORNADO_USDC_100 || '0x...',
            // BLF token pools (deploy separately)
            BLF_100: process.env.TORNADO_BLF_100 || '0x...',
            BLF_1000: process.env.TORNADO_BLF_1000 || '0x...'
        };

        // Token addresses
        this.tokens = {
            BLF: process.env.BLF_TOKEN_ADDRESS,
            USDC: process.env.USDC_ADDRESS || '0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48',
            USDT: process.env.USDT_ADDRESS || '0xdAC17F958D2ee523a2206206994597C13D831ec7'
        };
    }

    /**
     * Generate a private note for deposit
     * @param {string} token - Token symbol ('ETH', 'BLF', 'USDC')
     * @param {string|number} amount - Amount to deposit
     * @returns {Promise<Object>} Note object containing secrets and commitment
     */
    async generateNote(token, amount) {
        // Generate random nullifier and secret (31 bytes each)
        const nullifier = crypto.randomBytes(31);
        const secret = crypto.randomBytes(31);

        // In production, use actual Pedersen hash from circomlibjs
        // For now, simulate with Keccak256
        const nullifierHash = ethers.utils.solidityKeccak256(
            ['bytes32', 'bytes32'],
            [nullifier, ethers.utils.zeros(32)]
        );

        const commitment = ethers.utils.solidityKeccak256(
            ['bytes32', 'bytes32'],
            [nullifier, secret]
        );

        // Create pool ID
        const poolId = ethers.utils.solidityKeccak256(
            ['string', 'uint256'],
            [token, amount]
        );

        // Create note string (user-friendly format)
        const note = this.formatNote(token, amount, commitment);

        return {
            nullifier: '0x' + nullifier.toString('hex'),
            secret: '0x' + secret.toString('hex'),
            commitment,
            nullifierHash,
            note,
            token,
            amount: amount.toString(),
            poolId,
            createdAt: Date.now()
        };
    }

    /**
     * Deposit to Tornado Cash for privacy
     * @param {Object} note - Note object from generateNote()
     * @param {string|ethers.Wallet} signer - User's wallet or private key
     * @param {Object} options - Deposit options
     * @returns {Promise<Object>} Transaction result
     */
    async deposit(note, signer, options = {}) {
        let wallet;

        if (typeof signer === 'string') {
            // Private key provided
            wallet = new ethers.Wallet(signer, this.provider);
        } else if (signer instanceof ethers.Wallet) {
            wallet = signer;
        } else if (signer.connect) {
            // JsonRpcSigner or similar
            wallet = signer;
        } else {
            throw new Error('Invalid signer');
        }

        const token = note.token.toUpperCase();
        const amount = note.amount;

        // Check if we should use the privacy router or direct Tornado
        const useRouter = options.useRouter !== false && this.privacyRouter;

        if (useRouter) {
            return await this.depositViaRouter(note, wallet, options);
        }

        return await this.depositDirect(note, wallet, options);
    }

    /**
     * Deposit via FinallicaPrivacyRouter contract
     * @private
     */
    async depositViaRouter(note, wallet, options) {
        const router = new ethers.Contract(
            this.privacyRouterAddress,
            PRIVACY_ROUTER_ABI,
            wallet
        );

        let tx;
        const token = note.token.toUpperCase();

        if (token === 'ETH') {
            tx = await router.privateDepositETH(
                note.poolId,
                note.commitment,
                { value: ethers.utils.parseEther(note.amount) }
            );
        } else {
            // ERC20 deposit - ensure approval first
            const tokenAddress = this.getTokenAddress(token);
            const erc20 = new ethers.Contract(tokenAddress, ERC20_ABI, wallet);

            // Check allowance
            const allowance = await erc20.allowance(await wallet.getAddress(), this.privacyRouterAddress);
            const depositAmount = ethers.utils.parseUnits(note.amount, this.getTokenDecimals(token));

            if (allowance.lt(depositAmount)) {
                // Approve
                const approveTx = await erc20.approve(this.privacyRouterAddress, depositAmount);
                await approveTx.wait();
            }

            tx = await router.privateDepositERC20(
                note.poolId,
                note.commitment
            );
        }

        const receipt = await tx.wait();

        return {
            success: true,
            txHash: receipt.transactionHash,
            blockNumber: receipt.blockNumber,
            note: note.note,
            gasUsed: receipt.gasUsed.toString()
        };
    }

    /**
     * Deposit directly to Tornado Cash instance
     * @private
     */
    async depositDirect(note, wallet, options) {
        const tornadoAddress = this.getTornadoInstance(note.token, note.amount);
        const tornado = new ethers.Contract(tornadoAddress, TORNADO_ABI, wallet);

        let tx;
        const token = note.token.toUpperCase();

        if (token === 'ETH') {
            tx = await tornado.deposit(note.commitment, {
                value: ethers.utils.parseEther(note.amount)
            });
        } else {
            // ERC20 - approve first
            const tokenAddress = this.getTokenAddress(token);
            const erc20 = new ethers.Contract(tokenAddress, ERC20_ABI, wallet);
            const depositAmount = ethers.utils.parseUnits(note.amount, this.getTokenDecimals(token));

            const allowance = await erc20.allowance(await wallet.getAddress(), tornadoAddress);
            if (allowance.lt(depositAmount)) {
                const approveTx = await erc20.approve(tornadoAddress, depositAmount);
                await approveTx.wait();
            }

            tx = await tornado.deposit(note.commitment);
        }

        const receipt = await tx.wait();

        return {
            success: true,
            txHash: receipt.transactionHash,
            blockNumber: receipt.blockNumber,
            note: note.note,
            gasUsed: receipt.gasUsed.toString()
        };
    }

    /**
     * Withdraw from Tornado Cash
     * @param {string} noteString - The saved note string
     * @param {string} recipient - Withdrawal address
     * @param {Object} options - Withdrawal options
     * @param {string} options.relayerUrl - Override default relayer URL
     * @param {ethers.Wallet} options.wallet - Wallet for signing
     * @returns {Promise<Object>} Withdrawal result
     */
    async withdraw(noteString, recipient, options = {}) {
        // Parse note
        const note = this.parseNote(noteString);

        // Compute Merkle proof
        const merkleProof = await this.computeMerkleProof(note.commitment, options.tornadoInstance);

        // Generate ZK proof
        const zkProof = await this.generateWithdrawProof(note, merkleProof, recipient);

        const relayerUrl = options.relayerUrl || this.relayerUrl;

        if (relayerUrl) {
            return await this.withdrawViaRelayer(note, zkProof, merkleProof, recipient, relayerUrl);
        } else {
            return await this.withdrawDirect(note, zkProof, merkleProof, recipient, options);
        }
    }

    /**
     * Withdraw via relayer service
     * @private
     */
    async withdrawViaRelayer(note, zkProof, merkleProof, recipient, relayerUrl) {
        const response = await fetch(`${relayerUrl}/withdraw`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                proof: zkProof,
                root: merkleProof.root,
                nullifierHash: note.nullifierHash,
                recipient,
                fee: 0,
                refund: 0
            })
        });

        if (!response.ok) {
            const error = await response.text();
            throw new Error(`Relayer error: ${error}`);
        }

        const result = await response.json();
        return {
            success: true,
            ...result,
            method: 'relayer'
        };
    }

    /**
     * Direct withdrawal (less private as it shows the caller's address)
     * @private
     */
    async withdrawDirect(note, zkProof, merkleProof, recipient, options) {
        if (!options.wallet) {
            throw new Error('Wallet required for direct withdrawal');
        }

        const tornadoAddress = options.tornadoInstance || this.getTornadoInstance(note.token, note.amount);
        const tornado = new ethers.Contract(tornadoAddress, TORNADO_ABI, options.wallet);

        const tx = await tornado.withdraw(
            zkProof,
            merkleProof.root,
            note.nullifierHash,
            recipient,
            options.wallet.address, // relayer = caller for direct withdrawals
            0, // fee
            0  // refund
        );

        const receipt = await tx.wait();

        return {
            success: true,
            txHash: receipt.transactionHash,
            blockNumber: receipt.blockNumber,
            method: 'direct'
        };
    }

    /**
     * Generate ZK-SNARK proof for withdrawal
     * @private
     * @param {Object} note - Note object
     * @param {Object} merkleProof - Merkle proof
     * @param {string} recipient - Recipient address
     * @returns {Promise<string>} ZK proof
     */
    async generateWithdrawProof(note, merkleProof, recipient) {
        // In production, this would use snarkjs or similar:
        //
        // const snarkjs = require('snarkjs');
        // const { proof, publicSignals } = await snarkjs.groth16.fullProve(
        //     {
        //         root: merkleProof.root,
        //         nullifierHash: note.nullifierHash,
        //         recipient: recipient.toLowerCase(),
        //         relayer: address(0),
        //         fee: 0,
        //         refund: 0,
        //         secret: note.secret,
        //         nullifier: note.nullifier,
        //         pathElements: merkleProof.pathElements,
        //         pathIndices: merkleProof.pathIndices
        //     },
        //     'circuit.wasm',
        //     'circuit_final.zkey'
        // );
        // return this.formatProof(proof);

        // For now, return a placeholder proof
        // This would need actual ZK circuit compilation in production
        const proofInputs = ethers.utils.AbiCoder.defaultAbiCoder().encode(
            ['bytes32', 'bytes32', 'address', 'address', 'uint256', 'uint256'],
            [
                merkleProof.root,
                note.nullifierHash,
                recipient,
                ethers.constants.AddressZero,
                0,
                0
            ]
        );

        return '0x' + crypto.randomBytes(128).toString('hex') + proofInputs.slice(2);
    }

    /**
     * Compute Merkle proof for a commitment
     * @private
     * @param {bytes32} commitment - The commitment to find in the tree
     * @param {string} tornadoInstance - Tornado Cash instance address
     * @returns {Promise<Object>} Merkle proof
     */
    async computeMerkleProof(commitment, tornadoInstance) {
        // In production, fetch all Deposit events and build Merkle tree
        // using the incremental Merkle tree from tornado-core
        //
        // const tornado = new ethers.Contract(tornadoInstance, TORNADO_ABI, this.provider);
        // const depositEvents = await tornado.queryFilter('Deposit');
        // const tree = new IncrementalMerkleTree(20);
        // for (const event of depositEvents) {
        //     tree.insert(event.args.commitment);
        // }
        // const proof = tree.createProof(commitment);

        // Simplified placeholder for development
        return {
            root: ethers.utils.formatBytes32String('merkle_root_placeholder'),
            pathElements: [],
            pathIndices: []
        };
    }

    /**
     * Format note string
     * @private
     */
    formatNote(token, amount, commitment) {
        const commitmentShort = commitment.slice(0, 10);
        return `tornado-${token}-${amount}-${commitmentShort}-${commitment}`;
    }

    /**
     * Parse note string
     * @param {string} noteString - Note string to parse
     * @returns {Object} Parsed note data
     */
    parseNote(noteString) {
        const parts = noteString.split('-');
        if (parts.length < 5 || parts[0] !== 'tornado') {
            throw new Error('Invalid note format');
        }

        return {
            token: parts[1],
            amount: parts[2],
            commitment: parts[4],
            fullNote: noteString
        };
    }

    /**
     * Get Tornado Cash instance address for token/amount pair
     * @private
     */
    getTornadoInstance(token, amount) {
        const key = `${token}_${amount}`;
        return this.tornadoInstances[key] || this.tornadoInstances.ETH_0_1;
    }

    /**
     * Get token address
     * @private
     */
    getTokenAddress(token) {
        const address = this.tokens[token];
        if (!address) {
            throw new Error(`Unknown token: ${token}`);
        }
        return address;
    }

    /**
     * Get token decimals
     * @private
     */
    getTokenDecimals(token) {
        const decimals = {
            ETH: 18,
            BLF: 18,
            USDC: 6,
            USDT: 6
        };
        return decimals[token] || 18;
    }

    /**
     * Get available privacy pools
     * @returns {Promise<Array>} Array of available pools
     */
    async getAvailablePools() {
        if (!this.privacyRouter) {
            // Return default pools configuration
            return Object.entries(this.tornadoInstances)
                .filter(([key, address]) => address !== '0x...')
                .map(([key, address]) => {
                    const [token, amount] = key.split('_');
                    return { token, amount, address };
                });
        }

        try {
            const poolIds = await this.privacyRouter.getActivePools();
            const pools = [];

            for (const poolId of poolIds) {
                const [tornadoInstance, denomination, token, isActive] =
                    await this.privacyRouter.getPrivacyPool(poolId);

                if (isActive) {
                    pools.push({
                        poolId,
                        tornadoInstance,
                        denomination: denomination.toString(),
                        token,
                        isActive
                    });
                }
            }

            return pools;
        } catch (error) {
            console.error('Error fetching pools:', error);
            return [];
        }
    }

    /**
     * Validate a note string
     * @param {string} noteString - Note to validate
     * @returns {boolean} True if valid
     */
    validateNote(noteString) {
        try {
            const parsed = this.parseNote(noteString);
            return (
                parsed.commitment.length === 66 &&
                parsed.commitment.startsWith('0x')
            );
        } catch {
            return false;
        }
    }

    /**
     * Calculate estimated fee for a transaction
     * @param {string} token - Token symbol
     * @param {string|number} amount - Amount
     * @returns {Object} Fee breakdown
     */
    calculateFees(token, amount) {
        // Base protocol fee (0.25%)
        const protocolFeeBps = 25;
        const amountWei = ethers.utils.parseUnits(amount.toString(), this.getTokenDecimals(token));
        const protocolFee = amountWei.mul(protocolFeeBps).div(10000);

        // Relayer fee (typical ~0.1% or gas cost equivalent)
        const relayerFeeBps = 10;
        const relayerFee = amountWei.mul(relayerFeeBps).div(10000);

        return {
            protocolFee: ethers.utils.formatUnits(protocolFee, this.getTokenDecimals(token)),
            relayerFee: ethers.utils.formatUnits(relayerFee, this.getTokenDecimals(token)),
            totalFee: ethers.utils.formatUnits(protocolFee.add(relayerFee), this.getTokenDecimals(token)),
            totalFeeBps: protocolFeeBps + relayerFeeBps
        };
    }

    /**
     * Get status of a withdrawal transaction
     * @param {string} txHash - Transaction hash
     * @returns {Promise<Object>} Transaction status
     */
    async getWithdrawalStatus(txHash) {
        try {
            const receipt = await this.provider.getTransactionReceipt(txHash);

            if (!receipt) {
                return { status: 'pending', confirmations: 0 };
            }

            const currentBlock = await this.provider.getBlockNumber();
            return {
                status: receipt.status === 1 ? 'success' : 'failed',
                confirmations: currentBlock - receipt.blockNumber,
                blockNumber: receipt.blockNumber,
                txHash: receipt.transactionHash
            };
        } catch (error) {
            return { status: 'unknown', error: error.message };
        }
    }
}

module.exports = PrivacyService;
</file>

<file path="backend/services/repository-service.js">
// Repository Service - Business logic for repository management

const crypto = require('crypto');

class RepositoryService {
    constructor(db, gitSync) {
        this.db = db;
        this.gitSync = gitSync;
    }

    generateId() {
        return 'repo_' + crypto.randomBytes(16).toString('hex');
    }

    /**
     * Parse Git URL to extract repository info
     */
    parseGitUrl(url) {
        // Handle various Git URL formats
        // GitHub: https://github.com/user/repo
        // GitLab: https://gitlab.com/user/repo
        // SSH: git@github.com:user/repo.git

        let sourceType = 'https';
        let name = '';
        let owner = '';

        // Remove .git suffix if present
        const cleanUrl = url.replace(/\.git$/, '');

        // Parse URL
        try {
            if (cleanUrl.startsWith('git@')) {
                // SSH format: git@github.com:user/repo
                const parts = cleanUrl.split(':');
                const host = parts[0].replace('git@', '');
                const pathParts = parts[1].split('/');

                if (host.includes('github')) {
                    sourceType = 'github';
                } else if (host.includes('gitlab')) {
                    sourceType = 'gitlab';
                } else if (host.includes('bitbucket')) {
                    sourceType = 'bitbucket';
                } else {
                    sourceType = 'ssh';
                }

                owner = pathParts[0] || '';
                name = pathParts[1] || '';
            } else {
                // HTTPS format
                const urlObj = new URL(cleanUrl);

                if (urlObj.hostname.includes('github')) {
                    sourceType = 'github';
                } else if (urlObj.hostname.includes('gitlab')) {
                    sourceType = 'gitlab';
                } else if (urlObj.hostname.includes('bitbucket')) {
                    sourceType = 'bitbucket';
                }

                const pathParts = urlObj.pathname.split('/').filter(p => p);
                owner = pathParts[0] || '';
                name = pathParts[1] || '';
            }
        } catch (e) {
            // If URL parsing fails, return defaults
        }

        return {
            sourceType,
            name: owner && name ? `${owner}/${name}` : cleanUrl.split('/').pop() || 'unknown',
            owner,
            repoName: name
        };
    }

    /**
     * Detect default branch from URL/headers
     */
    async detectDefaultBranch(url) {
        // Default to 'main' for modern repos, could fetch from API to verify
        return 'main';
    }

    /**
     * Create a new repository
     */
    async createRepository(data) {
        const urlInfo = this.parseGitUrl(data.url);

        const repo = {
            id: this.generateId(),
            name: data.name || urlInfo.name,
            sourceType: urlInfo.sourceType,
            url: data.url,
            cloneUrl: data.url, // Will be updated with auth if private
            branch: data.branch || 'main',
            description: data.description || '',
            tags: data.tags || [],
            isPrivate: data.isPrivate || false,
            authTokenId: data.authTokenId,
            localPath: null, // Will be set after clone
            status: 'pending'
        };

        // Create in database
        this.db.createRepository(repo);

        // Log activity
        this.db.logActivity('repo_added', 'repository', repo.id, null, {
            name: repo.name,
            sourceType: repo.sourceType
        });

        return repo;
    }

    /**
     * Get repository with details
     */
    getRepository(id) {
        return this.db.getRepository(id);
    }

    /**
     * List all repositories
     */
    listRepositories(options = {}) {
        return this.db.getAllRepositories(options);
    }

    /**
     * Update repository
     */
    updateRepository(id, updates) {
        const result = this.db.updateRepository(id, updates);

        if (Object.keys(updates).length > 0) {
            this.db.logActivity('repo_updated', 'repository', id, null, updates);
        }

        return result;
    }

    /**
     * Delete repository
     */
    async deleteRepository(id) {
        const repo = this.db.getRepository(id);
        if (!repo) {
            throw new Error('Repository not found');
        }

        // Delete cloned files
        await this.gitSync.deleteRepository(id);

        // Delete from database
        this.db.deleteRepository(id);

        // Log activity
        this.db.logActivity('repo_deleted', 'repository', id, null, {
            name: repo.name
        });

        return { success: true };
    }

    /**
     * Sync a repository (manual trigger)
     */
    async syncRepository(id) {
        const repo = this.db.getRepository(id);
        if (!repo) {
            throw new Error('Repository not found');
        }

        // Update status to syncing
        this.db.updateRepository(id, { status: 'cloning' });

        // Get auth token if private
        let authToken = null;
        if (repo.is_private && repo.auth_token_id) {
            authToken = this.db.getAuthToken(repo.auth_token_id);
        }

        // Perform sync
        const result = await this.gitSync.syncRepository(repo, authToken);

        // Update repository with results
        const updates = {
            status: result.success ? 'active' : 'error',
            last_commit_hash: result.commitHash,
            last_sync_at: Math.floor(Date.now() / 1000),
            stats: result.stats
        };

        if (!result.success) {
            updates.error_message = result.error;
        }

        this.db.updateRepository(id, updates);

        // Log activity
        this.db.logActivity('repo_synced', 'repository', id, null, {
            success: result.success,
            filesAdded: result.filesAdded,
            filesModified: result.filesModified,
            duration: result.duration
        });

        return result;
    }

    /**
     * Get files from a repository
     */
    async getRepositoryFiles(id, dirPath = '') {
        return this.gitSync.listFiles(id, dirPath);
    }

    /**
     * Get file content
     */
    async getFileContent(id, filePath) {
        return this.gitSync.getFileContent(id, filePath);
    }

    /**
     * Search repositories
     */
    searchRepositories(query) {
        const repos = this.db.getAllRepositories();

        if (!query) {
            return repos;
        }

        const lowerQuery = query.toLowerCase();

        return repos.filter(repo => {
            return (
                repo.name?.toLowerCase().includes(lowerQuery) ||
                repo.description?.toLowerCase().includes(lowerQuery) ||
                repo.tags?.some(tag => tag.toLowerCase().includes(lowerQuery))
            );
        });
    }

    /**
     * Get repositories by tag
     */
    getRepositoriesByTag(tag) {
        const repos = this.db.getAllRepositories();
        return repos.filter(repo =>
            repo.tags?.some(t => t.toLowerCase() === tag.toLowerCase())
        );
    }

    /**
     * Get repository statistics summary
     */
    getStatsSummary() {
        const repos = this.db.getAllRepositories();

        return {
            total: repos.length,
            active: repos.filter(r => r.status === 'active').length,
            error: repos.filter(r => r.status === 'error').length,
            pending: repos.filter(r => r.status === 'pending' || r.status === 'cloning').length,
            private: repos.filter(r => r.is_private).length,
            bySourceType: this.groupBy(repos, 'source_type')
        };
    }

    groupBy(array, key) {
        return array.reduce((result, item) => {
            const group = item[key] || 'unknown';
            result[group] = (result[group] || 0) + 1;
            return result;
        }, {});
    }
}

module.exports = RepositoryService;
</file>

<file path="contracts/FinallicaGovernance.sol">
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.20;

import "@openzeppelin/contracts/security/ReentrancyGuard.sol";
import "@openzeppelin/contracts/access/Ownable.sol";
import "@openzeppelin/contracts/token/ERC20/IERC20.sol";

/**
 * @title FinallicaGovernanceToken
 * @notice BLF token used for staking and governance in Finallica
 * @dev This is the governance token that allows holders to propose and vote on changes
 */
contract FinallicaGovernanceToken is Ownable {
    string public constant name = "Finallica Governance Token";
    string public constant symbol = "BLF";
    uint8 public constant decimals = 18;

    uint256 public totalSupply;
    mapping(address => uint256) public balanceOf;
    mapping(address => mapping(address => uint256)) public allowance;

    /// @notice Staked balance for each user
    mapping(address => uint256) public stakedBalance;

    /// @notice Delegate address for voting
    mapping(address => address) public delegate;

    /// @notice Total staked tokens
    uint256 public totalStaked;

    /// @notice Minimum stake for VR (Validator-Router)
    uint256 public constant MIN_STAKE_VR = 500_000 * 10**18; // 500K BLF

    /// @notice Minimum stake for Settlement Executor
    uint256 public constant MIN_STAKE_SE = 2_000_000 * 10**18; // 2M BLF

    /// @notice Unstaking period in seconds
    uint256 public constant UNBONDING_PERIOD = 30 days;

    /// @notice Unstaking requests
    mapping(address => uint256) public unstakeRequestTime;

    event Transfer(address indexed from, address indexed to, uint256 value);
    event Approval(address indexed owner, address indexed spender, uint256 value);
    event Staked(address indexed user, uint256 amount);
    event Unstaked(address indexed user, uint256 amount);
    event UnstakeRequested(address indexed user, uint256 amount, uint256 availableAt);
    event DelegateChanged(address indexed from, address indexed to, address delegate);

    constructor(uint256 initialSupply) {
        totalSupply = initialSupply;
        balanceOf[msg.sender] = initialSupply;
        emit Transfer(address(0), msg.sender, initialSupply);
    }

    function transfer(address to, uint256 value) external returns (bool) {
        _transfer(msg.sender, to, value);
        return true;
    }

    function approve(address spender, uint256 value) external returns (bool) {
        allowance[msg.sender][spender] = value;
        emit Approval(msg.sender, spender, value);
        return true;
    }

    function transferFrom(address from, address to, uint256 value) external returns (bool) {
        uint256 currentAllowance = allowance[from][msg.sender];
        require(currentAllowance >= value, "Insufficient allowance");
        allowance[from][msg.sender] = currentAllowance - value;
        _transfer(from, to, value);
        return true;
    }

    function stake(uint256 amount) external {
        require(balanceOf[msg.sender] >= amount, "Insufficient balance");
        require(amount >= MIN_STAKE_VR, "Below minimum stake");

        balanceOf[msg.sender] -= amount;
        stakedBalance[msg.sender] += amount;
        totalStaked += amount;

        emit Staked(msg.sender, amount);
    }

    function requestUnstake(uint256 amount) external {
        require(stakedBalance[msg.sender] >= amount, "Insufficient staked balance");
        stakedBalance[msg.sender] -= amount;
        unstakeRequestTime[msg.sender] = block.timestamp;
        uint256 availableAt = block.timestamp + UNBONDING_PERIOD;

        emit UnstakeRequested(msg.sender, amount, availableAt);
    }

    function unstake() external {
        require(unstakeRequestTime[msg.sender] > 0, "No unstake request");
        require(block.timestamp >= unstakeRequestTime[msg.sender], "Still unbonding");
        require(block.timestamp >= unstakeRequestTime[msg.sender] + UNBONDING_PERIOD, "Unbonding period not met");

        uint256 amount = stakedBalance[msg.sender];
        require(amount > 0, "Nothing to unstake");

        stakedBalance[msg.sender] = 0;
        unstakeRequestTime[msg.sender] = 0;
        balanceOf[msg.sender] += amount;
        totalStaked -= amount;

        emit Unstaked(msg.sender, amount);
    }

    function setDelegate(address to) external {
        delegate[msg.sender] = to;
        emit DelegateChanged(msg.sender, to, to);
    }

    function getVotingPower(address account) external view returns (uint256) {
        address delegatedTo = delegate[account];
        if (delegatedTo == address(0)) {
            return stakedBalance[account];
        }
        return stakedBalance[delegatedTo];
    }

    function _transfer(address from, address to, uint256 value) internal {
        require(balanceOf[from] >= value, "Insufficient balance");
        balanceOf[from] -= value;
        balanceOf[to] += value;
        emit Transfer(from, to, value);
    }
}

/**
 * @title FinallicaProposals
 * @notice Manages proposals for changes to Finallica documentation
 * @dev Uses BLS aggregated signatures for efficient verification
 */
contract FinallicaProposals is Ownable, ReentrancyGuard {
    FinallicaGovernanceToken public token;

    uint256 public nextProposalId;
    uint256 public constant PROPOSAL_STAKE = 1000 * 10**18; // 1000 BLF
    uint256 public constant VOTING_PERIOD = 7 days;
    uint256 public constant QUORUM_PCT = 67; // 67%

    struct Proposal {
        uint256 id;
        address proposer;
        string title;
        string document; // Document name (e.g., "README.md")
        string diff;    // Git diff format
        string rationale;
        ProposalType proposalType;
        ProposalStatus status;
        uint256 createdAt;
        uint256 deadline;
        uint256 votesFor;
        uint256 votesAgainst;
        uint256 votesAbstain;
        uint256 totalStake;
        bool executed;
    }

    enum ProposalType {
        DOCUMENT_EDIT,
        NEW_SECTION,
        PROTOCOL_CHANGE,
        PARAMETER_UPDATE
    }

    enum ProposalStatus {
        PENDING,
        APPROVED,
        REJECTED,
        EXECUTED
    }

    mapping(uint256 => Proposal) public proposals;

    /// @notice Vote record per proposal per voter
    mapping(uint256 => mapping(address => Vote)) public votes;

    struct Vote {
        bool hasVoted;
        bool support; // true = for, false = against
        uint256 stake;
        uint8 weight; // 1-100, percentage of stake to commit
    }

    event ProposalCreated(
        uint256 indexed id,
        address indexed proposer,
        string title,
        ProposalType proposalType
    );

    event VoteCast(
        uint256 indexed proposalId,
        address indexed voter,
        bool support,
        uint256 stake
    );

    event ProposalExecuted(uint256 indexed proposalId);

    modifier onlyProposer() {
        require(token.stakedBalance(msg.sender) >= PROPOSAL_STAKE, "Not enough staked");
        _;
    }

    constructor(address tokenAddress) {
        token = FinallicaGovernanceToken(tokenAddress);
    }

    /**
     * @notice Create a new proposal
     * @param title Title of the proposal
     * @param document Document name to modify
     * @param diff Git diff format changes
     * @param rationale Explanation for the change
     * @param proposalType Type of proposal
     */
    function createProposal(
        string calldata title,
        string calldata document,
        string calldata diff,
        string calldata rationale,
        ProposalType proposalType
    ) external onlyProposer returns (uint256) {
        uint256 proposalId = nextProposalId++;

        proposals[proposalId] = Proposal({
            id: proposalId,
            proposer: msg.sender,
            title: title,
            document: document,
            diff: diff,
            rationale: rationale,
            proposalType: proposalType,
            status: ProposalStatus.PENDING,
            createdAt: block.timestamp,
            deadline: block.timestamp + VOTING_PERIOD,
            votesFor: 0,
            votesAgainst: 0,
            votesAbstain: 0,
            totalStake: 0,
            executed: false
        });

        emit ProposalCreated(proposalId, msg.sender, title, proposalType);
        return proposalId;
    }

    /**
     * @notice Cast a vote on a proposal
     * @param proposalId ID of the proposal
     * @param support True to vote for, false to vote against
     * @param weight Percentage of stake to commit (1-100)
     */
    function castVote(
        uint256 proposalId,
        bool support,
        uint8 weight
    ) external {
        Proposal storage proposal = proposals[proposalId];
        require(proposal.id != 0, "Proposal does not exist");
        require(proposal.status == ProposalStatus.PENDING, "Proposal not active");
        require(block.timestamp <= proposal.deadline, "Voting ended");
        require(!votes[proposalId][msg.sender].hasVoted, "Already voted");
        require(weight > 0 && weight <= 100, "Invalid weight");

        uint256 voterStake = token.getVotingPower(msg.sender);
        require(voterStake > 0, "No voting power");

        uint256 voteWeight = (voterStake * weight) / 100;

        votes[proposalId][msg.sender] = Vote({
            hasVoted: true,
            support: support,
            stake: voterStake,
            weight: weight
        });

        if (support) {
            proposal.votesFor += voteWeight;
        } else {
            proposal.votesAgainst += voteWeight;
        }

        proposal.totalStake += voteWeight;

        emit VoteCast(proposalId, msg.sender, support, voteWeight);

        // Check if quorum reached and decision made
        _checkProposalOutcome(proposalId);
    }

    /**
     * @notice Cast batch votes (for BLS aggregated signatures)
     * @param proposalId ID of the proposal
     * @param voters Addresses of voters
     * @param support Whether each voter supports
     * @param sigs BLS aggregated signature
     */
    function castBatchVotes(
        uint256 proposalId,
        address[] calldata voters,
        bool[] calldata support,
        bytes calldata sigs
    ) external {
        require(voters.length == support.length, "Array length mismatch");
        // In production, verify BLS signature here

        for (uint256 i = 0; i < voters.length; i++) {
            Proposal storage proposal = proposals[proposalId];
            if (proposal.status != ProposalStatus.PENDING) continue;

            address voter = voters[i];
            if (votes[proposalId][voter].hasVoted) continue;

            uint256 voterStake = token.getVotingPower(voter);
            if (voterStake == 0) continue;

            uint256 voteWeight = voterStake; // 100% weight for batch votes

            votes[proposalId][voter] = Vote({
                hasVoted: true,
                support: support[i],
                stake: voterStake,
                weight: 100
            });

            if (support[i]) {
                proposal.votesFor += voteWeight;
            } else {
                proposal.votesAgainst += voteWeight;
            }

            proposal.totalStake += voteWeight;

            emit VoteCast(proposalId, voter, support[i], voteWeight);
        }

        _checkProposalOutcome(proposalId);
    }

    /**
     * @notice Execute an approved proposal
     * @param proposalId ID of the proposal to execute
     */
    function executeProposal(uint256 proposalId) external nonReentrant {
        Proposal storage proposal = proposals[proposalId];
        require(proposal.id != 0, "Proposal does not exist");
        require(proposal.status == ProposalStatus.APPROVED, "Proposal not approved");
        require(!proposal.executed, "Already executed");
        require(block.timestamp > proposal.deadline, "Voting still active");

        proposal.status = ProposalStatus.EXECUTED;
        proposal.executed = true;

        emit ProposalExecuted(proposalId);
    }

    function _checkProposalOutcome(uint256 proposalId) internal {
        Proposal storage proposal = proposals[proposalId];

        // Calculate quorum
        uint256 quorum = (token.totalStaked() * QUORUM_PCT) / 100;

        if (proposal.totalStake >= quorum) {
            if (proposal.votesFor > proposal.votesAgainst) {
                proposal.status = ProposalStatus.APPROVED;
            } else if (proposal.votesAgainst > proposal.votesFor) {
                proposal.status = ProposalStatus.REJECTED;
            }
        }
    }

    /**
     * @notice Get proposal details
     */
    function getProposal(uint256 proposalId) external view returns (
        uint256 id,
        address proposer,
        string memory title,
        string memory document,
        string memory diff,
        string memory rationale,
        ProposalType proposalType,
        ProposalStatus status,
        uint256 createdAt,
        uint256 deadline,
        uint256 votesFor,
        uint256 votesAgainst,
        uint256 votesAbstain,
        uint256 totalStake,
        bool executed
    ) {
        Proposal storage p = proposals[proposalId];
        return (
            p.id,
            p.proposer,
            p.title,
            p.document,
            p.diff,
            p.rationale,
            p.proposalType,
            p.status,
            p.createdAt,
            p.deadline,
            p.votesFor,
            p.votesAgainst,
            p.votesAbstain,
            p.totalStake,
            p.executed
        );
    }

    /**
     * @notice Check if an address has voted on a proposal
     */
    function hasVoted(uint256 proposalId, address voter) external view returns (bool) {
        return votes[proposalId][voter].hasVoted;
    }
}

/**
 * @title FinallicaConsensus
 * @notice HotStuff-style BFT consensus for Finallica state roots
 * @dev Implements 3-phase commit with 8 notary nodes
 */
contract FinallicaConsensus is Ownable {
    /// @notice State root of the Finallica documentation system
    bytes32 public stateRoot;

    /// @notice Current block/epoch number
    uint256 public blockNumber;
    uint256 public epoch;

    /// @notice Notary nodes (8 authorities)
    mapping(address => bool) public isNotary;
    address[] public notaries;

    /// @notice Quorum threshold (5 of 8)
    uint256 public constant QUORUM_THRESHOLD = 5;

    /// @notice State root history
    mapping(uint256 => bytes32) public stateRootHistory;

    /// @notice Signatures for each state root
    mapping(uint256 => mapping(address => bytes)) public stateRootSigs;

    /// @notice View number for leader rotation
    uint256 public viewNumber;

    /// @notice Current leader
    address public leader;

    struct Phase {
        uint256 viewNumber;
        PhaseType phaseType;
        uint256 startTime;
        bytes32 blockHash;
        bytes32 prepareQC;
        bytes32 precommitQC;
        bytes32 commitQC;
    }

    enum PhaseType {
        PREPARE,
        PRE_COMMIT,
        COMMIT,
        DECIDE
    }

    Phase public currentPhase;

    /// @notice Events
    event StateRootProposed(uint256 indexed view, address indexed leader, bytes32 stateRoot);
    event PhaseTransition(uint256 indexed view, PhaseType from, PhaseType to);
    event StateRootFinalized(uint256 indexed blockNumber, bytes32 stateRoot, bytes32 aggregatedSig);

    modifier onlyNotary() {
        require(isNotary[msg.sender], "Not a notary");
        _;
    }

    modifier onlyLeader() {
        require(msg.sender == leader, "Not the leader");
        _;
    }

    constructor() {
        // Initialize 8 demo notary addresses
        for (uint256 i = 0; i < 8; i++) {
            address notaryAddress = address(uint160(0x1000 + i));
            notaries.push(notaryAddress);
            isNotary[notaryAddress] = true;
        }

        leader = notaries[0];
        blockNumber = 18492;
        epoch = 1;

        currentPhase = Phase({
            viewNumber: 0,
            phaseType: PhaseType.PREPARE,
            startTime: block.timestamp,
            blockHash: bytes32(0),
            prepareQC: bytes32(0),
            precommitQC: bytes32(0),
            commitQC: bytes32(0)
        });
    }

    /**
     * @notice Propose a new state root (HotStuff PREPARE phase)
     * @param stateRoot The new state root hash
     */
    function proposeStateRoot(bytes32 stateRoot) external onlyLeader {
        require(currentPhase.phaseType == PhaseType.DECIDE ||
                currentPhase.phaseType == PhaseType.PREPARE,
                "Invalid phase transition");

        // Move to PREPARE phase
        currentPhase = Phase({
            viewNumber: viewNumber,
            phaseType: PhaseType.PREPARE,
            startTime: block.timestamp,
            blockHash: keccak256(abi.encodePacked(blockNumber, stateRoot)),
            prepareQC: bytes32(0),
            precommitQC: bytes32(0),
            commitQC: bytes32(0)
        });

        emit StateRootProposed(viewNumber, msg.sender, stateRoot);
        emit PhaseTransition(viewNumber, PhaseType.DECIDE, PhaseType.PREPARE);
    }

    /**
     * @notice Vote for a state root (collect signatures)
     * @param stateRoot The state root being voted on
     * @param signature The notary's BLS signature
     */
    function voteStateRoot(bytes32 stateRoot, bytes memory signature) external onlyNotary {
        stateRootSigs[blockNumber][msg.sender] = signature;

        // Count signatures
        uint256 sigCount = 0;
        for (uint256 i = 0; i < notaries.length; i++) {
            if (stateRootSigs[blockNumber][notaries[i]] != bytes32(0)) {
                sigCount++;
            }
        }

        // If we have quorum, finalize
        if (sigCount >= QUORUM_THRESHOLD) {
            _finalizeStateRoot(stateRoot);
        }
    }

    /**
     * @notice Finalize a state root (HotStuff DECIDE phase)
     * @param stateRoot The finalized state root
     */
    function _finalizeStateRoot(bytes32 stateRoot) internal {
        // Store state root
        stateRootHistory[blockNumber] = stateRoot;
        stateRoot = stateRoot;

        // Advance block
        blockNumber++;

        // Rotate leader every 8 blocks
        if (blockNumber % 8 == 0) {
            viewNumber++;
            leader = notaries[viewNumber % notaries.length];
        }

        // New epoch every 100 blocks
        if (blockNumber % 100 == 0) {
            epoch++;
        }

        // Move to DECIDE phase
        currentPhase.phaseType = PhaseType.DECIDE;

        emit StateRootFinalized(blockNumber, stateRoot, bytes32(0));
    }

    /**
     * @notice Get the current state root
     */
    function getCurrentStateRoot() external view returns (bytes32) {
        return stateRoot;
    }

    /**
     * @notice Verify a Merkle proof against the state root
     * @param proof The Merkle proof
     * @param root The expected root
     */
    function verifyMerkleProof(
        bytes32[] memory proof,
        bytes32 root,
        bytes32 leaf,
        uint256 index
    ) external pure returns (bool) {
        bytes32 computedHash = leaf;

        for (uint256 i = 0; i < proof.length; i++) {
            if (index % 2 == 0) {
                computedHash = keccak256(abi.encodePacked(computedHash, proof[i]));
            } else {
                computedHash = keccak256(abi.encodePacked(proof[i], computedHash));
            }
            index /= 2;
        }

        return computedHash == root;
    }

    /**
     * @notice Add a notary
     */
    function addNotary(address notaryAddress) external onlyOwner {
        require(!isNotary[notaryAddress], "Already a notary");
        notaries.push(notaryAddress);
        isNotary[notaryAddress] = true;
    }

    /**
     * @notice Remove a notary
     */
    function removeNotary(address notaryAddress) external onlyOwner {
        require(isNotary[notaryAddress], "Not a notary");
        isNotary[notaryAddress] = false;

        // Remove from array
        for (uint256 i = 0; i < notaries.length; i++) {
            if (notaries[i] == notaryAddress) {
                notaries[i] = notaries[notaries.length - 1];
                notaries.pop();
                break;
            }
        }
    }

    /**
     * @notice Get all notaries
     */
    function getNotaries() external view returns (address[] memory) {
        return notaries;
    }

    /**
     * @notice Calculate voting weight using stake^0.7
     * @param stake The staker's stake amount
     */
    function calculateVotingWeight(uint256 stake) external pure returns (uint256) {
        // weight = stake^0.7
        // Using approximation: (stake^70 / 10^70) / 10^17
        // For simplicity, returning linear scaling here
        // In production, use a proper power function library
        return stake / 10; // Simplified demo
    }

    /**
     * @notice Get consensus status
     */
    function getConsensusStatus() external view returns (
        uint256 _blockNumber,
        uint256 _epoch,
        bytes32 _stateRoot,
        address _leader,
        uint256 _viewNumber,
        PhaseType _phaseType,
        uint256 _notaryCount,
        uint256 _quorumThreshold
    ) {
        return (
            blockNumber,
            epoch,
            stateRoot,
            leader,
            viewNumber,
            currentPhase.phaseType,
            notaries.length,
            QUORUM_THRESHOLD
        );
    }
}

/**
 * @title FinallicaDocumentRegistry
 * @notice Stores document hashes on-chain for verification
 */
contract FinallicaDocumentRegistry is Ownable {
    /// @notice Mapping of document name to content hash
    mapping(string => bytes32) public documentHashes;

    /// @notice Mapping of document name to block number of last update
    mapping(string => uint256) public documentVersions;

    /// @notice Document history
    struct DocumentVersion {
        bytes32 contentHash;
        address updater;
        uint256 blockNumber;
        uint256 timestamp;
        string commitHash;
    }

    mapping(string => DocumentVersion[]) public documentHistory;

    event DocumentUpdated(
        string indexed documentName,
        bytes32 contentHash,
        address indexed updater,
        uint256 blockNumber
    );

    /**
     * @notice Register a document update
     * @param documentName Name of the document
     * @param contentHash SHA256 hash of the content
     * @param commitHash Git commit hash
     */
    function updateDocument(
        string calldata documentName,
        bytes32 contentHash,
        string calldata commitHash
    ) external {
        documentHashes[documentName] = contentHash;
        documentVersions[documentName] = block.number;

        documentHistory[documentName].push(DocumentVersion({
            contentHash: contentHash,
            updater: msg.sender,
            blockNumber: block.number,
            timestamp: block.timestamp,
            commitHash: commitHash
        });

        emit DocumentUpdated(documentName, contentHash, msg.sender, block.number);
    }

    /**
     * @notice Verify a document's content hash
     * @param documentName Name of the document
     * @param contentHash Hash to verify
     */
    function verifyDocument(string calldata documentName, bytes32 contentHash)
        external view returns (bool)
    {
        return documentHashes[documentName] == contentHash;
    }

    /**
     * @notice Get document history
     */
    function getDocumentHistory(string calldata documentName)
        external view returns (DocumentVersion[] memory)
    {
        return documentHistory[documentName];
    }

    /**
     * @notice Get the latest content hash for a document
     */
    function getLatestHash(string calldata documentName)
        external view returns (bytes32)
    {
        return documentHashes[documentName];
    }
}

/**
 * @title FinallicaStaking
 * @notice Manages staking and slashing for Validator-Routers
 */
contract FinallicaStaking is Ownable, ReentrancyGuard {
    FinallicaGovernanceToken public token;

    struct Validator {
        address owner;
        uint256 stake;
        uint256 bondedAt;
        bool isActive;
        bool isSlashed;
        uint256 slashCount;
        ValidatorType vType;
    }

    enum ValidatorType {
        GUARD,
        MIDDLE,
        SETTLEMENT_EXECUTOR
    }

    mapping(address => Validator) public validators;

    address[] public validatorList;

    /// @notice Minimum stake amounts
    uint256 public constant MIN_STAKE_GUARD = 15_700_000 * 10**18; // 15.7M BLF
    uint256 public constant MIN_STAKE_MIDDLE = 2_000_000 * 10**18; // 2M BLF
    uint256 public constant MIN_STAKE_SE = 12_300_000 * 10**18; // 12.3M BLF

    /// @notice Slashing conditions
    uint256 public constant SLASH_DOUBLE_SIGN = 10000; // 100%
    uint256 public constant SLASH_CENSORSHIP = 1000;    // 10%
    uint256 public constant SLASH_DOWNTIME = 100;       // 1%

    event ValidatorRegistered(address indexed validator, ValidatorType vType, uint256 stake);
    event ValidatorUnregistered(address indexed validator);
    event ValidatorSlashed(address indexed validator, uint256 amount, string reason);

    constructor(address tokenAddress) {
        token = FinallicaGovernanceToken(tokenAddress);
    }

    /**
     * @notice Register as a Validator-Router
     * @param vType Type of validator
     * @param stakeAmount Amount to stake
     */
    function registerValidator(ValidatorType vType, uint256 stakeAmount)
        external nonReentrant
    {
        require(validators[msg.sender].stake == 0, "Already registered");

        uint256 minStake;
        if (vType == ValidatorType.GUARD) {
            minStake = MIN_STAKE_GUARD;
        } else if (vType == ValidatorType.MIDDLE) {
            minStake = MIN_STAKE_MIDDLE;
        } else {
            minStake = MIN_STAKE_SE;
        }

        require(stakeAmount >= minStake, "Insufficient stake");

        // Transfer tokens to contract
        require(token.transferFrom(msg.sender, address(this), stakeAmount),
            "Transfer failed");

        validators[msg.sender] = Validator({
            owner: msg.sender,
            stake: stakeAmount,
            bondedAt: block.timestamp,
            isActive: true,
            isSlashed: false,
            slashCount: 0,
            vType: vType
        };

        validatorList.push(msg.sender);

        emit ValidatorRegistered(msg.sender, vType, stakeAmount);
    }

    /**
     * @notice Unregister as validator
     */
    function unregisterValidator() external nonReentrant {
        Validator storage validator = validators[msg.sender];
        require(validator.isActive, "Not active");

        // Must wait unbonding period
        require(block.timestamp >= validator.bondedAt + 30 days,
            "Still bonded");

        // Return stake
        require(token.transfer(msg.sender, validator.stake), "Transfer failed");

        validator.isActive = false;
        // Remove from list (would need to implement proper removal)

        emit ValidatorUnregistered(msg.sender);
    }

    /**
     * @notice Slash a validator for misbehavior
     * @param validatorAddress Address of the validator to slash
     * @param reason Reason for slashing
     * @param percentage Percentage to slash (basis points)
     */
    function slashValidator(
        address validatorAddress,
        string calldata reason,
        uint256 percentage
    ) external onlyOwner {
        require(validators[validatorAddress].isActive, "Not active");
        require(percentage <= 10000, "Invalid percentage");

        Validator storage validator = validators[validatorAddress];
        uint256 slashAmount = (validator.stake * percentage) / 10000;

        require(token.transfer(owner(), slashAmount), "Transfer failed");
        validator.stake -= slashAmount;
        validator.slashCount++;
        validator.isSlashed = true;

        emit ValidatorSlashed(validatorAddress, slashAmount, reason);
    }

    /**
     * @notice Get validator info
     */
    function getValidator(address validatorAddress) external view returns (
        address owner,
        uint256 stake,
        uint256 bondedAt,
        bool isActive,
        bool isSlashed,
        uint256 slashCount,
        ValidatorType vType
    ) {
        Validator memory v = validators[validatorAddress];
        return (
            v.owner,
            v.stake,
            v.bondedAt,
            v.isActive,
            v.isSlashed,
            v.slashCount,
            v.vType
        );
    }

    /**
     * @notice Get all validators
     */
    function getAllValidators() external view returns (address[] memory) {
        return validatorList;
    }

    /**
     * @notice Get total staked across all validators
     */
    function getTotalStaked() external view returns (uint256) {
        uint256 total = 0;
        for (uint256 i = 0; i < validatorList.length; i++) {
            total += validators[validatorList[i]].stake;
        }
        return total;
    }
}
</file>

<file path="contracts/FinallicaPrivacyRouter.sol">
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.20;

import "@openzeppelin/contracts/access/Ownable.sol";
import "@openzeppelin/contracts/security/ReentrancyGuard.sol";
import "@openzeppelin/contracts/token/ERC20/IERC20.sol";

/**
 * @title FinallicaPrivacyRouter
 * @notice Optional privacy layer using Tornado Cash for BLF token and ETH transfers
 * @dev Users opt-in to privacy features; nothing is mandatory
 * @custom:security-contact security@finallica.io
 */
contract FinallicaPrivacyRouter is Ownable, ReentrancyGuard {
    /// @notice BLF governance token address
    address public blfToken;

    /// @notice Tornado Cash instance addresses (configurable)
    mapping(address => bool) public authorizedTornadoInstances;

    /// @notice Privacy pool configurations
    struct PrivacyPool {
        address tornadoInstance;
        uint256 denomination;
        address token; // address(0) for ETH, token address for ERC20
        bool isActive;
    }

    /// @notice Pool ID to PrivacyPool mapping
    mapping(bytes32 => PrivacyPool) public privacyPools;

    /// @notice List of all pool IDs
    bytes32[] public poolList;

    /// @notice Relayer registry for feeless withdrawals
    mapping(address => bool) public authorizedRelayers;

    /// @notice Minimum privacy fee (basis points)
    uint256 public constant MIN_PRIVACY_FEE = 10; // 0.1%

    /// @notice Maximum privacy fee (basis points)
    uint256 public constant MAX_PRIVACY_FEE = 100; // 1%

    /// @notice Protocol fee for privacy services
    uint256 public protocolFeeBps = 25; // 0.25%

    /// @notice Accumulated protocol fees
    mapping(address => uint256) public accumulatedFees;

    // ============================================
    // EVENTS
    // ============================================

    event PrivateDeposit(
        bytes32 indexed poolId,
        address indexed depositor,
        uint256 amount,
        bytes32 commitment
    );

    event PrivateWithdrawal(
        bytes32 indexed poolId,
        address indexed recipient,
        uint256 amount,
        address relayer,
        uint256 fee
    );

    event PrivacyPoolAdded(
        bytes32 indexed poolId,
        address tornadoInstance,
        uint256 denomination,
        address token
    );

    event PrivacyPoolRemoved(bytes32 indexed poolId);

    event PrivacyPoolDeactivated(bytes32 indexed poolId);

    event RelayerAdded(address indexed relayer);
    event RelayerRemoved(address indexed relayer);

    event FeesCollected(address indexed token, uint256 amount);
    event FeesWithdrawn(address indexed token, address indexed to, uint256 amount);

    event ProtocolFeeUpdated(uint256 newFeeBps);

    // ============================================
    // ERRORS
    // ============================================

    error PoolNotFound();
    error PoolNotActive();
    error InvalidAmount();
    error InvalidToken();
    error UnauthorizedInstance();
    error UnauthorizedRelayer();
    error InvalidFee();
    error TransferFailed();

    // ============================================
    // CONSTRUCTOR
    // ============================================

    constructor(address _blfToken) Ownable(msg.sender) {
        blfToken = _blfToken;
    }

    // ============================================
    // DEPOSIT FUNCTIONS
    // ============================================

    /**
     * @notice Deposit to Tornado Cash for privacy (ETH)
     * @param poolId The privacy pool to use
     * @param commitment The commitment hash (generated off-chain)
     */
    function privateDepositETH(
        bytes32 poolId,
        bytes32 commitment
    ) external payable nonReentrant {
        PrivacyPool storage pool = privacyPools[poolId];
        if (!pool.isActive) revert PoolNotActive();
        if (pool.token != address(0)) revert InvalidToken();
        if (msg.value != pool.denomination) revert InvalidAmount();

        (bool success, ) = pool.tornadoInstance.call{value: msg.value}(
            abi.encodeWithSignature("deposit(bytes32)", commitment)
        );
        if (!success) revert TransferFailed();

        emit PrivateDeposit(poolId, msg.sender, pool.denomination, commitment);
    }

    /**
     * @notice Deposit to Tornado Cash for privacy (ERC20)
     * @param poolId The privacy pool to use
     * @param commitment The commitment hash (generated off-chain)
     */
    function privateDepositERC20(
        bytes32 poolId,
        bytes32 commitment
    ) external nonReentrant {
        PrivacyPool storage pool = privacyPools[poolId];
        if (!pool.isActive) revert PoolNotActive();
        if (pool.token == address(0)) revert InvalidToken();

        uint256 denomination = pool.denomination;

        // Transfer tokens from sender to this contract, then to Tornado
        IERC20 token = IERC20(pool.token);
        uint256 balanceBefore = token.balanceOf(pool.tornadoInstance);

        bool success = token.transferFrom(msg.sender, pool.tornadoInstance, denomination);
        if (!success) revert TransferFailed();

        // Verify transfer succeeded
        uint256 balanceAfter = token.balanceOf(pool.tornadoInstance);
        if (balanceAfter != balanceBefore + denomination) revert TransferFailed();

        // Call Tornado deposit function
        (success, ) = pool.tornadoInstance.call(
            abi.encodeWithSignature("deposit(bytes32)", commitment)
        );
        if (!success) revert TransferFailed();

        emit PrivateDeposit(poolId, msg.sender, denomination, commitment);
    }

    /**
     * @notice Batch deposit multiple amounts for enhanced privacy
     * @param poolIds Array of pool IDs
     * @param commitments Array of commitments
     */
    function privateDepositBatch(
        bytes32[] calldata poolIds,
        bytes32[] calldata commitments
    ) external payable nonReentrant {
        require(poolIds.length == commitments.length, "Length mismatch");

        uint256 totalEthValue = 0;

        for (uint256 i = 0; i < poolIds.length; i++) {
            PrivacyPool storage pool = privacyPools[poolIds[i]];
            if (!pool.isActive) revert PoolNotActive();

            if (pool.token == address(0)) {
                totalEthValue += pool.denomination;
            } else {
                // ERC20 handling
                IERC20 token = IERC20(pool.token);
                bool success = token.transferFrom(
                    msg.sender,
                    pool.tornadoInstance,
                    pool.denomination
                );
                if (!success) revert TransferFailed();
            }

            (bool success, ) = pool.tornadoInstance.call{value: pool.token == address(0) ? pool.denomination : 0}(
                abi.encodeWithSignature("deposit(bytes32)", commitments[i])
            );
            if (!success) revert TransferFailed();

            emit PrivateDeposit(poolIds[i], msg.sender, pool.denomination, commitments[i]);
        }

        if (totalEthValue > msg.value) revert InvalidAmount();
    }

    // ============================================
    // WITHDRAWAL FUNCTIONS
    // ============================================

    /**
     * @notice Withdraw through relayer for privacy (direct)
     * @param poolId The privacy pool
     * @param proof ZK-SNARK proof
     * @param root Merkle root
     * @param nullifierHash Nullifier hash
     * @param recipient Withdrawal recipient
     * @param relayer Relayer address (for fee)
     * @param fee Relayer fee
     * @param refund Refund amount
     */
    function privateWithdraw(
        bytes32 poolId,
        bytes calldata proof,
        bytes32 root,
        bytes32 nullifierHash,
        address payable recipient,
        address payable relayer,
        uint256 fee,
        uint256 refund
    ) external nonReentrant {
        PrivacyPool storage pool = privacyPools[poolId];
        if (!pool.isActive) revert PoolNotActive();

        // Calculate protocol fee
        uint256 protocolFee = (pool.denomination * protocolFeeBps) / 10000;
        uint256 totalFee = fee + protocolFee;

        // Execute withdrawal through Tornado
        (bool success, ) = pool.tornadoInstance.call{value: pool.token == address(0) ? pool.denomination : 0}(
            abi.encodeWithSignature(
                "withdraw(bytes,bytes32,bytes32,address,address,uint256,uint256)",
                proof, root, nullifierHash, recipient, relayer, totalFee, refund
            )
        );
        if (!success) revert TransferFailed();

        // Track protocol fee for ERC20 pools
        if (pool.token != address(0)) {
            accumulatedFees[pool.token] += protocolFee;
        }

        emit PrivateWithdrawal(poolId, recipient, pool.denomination, relayer, totalFee);
    }

    /**
     * @notice Relayer withdrawal function
     * @param poolId The privacy pool
     * @param proof ZK-SNARK proof
     * @param root Merkle root
     * @param nullifierHash Nullifier hash
     * @param recipient Withdrawal recipient
     * @param fee Relayer fee
     */
    function relayerWithdraw(
        bytes32 poolId,
        bytes calldata proof,
        bytes32 root,
        bytes32 nullifierHash,
        address payable recipient,
        uint256 fee
    ) external nonReentrant {
        if (!authorizedRelayers[msg.sender]) revert UnauthorizedRelayer();

        PrivacyPool storage pool = privacyPools[poolId];
        if (!pool.isActive) revert PoolNotActive();

        uint256 protocolFee = (pool.denomination * protocolFeeBps) / 10000;
        uint256 totalFee = fee + protocolFee;

        (bool success, ) = pool.tornadoInstance.call{value: pool.token == address(0) ? pool.denomination : 0}(
            abi.encodeWithSignature(
                "withdraw(bytes,bytes32,bytes32,address,address,uint256,uint256)",
                proof, root, nullifierHash, recipient, msg.sender, totalFee, 0
            )
        );
        if (!success) revert TransferFailed();

        if (pool.token != address(0)) {
            accumulatedFees[pool.token] += protocolFee;
        }

        emit PrivateWithdrawal(poolId, recipient, pool.denomination, msg.sender, totalFee);
    }

    // ============================================
    // POOL MANAGEMENT
    // ============================================

    /**
     * @notice Add a new privacy pool
     * @param poolId Unique identifier for the pool
     * @param tornadoInstance Tornado Cash contract address
     * @param denomination Deposit amount
     * @param token Token address (address(0) for ETH)
     */
    function addPrivacyPool(
        bytes32 poolId,
        address tornadoInstance,
        uint256 denomination,
        address token
    ) external onlyOwner {
        require(tornadoInstance != address(0), "Invalid instance");
        require(denomination > 0, "Invalid denomination");
        require(privacyPools[poolId].tornadoInstance == address(0), "Pool exists");

        privacyPools[poolId] = PrivacyPool({
            tornadoInstance: tornadoInstance,
            denomination: denomination,
            token: token,
            isActive: true
        });

        authorizedTornadoInstances[tornadoInstance] = true;
        poolList.push(poolId);

        emit PrivacyPoolAdded(poolId, tornadoInstance, denomination, token);
    }

    /**
     * @notice Deactivate a privacy pool (keeps history, prevents new deposits)
     * @param poolId Pool ID to deactivate
     */
    function deactivatePrivacyPool(bytes32 poolId) external onlyOwner {
        PrivacyPool storage pool = privacyPools[poolId];
        if (pool.tornadoInstance == address(0)) revert PoolNotFound();

        pool.isActive = false;
        emit PrivacyPoolDeactivated(poolId);
    }

    /**
     * @notice Remove a privacy pool entirely
     * @param poolId Pool ID to remove
     */
    function removePrivacyPool(bytes32 poolId) external onlyOwner {
        PrivacyPool storage pool = privacyPools[poolId];
        if (pool.tornadoInstance == address(0)) revert PoolNotFound();

        address tornadoInstance = pool.tornadoInstance;
        delete privacyPools[poolId];
        authorizedTornadoInstances[tornadoInstance] = false;

        // Remove from pool list
        for (uint256 i = 0; i < poolList.length; i++) {
            if (poolList[i] == poolId) {
                poolList[i] = poolList[poolList.length - 1];
                poolList.pop();
                break;
            }
        }

        emit PrivacyPoolRemoved(poolId);
    }

    // ============================================
    // RELAYER MANAGEMENT
    // ============================================

    /**
     * @notice Add authorized relayer
     * @param relayer Relayer address
     */
    function addRelayer(address relayer) external onlyOwner {
        require(relayer != address(0), "Invalid relayer");
        authorizedRelayers[relayer] = true;
        emit RelayerAdded(relayer);
    }

    /**
     * @notice Remove relayer
     * @param relayer Relayer address
     */
    function removeRelayer(address relayer) external onlyOwner {
        authorizedRelayers[relayer] = false;
        emit RelayerRemoved(relayer);
    }

    /**
     * @notice Check if address is authorized relayer
     * @param relayer Address to check
     */
    function isRelayer(address relayer) external view returns (bool) {
        return authorizedRelayers[relayer];
    }

    // ============================================
    // FEE MANAGEMENT
    // ============================================

    /**
     * @notice Update protocol fee
     * @param newFeeBps New fee in basis points
     */
    function setProtocolFee(uint256 newFeeBps) external onlyOwner {
        require(newFeeBps >= MIN_PRIVACY_FEE && newFeeBps <= MAX_PRIVACY_FEE, "Invalid fee");
        protocolFeeBps = newFeeBps;
        emit ProtocolFeeUpdated(newFeeBps);
    }

    /**
     * @notice Withdraw accumulated fees
     * @param token Token address (address(0) for ETH)
     * @param to Recipient address
     * @param amount Amount to withdraw
     */
    function withdrawFees(
        address token,
        address to,
        uint256 amount
    ) external onlyOwner {
        require(to != address(0), "Invalid recipient");

        if (token == address(0)) {
            uint256 balance = address(this).balance;
            if (amount > balance) amount = balance;
            (bool success, ) = to.call{value: amount}("");
            if (!success) revert TransferFailed();
        } else {
            uint256 available = accumulatedFees[token];
            if (amount > available) amount = available;
            accumulatedFees[token] -= amount;
            bool success = IERC20(token).transfer(to, amount);
            if (!success) revert TransferFailed();
        }

        emit FeesWithdrawn(token, to, amount);
    }

    /**
     * @notice Get accumulated fees for a token
     * @param token Token address
     */
    function getAccumulatedFees(address token) external view returns (uint256) {
        return accumulatedFees[token];
    }

    // ============================================
    // VIEW FUNCTIONS
    // ============================================

    /**
     * @notice Get privacy pool details
     * @param poolId Pool ID
     */
    function getPrivacyPool(bytes32 poolId) external view returns (
        address tornadoInstance,
        uint256 denomination,
        address token,
        bool isActive
    ) {
        PrivacyPool memory pool = privacyPools[poolId];
        return (
            pool.tornadoInstance,
            pool.denomination,
            pool.token,
            pool.isActive
        );
    }

    /**
     * @notice Get all pool IDs
     */
    function getAllPoolIds() external view returns (bytes32[] memory) {
        return poolList;
    }

    /**
     * @notice Get active pools
     */
    function getActivePools() external view returns (bytes32[] memory) {
        uint256 activeCount = 0;
        for (uint256 i = 0; i < poolList.length; i++) {
            if (privacyPools[poolList[i]].isActive) {
                activeCount++;
            }
        }

        bytes32[] memory activePools = new bytes32[](activeCount);
        uint256 index = 0;
        for (uint256 i = 0; i < poolList.length; i++) {
            if (privacyPools[poolList[i]].isActive) {
                activePools[index++] = poolList[i];
            }
        }

        return activePools;
    }

    /**
     * @notice Calculate fee for an amount
     * @param amount Deposit/withdrawal amount
     */
    function calculateFee(uint256 amount) external view returns (uint256) {
        return (amount * protocolFeeBps) / 10000;
    }

    // ============================================
    // EMERGENCY FUNCTIONS
    // ============================================

    /**
     * @notice Emergency pause - deactivate all pools
     */
    function emergencyPause() external onlyOwner {
        for (uint256 i = 0; i < poolList.length; i++) {
            privacyPools[poolList[i]].isActive = false;
        }
    }

    /**
     * @notice Resume paused pools
     * @param poolIds Pools to resume
     */
    function resumePools(bytes32[] calldata poolIds) external onlyOwner {
        for (uint256 i = 0; i < poolIds.length; i++) {
            privacyPools[poolIds[i]].isActive = true;
        }
    }

    // ============================================
    // RECEIVE ETHER
    // ============================================

    receive() external payable {}
}
</file>

<file path="contracts/hardhat.config.js">
require("@nomicfoundation/hardhat-waffle");
require("@nomicfoundation/hardhat-ethers");
require("hardhat-gas-reporter");
require("@nomicfoundation/hardhat-chai-matchers");

module.exports = {
  solidity: {
    version: "0.8.20",
    settings: {
      optimizer: {
        enabled: true,
        runs: 200
      }
    }
  },
  networks: {
    hardhat: {
      chainId: 31337,
      accounts: {
        count: 20,
        accountsBalance: "1000000000000000000000000" // 1M BLF each
      }
    },
    localhost: {
      url: "http://127.0.0.1:8545",
      chainId: 31337
    },
    finallica_testnet: {
      url: process.env.FINALICA_RPC || "https://rpc.testnet.finallica.io",
      chainId: 31337,
      accounts: process.env.PRIVATE_KEY ? [process.env.PRIVATE_KEY] : []
    }
  },
  paths: {
    sources: "./contracts",
    tests: "./test",
    cache: "./cache",
    artifacts: "./artifacts"
  },
  gasReporter: {
    enabled: true,
    currency: "USD",
    gasPrice: 20,
    coinmarketcap: "ETH"
  }
};
</file>

<file path="contracts/package.json">
{
  "name": "finallica-contracts",
  "version": "1.0.0",
  "description": "Smart contracts for Finallica governance and consensus",
  "main": "index.js",
  "scripts": {
    "compile": "hardhat compile",
    "test": "hardhat test",
    "deploy": "hardhat run scripts/deploy.js --network localhost"
  },
  "dependencies": {
    "@openzeppelin/contracts": "^4.9.3",
    "@nomicfoundation/hardhat-ethers": "^3.0.0",
    "ethers": "^6.9.0",
    "hardhat": "^2.19.0"
  },
  "devDependencies": {
    "@nomicfoundation/hardhat-chai-matchers": "^2.0.0",
    "chai": "^4.3.10",
    "hardhat-gas-reporter": "^1.0.8"
  }
}
</file>

<file path="docs/finallica/.git/COMMIT_EDITMSG">
Initial commit - Finallica documentation
</file>

<file path="docs/finallica/.git/config">
[core]
	repositoryformatversion = 0
	filemode = false
	bare = false
	logallrefupdates = true
	ignorecase = true
</file>

<file path="docs/finallica/.git/description">
Unnamed repository; edit this file 'description' to name the repository.
</file>

<file path="docs/finallica/.git/HEAD">
ref: refs/heads/master
</file>

<file path="docs/finallica/.git/hooks/applypatch-msg.sample">
#!/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

. git-sh-setup
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
:
</file>

<file path="docs/finallica/.git/hooks/commit-msg.sample">
#!/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".

# Uncomment the below to add a Signed-off-by line to the message.
# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
# hook is more suited to it.
#
# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"

# This example catches duplicate Signed-off-by lines.

test "" = "$(grep '^Signed-off-by: ' "$1" |
	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
	echo >&2 Duplicate Signed-off-by lines.
	exit 1
}
</file>

<file path="docs/finallica/.git/hooks/fsmonitor-watchman.sample">
#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#
# The hook is passed a version (currently 2) and last update token
# formatted as a string and outputs to stdout a new update token and
# all files that have been modified since the update token. Paths must
# be relative to the root of the working tree and separated by a single NUL.
#
# To enable this hook, rename this file to "query-watchman" and set
# 'git config core.fsmonitor .git/hooks/query-watchman'
#
my ($version, $last_update_token) = @ARGV;

# Uncomment for debugging
# print STDERR "$0 $version $last_update_token\n";

# Check the hook interface version
if ($version ne 2) {
	die "Unsupported query-fsmonitor hook version '$version'.\n" .
	    "Falling back to scanning...\n";
}

my $git_work_tree = get_working_dir();

my $retry = 1;

my $json_pkg;
eval {
	require JSON::XS;
	$json_pkg = "JSON::XS";
	1;
} or do {
	require JSON::PP;
	$json_pkg = "JSON::PP";
};

launch_watchman();

sub launch_watchman {
	my $o = watchman_query();
	if (is_work_tree_watched($o)) {
		output_result($o->{clock}, @{$o->{files}});
	}
}

sub output_result {
	my ($clockid, @files) = @_;

	# Uncomment for debugging watchman output
	# open (my $fh, ">", ".git/watchman-output.out");
	# binmode $fh, ":utf8";
	# print $fh "$clockid\n@files\n";
	# close $fh;

	binmode STDOUT, ":utf8";
	print $clockid;
	print "\0";
	local $, = "\0";
	print @files;
}

sub watchman_clock {
	my $response = qx/watchman clock "$git_work_tree"/;
	die "Failed to get clock id on '$git_work_tree'.\n" .
		"Falling back to scanning...\n" if $? != 0;

	return $json_pkg->new->utf8->decode($response);
}

sub watchman_query {
	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
	or die "open2() failed: $!\n" .
	"Falling back to scanning...\n";

	# In the query expression below we're asking for names of files that
	# changed since $last_update_token but not from the .git folder.
	#
	# To accomplish this, we're using the "since" generator to use the
	# recency index to select candidate nodes and "fields" to limit the
	# output to file names only. Then we're using the "expression" term to
	# further constrain the results.
	my $last_update_line = "";
	if (substr($last_update_token, 0, 1) eq "c") {
		$last_update_token = "\"$last_update_token\"";
		$last_update_line = qq[\n"since": $last_update_token,];
	}
	my $query = <<"	END";
		["query", "$git_work_tree", {$last_update_line
			"fields": ["name"],
			"expression": ["not", ["dirname", ".git"]]
		}]
	END

	# Uncomment for debugging the watchman query
	# open (my $fh, ">", ".git/watchman-query.json");
	# print $fh $query;
	# close $fh;

	print CHLD_IN $query;
	close CHLD_IN;
	my $response = do {local $/; <CHLD_OUT>};

	# Uncomment for debugging the watch response
	# open ($fh, ">", ".git/watchman-response.json");
	# print $fh $response;
	# close $fh;

	die "Watchman: command returned no output.\n" .
	"Falling back to scanning...\n" if $response eq "";
	die "Watchman: command returned invalid output: $response\n" .
	"Falling back to scanning...\n" unless $response =~ /^\{/;

	return $json_pkg->new->utf8->decode($response);
}

sub is_work_tree_watched {
	my ($output) = @_;
	my $error = $output->{error};
	if ($retry > 0 and $error and $error =~ m/unable to resolve root .* directory (.*) is not watched/) {
		$retry--;
		my $response = qx/watchman watch "$git_work_tree"/;
		die "Failed to make watchman watch '$git_work_tree'.\n" .
		    "Falling back to scanning...\n" if $? != 0;
		$output = $json_pkg->new->utf8->decode($response);
		$error = $output->{error};
		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		# Uncomment for debugging watchman output
		# open (my $fh, ">", ".git/watchman-output.out");
		# close $fh;

		# Watchman will always return all files on the first query so
		# return the fast "everything is dirty" flag to git and do the
		# Watchman query just to get it over with now so we won't pay
		# the cost in git to look up each individual file.
		my $o = watchman_clock();
		$error = $output->{error};

		die "Watchman: $error.\n" .
		"Falling back to scanning...\n" if $error;

		output_result($o->{clock}, ("/"));
		$last_update_token = $o->{clock};

		eval { launch_watchman() };
		return 0;
	}

	die "Watchman: $error.\n" .
	"Falling back to scanning...\n" if $error;

	return 1;
}

sub get_working_dir {
	my $working_dir;
	if ($^O =~ 'msys' || $^O =~ 'cygwin') {
		$working_dir = Win32::GetCwd();
		$working_dir =~ tr/\\/\//;
	} else {
		require Cwd;
		$working_dir = Cwd::cwd();
	}

	return $working_dir;
}
</file>

<file path="docs/finallica/.git/hooks/post-update.sample">
#!/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info
</file>

<file path="docs/finallica/.git/hooks/pre-applypatch.sample">
#!/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".

. git-sh-setup
precommit="$(git rev-parse --git-path hooks/pre-commit)"
test -x "$precommit" && exec "$precommit" ${1+"$@"}
:
</file>

<file path="docs/finallica/.git/hooks/pre-commit.sample">
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1
then
	against=HEAD
else
	# Initial commit: diff against an empty tree object
	against=$(git hash-object -t tree /dev/null)
fi

# If you want to allow non-ASCII filenames set this variable to true.
allownonascii=$(git config --type=bool hooks.allownonascii)

# Redirect output to stderr.
exec 1>&2

# Cross platform projects tend to avoid non-ASCII filenames; prevent
# them from being added to the repository. We exploit the fact that the
# printable range starts at the space character and ends with tilde.
if [ "$allownonascii" != "true" ] &&
	# Note that the use of brackets around a tr range is ok here, (it's
	# even required, for portability to Solaris 10's /usr/bin/tr), since
	# the square bracket bytes happen to fall in the designated range.
	test $(git diff-index --cached --name-only --diff-filter=A -z $against |
	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
then
	cat <<\EOF
Error: Attempt to add a non-ASCII file name.

This can cause problems if you want to work with people on other platforms.

To be portable it is advisable to rename the file.

If you know what you are doing you can disable this check using:

  git config hooks.allownonascii true
EOF
	exit 1
fi

# If there are whitespace errors, print the offending file names and fail.
exec git diff-index --check --cached $against --
</file>

<file path="docs/finallica/.git/hooks/pre-merge-commit.sample">
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git merge" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message to
# stderr if it wants to stop the merge commit.
#
# To enable this hook, rename this file to "pre-merge-commit".

. git-sh-setup
test -x "$GIT_DIR/hooks/pre-commit" &&
        exec "$GIT_DIR/hooks/pre-commit"
:
</file>

<file path="docs/finallica/.git/hooks/pre-push.sample">
#!/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done
#
# If pushing without using a named remote those arguments will be equal.
#
# Information about the commits which are being pushed is supplied as lines to
# the standard input in the form:
#
#   <local ref> <local oid> <remote ref> <remote oid>
#
# This sample shows how to prevent push of commits where the log message starts
# with "WIP" (work in progress).

remote="$1"
url="$2"

zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')

while read local_ref local_oid remote_ref remote_oid
do
	if test "$local_oid" = "$zero"
	then
		# Handle delete
		:
	else
		if test "$remote_oid" = "$zero"
		then
			# New branch, examine all commits
			range="$local_oid"
		else
			# Update to existing branch, examine new commits
			range="$remote_oid..$local_oid"
		fi

		# Check for WIP commit
		commit=$(git rev-list -n 1 --grep '^WIP' "$range")
		if test -n "$commit"
		then
			echo >&2 "Found WIP commit in $local_ref, not pushing"
			exit 1
		fi
	fi
done

exit 0
</file>

<file path="docs/finallica/.git/hooks/pre-rebase.sample">
#!/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#
# $1 -- the upstream the series was forked from.
# $2 -- the branch being rebased (or empty when rebasing the current branch).
#
# This sample shows how to prevent topic branches that are already
# merged to 'next' branch from getting rebased, because allowing it
# would result in rebasing already published history.

publish=next
basebranch="$1"
if test "$#" = 2
then
	topic="refs/heads/$2"
else
	topic=`git symbolic-ref HEAD` ||
	exit 0 ;# we do not interrupt rebasing detached HEAD
fi

case "$topic" in
refs/heads/??/*)
	;;
*)
	exit 0 ;# we do not interrupt others.
	;;
esac

# Now we are dealing with a topic branch being rebased
# on top of master.  Is it OK to rebase it?

# Does the topic really exist?
git show-ref -q "$topic" || {
	echo >&2 "No such branch $topic"
	exit 1
}

# Is topic fully merged to master?
not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
if test -z "$not_in_master"
then
	echo >&2 "$topic is fully merged to master; better remove it."
	exit 1 ;# we could allow it, but there is no point.
fi

# Is topic ever merged to next?  If so you should not be rebasing it.
only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
only_next_2=`git rev-list ^master           ${publish} | sort`
if test "$only_next_1" = "$only_next_2"
then
	not_in_topic=`git rev-list "^$topic" master`
	if test -z "$not_in_topic"
	then
		echo >&2 "$topic is already up to date with master"
		exit 1 ;# we could allow it, but there is no point.
	else
		exit 0
	fi
else
	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
	/usr/bin/perl -e '
		my $topic = $ARGV[0];
		my $msg = "* $topic has commits already merged to public branch:\n";
		my (%not_in_next) = map {
			/^([0-9a-f]+) /;
			($1 => 1);
		} split(/\n/, $ARGV[1]);
		for my $elem (map {
				/^([0-9a-f]+) (.*)$/;
				[$1 => $2];
			} split(/\n/, $ARGV[2])) {
			if (!exists $not_in_next{$elem->[0]}) {
				if ($msg) {
					print STDERR $msg;
					undef $msg;
				}
				print STDERR " $elem->[1]\n";
			}
		}
	' "$topic" "$not_in_next" "$not_in_master"
	exit 1
fi

<<\DOC_END

This sample hook safeguards topic branches that have been
published from being rewound.

The workflow assumed here is:

 * Once a topic branch forks from "master", "master" is never
   merged into it again (either directly or indirectly).

 * Once a topic branch is fully cooked and merged into "master",
   it is deleted.  If you need to build on top of it to correct
   earlier mistakes, a new topic branch is created by forking at
   the tip of the "master".  This is not strictly necessary, but
   it makes it easier to keep your history simple.

 * Whenever you need to test or publish your changes to topic
   branches, merge them into "next" branch.

The script, being an example, hardcodes the publish branch name
to be "next", but it is trivial to make it configurable via
$GIT_DIR/config mechanism.

With this workflow, you would want to know:

(1) ... if a topic branch has ever been merged to "next".  Young
    topic branches can have stupid mistakes you would rather
    clean up before publishing, and things that have not been
    merged into other branches can be easily rebased without
    affecting other people.  But once it is published, you would
    not want to rewind it.

(2) ... if a topic branch has been fully merged to "master".
    Then you can delete it.  More importantly, you should not
    build on top of it -- other people may already want to
    change things related to the topic as patches against your
    "master", so if you need further changes, it is better to
    fork the topic (perhaps with the same name) afresh from the
    tip of "master".

Let's look at this example:

		   o---o---o---o---o---o---o---o---o---o "next"
		  /       /           /           /
		 /   a---a---b A     /           /
		/   /               /           /
	       /   /   c---c---c---c B         /
	      /   /   /             \         /
	     /   /   /   b---b C     \       /
	    /   /   /   /             \     /
    ---o---o---o---o---o---o---o---o---o---o---o "master"


A, B and C are topic branches.

 * A has one fix since it was merged up to "next".

 * B has finished.  It has been fully merged up to "master" and "next",
   and is ready to be deleted.

 * C has not merged to "next" at all.

We would want to allow C to be rebased, refuse A, and encourage
B to be deleted.

To compute (1):

	git rev-list ^master ^topic next
	git rev-list ^master        next

	if these match, topic has not merged in next at all.

To compute (2):

	git rev-list master..topic

	if this is empty, it is fully merged to "master".

DOC_END
</file>

<file path="docs/finallica/.git/hooks/pre-receive.sample">
#!/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then
	i=0
	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
	do
		eval "value=\$GIT_PUSH_OPTION_$i"
		case "$value" in
		echoback=*)
			echo "echo from the pre-receive-hook: ${value#*=}" >&2
			;;
		reject)
			exit 1
		esac
		i=$((i + 1))
	done
fi
</file>

<file path="docs/finallica/.git/hooks/prepare-commit-msg.sample">
#!/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

# This hook includes three examples. The first one removes the
# "# Please enter the commit message..." help message.
#
# The second includes the output of "git diff --name-status -r"
# into the message, just before the "git status" output.  It is
# commented because it doesn't cope with --amend or with squashed
# commits.
#
# The third example adds a Signed-off-by line to the message, that can
# still be edited.  This is rarely a good idea.

COMMIT_MSG_FILE=$1
COMMIT_SOURCE=$2
SHA1=$3

/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"

# case "$COMMIT_SOURCE,$SHA1" in
#  ,|template,)
#    /usr/bin/perl -i.bak -pe '
#       print "\n" . `git diff --cached --name-status -r`
# 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
#  *) ;;
# esac

# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
# if test -z "$COMMIT_SOURCE"
# then
#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
# fi
</file>

<file path="docs/finallica/.git/hooks/push-to-checkout.sample">
#!/bin/sh

# An example hook script to update a checked-out tree on a git push.
#
# This hook is invoked by git-receive-pack(1) when it reacts to git
# push and updates reference(s) in its repository, and when the push
# tries to update the branch that is currently checked out and the
# receive.denyCurrentBranch configuration variable is set to
# updateInstead.
#
# By default, such a push is refused if the working tree and the index
# of the remote repository has any difference from the currently
# checked out commit; when both the working tree and the index match
# the current commit, they are updated to match the newly pushed tip
# of the branch. This hook is to be used to override the default
# behaviour; however the code below reimplements the default behaviour
# as a starting point for convenient modification.
#
# The hook receives the commit with which the tip of the current
# branch is going to be updated:
commit=$1

# It can exit with a non-zero status to refuse the push (when it does
# so, it must not modify the index or the working tree).
die () {
	echo >&2 "$*"
	exit 1
}

# Or it can make any necessary changes to the working tree and to the
# index to bring them to the desired state when the tip of the current
# branch is updated to the new commit, and exit with a zero status.
#
# For example, the hook can simply run git read-tree -u -m HEAD "$1"
# in order to emulate git fetch that is run in the reverse direction
# with git push, as the two-tree form of git read-tree -u -m is
# essentially the same as git switch or git checkout that switches
# branches while keeping the local changes in the working tree that do
# not interfere with the difference between the branches.

# The below is a more-or-less exact translation to shell of the C code
# for the default behaviour for git's push-to-checkout hook defined in
# the push_to_deploy() function in builtin/receive-pack.c.
#
# Note that the hook will be executed from the repository directory,
# not from the working tree, so if you want to perform operations on
# the working tree, you will have to adapt your code accordingly, e.g.
# by adding "cd .." or using relative paths.

if ! git update-index -q --ignore-submodules --refresh
then
	die "Up-to-date check failed"
fi

if ! git diff-files --quiet --ignore-submodules --
then
	die "Working directory has unstaged changes"
fi

# This is a rough translation of:
#
#   head_has_history() ? "HEAD" : EMPTY_TREE_SHA1_HEX
if git cat-file -e HEAD 2>/dev/null
then
	head=HEAD
else
	head=$(git hash-object -t tree --stdin </dev/null)
fi

if ! git diff-index --quiet --cached --ignore-submodules $head --
then
	die "Working directory has staged changes"
fi

if ! git read-tree -u -m "$commit"
then
	die "Could not update working tree to new HEAD"
fi
</file>

<file path="docs/finallica/.git/hooks/sendemail-validate.sample">
#!/bin/sh

# An example hook script to validate a patch (and/or patch series) before
# sending it via email.
#
# The hook should exit with non-zero status after issuing an appropriate
# message if it wants to prevent the email(s) from being sent.
#
# To enable this hook, rename this file to "sendemail-validate".
#
# By default, it will only check that the patch(es) can be applied on top of
# the default upstream branch without conflicts in a secondary worktree. After
# validation (successful or not) of the last patch of a series, the worktree
# will be deleted.
#
# The following config variables can be set to change the default remote and
# remote ref that are used to apply the patches against:
#
#   sendemail.validateRemote (default: origin)
#   sendemail.validateRemoteRef (default: HEAD)
#
# Replace the TODO placeholders with appropriate checks according to your
# needs.

validate_cover_letter () {
	file="$1"
	# TODO: Replace with appropriate checks (e.g. spell checking).
	true
}

validate_patch () {
	file="$1"
	# Ensure that the patch applies without conflicts.
	git am -3 "$file" || return
	# TODO: Replace with appropriate checks for this patch
	# (e.g. checkpatch.pl).
	true
}

validate_series () {
	# TODO: Replace with appropriate checks for the whole series
	# (e.g. quick build, coding style checks, etc.).
	true
}

# main -------------------------------------------------------------------------

if test "$GIT_SENDEMAIL_FILE_COUNTER" = 1
then
	remote=$(git config --default origin --get sendemail.validateRemote) &&
	ref=$(git config --default HEAD --get sendemail.validateRemoteRef) &&
	worktree=$(mktemp --tmpdir -d sendemail-validate.XXXXXXX) &&
	git worktree add -fd --checkout "$worktree" "refs/remotes/$remote/$ref" &&
	git config --replace-all sendemail.validateWorktree "$worktree"
else
	worktree=$(git config --get sendemail.validateWorktree)
fi || {
	echo "sendemail-validate: error: failed to prepare worktree" >&2
	exit 1
}

unset GIT_DIR GIT_WORK_TREE
cd "$worktree" &&

if grep -q "^diff --git " "$1"
then
	validate_patch "$1"
else
	validate_cover_letter "$1"
fi &&

if test "$GIT_SENDEMAIL_FILE_COUNTER" = "$GIT_SENDEMAIL_FILE_TOTAL"
then
	git config --unset-all sendemail.validateWorktree &&
	trap 'git worktree remove -ff "$worktree"' EXIT &&
	validate_series
fi
</file>

<file path="docs/finallica/.git/hooks/update.sample">
#!/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated
#   This boolean sets whether unannotated tags will be allowed into the
#   repository.  By default they won't be.
# hooks.allowdeletetag
#   This boolean sets whether deleting tags will be allowed in the
#   repository.  By default they won't be.
# hooks.allowmodifytag
#   This boolean sets whether a tag may be modified after creation. By default
#   it won't be.
# hooks.allowdeletebranch
#   This boolean sets whether deleting branches will be allowed in the
#   repository.  By default they won't be.
# hooks.denycreatebranch
#   This boolean sets whether remotely creating branches will be denied
#   in the repository.  By default this is allowed.
#

# --- Command line
refname="$1"
oldrev="$2"
newrev="$3"

# --- Safety check
if [ -z "$GIT_DIR" ]; then
	echo "Don't run this script from the command line." >&2
	echo " (if you want, you could supply GIT_DIR then run" >&2
	echo "  $0 <ref> <oldrev> <newrev>)" >&2
	exit 1
fi

if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
	exit 1
fi

# --- Config
allowunannotated=$(git config --type=bool hooks.allowunannotated)
allowdeletebranch=$(git config --type=bool hooks.allowdeletebranch)
denycreatebranch=$(git config --type=bool hooks.denycreatebranch)
allowdeletetag=$(git config --type=bool hooks.allowdeletetag)
allowmodifytag=$(git config --type=bool hooks.allowmodifytag)

# check for no description
projectdesc=$(sed -e '1q' "$GIT_DIR/description")
case "$projectdesc" in
"Unnamed repository"* | "")
	echo "*** Project description file hasn't been set" >&2
	exit 1
	;;
esac

# --- Check types
# if $newrev is 0000...0000, it's a commit to delete a ref.
zero=$(git hash-object --stdin </dev/null | tr '[0-9a-f]' '0')
if [ "$newrev" = "$zero" ]; then
	newrev_type=delete
else
	newrev_type=$(git cat-file -t $newrev)
fi

case "$refname","$newrev_type" in
	refs/tags/*,commit)
		# un-annotated tag
		short_refname=${refname##refs/tags/}
		if [ "$allowunannotated" != "true" ]; then
			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
			exit 1
		fi
		;;
	refs/tags/*,delete)
		# delete tag
		if [ "$allowdeletetag" != "true" ]; then
			echo "*** Deleting a tag is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/tags/*,tag)
		# annotated tag
		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
		then
			echo "*** Tag '$refname' already exists." >&2
			echo "*** Modifying a tag is not allowed in this repository." >&2
			exit 1
		fi
		;;
	refs/heads/*,commit)
		# branch
		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
			echo "*** Creating a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/heads/*,delete)
		# delete branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/remotes/*,commit)
		# tracking branch
		;;
	refs/remotes/*,delete)
		# delete tracking branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	*)
		# Anything else (is there anything else?)
		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
		exit 1
		;;
esac

# --- Finished
exit 0
</file>

<file path="docs/finallica/.git/info/exclude">
# git ls-files --others --exclude-from=.git/info/exclude
# Lines that start with '#' are comments.
# For a project mostly in C, the following would be a good set of
# exclude patterns (uncomment them if you want to use them):
# *.[oa]
# *~
</file>

<file path="docs/finallica/.git/logs/HEAD">
0000000000000000000000000000000000000000 3c2361557fdc2e2a3ecf671cbb5fb44413ec1f75 OpenScroll Dev <122853803+owenservera@users.noreply.github.com> 1766444708 +0100	commit (initial): Initial commit - Finallica documentation
</file>

<file path="docs/finallica/.git/logs/refs/heads/master">
0000000000000000000000000000000000000000 3c2361557fdc2e2a3ecf671cbb5fb44413ec1f75 OpenScroll Dev <122853803+owenservera@users.noreply.github.com> 1766444708 +0100	commit (initial): Initial commit - Finallica documentation
</file>

<file path="docs/finallica/.git/refs/heads/master">
3c2361557fdc2e2a3ecf671cbb5fb44413ec1f75
</file>

<file path="docs/finallica/ARCHITECTURE_OVERVIEW.md">
# Finallica Architecture Overview

This document describes the macro network architecture and end-to-end payment flow of the Finallica global financial privacy network.

---

## Section 1: Macro Network Architecture

### 1.1 Global Topology

The Finallica network operates as a **trust-minimized settlement overlay** consisting of:

- **127 jurisdictional shards** for regulatory compliance and latency optimization
- **~12,000 Validator-Routers (VRs)** distributed globally
- **8 Consensus Notaries** providing BFT state root signatures
- **15,240 cross-shard bridge links** connecting shards

### 1.2 Consensus Notaries (8 Authorities)

Eight geo-distributed notaries maintain the global state root:

| Notary | Location | BLS Pubkey | Stake |
|--------|----------|------------|-------|
| Notary1 | Switzerland | 0x1a2b... | 50M BLF |
| Notary2 | Singapore | 0x3c4d... | 48M BLF |
| Notary3 | Iceland | 0x5e6f... | 52M BLF |
| Notary4 | Canada | 0x7a8b... | 45M BLF |
| Notary5 | New Zealand | 0x9c0d... | 51M BLF |
| Notary6 | Germany | 0xae1f... | 47M BLF |
| Notary7 | Japan | 0xbf2a... | 49M BLF |
| Notary8 | USA | 0xd03c... | 46M BLF |

**Notary Responsibilities**:
- Publish global state root every 10 seconds
- Sign state root with BLS12-381 aggregated signatures (5 of 8 threshold)
- Validate shard state proofs via STARKs

### 1.3 Shard Topology (127 Shards)

Each shard is a **Crandall clique** of Validator-Routers:

```
Shard N topology:

 N = floor(  stake_weight) where  = 2.5                   
 Full-mesh TLS connections between all VRs in shard          
 Deterministic bipartite graph for cross-shard bridges       
 Bridge selection: top 5% stake in each shard                

```

#### Example: Shard 0 (North America)

| VR ID | IP Address | Role | Stake | Fee | Flags |
|-------|------------|------|-------|-----|-------|
| VR-0-001 | 203.0.113.9 | Guard | 8.2M BLF | 3 bps | Guard, Bridge, Stable |
| VR-0-015 | 203.0.113.42 | Guard | 15.7M BLF | 2 bps | Guard, Bridge, Fast |
| VR-0-084 | 203.0.113.128 | Guard | 4.1M BLF | 5 bps | Guard |
| VR-0-341 | 203.0.114.55 | Middle | 2.8M BLF | 4 bps | - |
| VR-0-552 | 203.0.115.72 | Middle | 6.3M BLF | 3 bps | - |
| VR-0-891 | 203.0.116.18 | Middle | 1.9M BLF | 6 bps | - |
| SE-0-12 | 203.0.117.5 | Exit | 12.3M BLF | 25 bps | SWIFT, ACH, BTC |
| SE-0-45 | 203.0.117.89 | Exit | 8.7M BLF | 10 bps | ACH only |

**Shard 0 Statistics**:
- Total VRs: 2,407 (as of epoch 18492)
- Guard VRs: ~722 (top 30% by stake)
- Middle VRs: ~1,485
- Settlement Executors: ~200
- Total Stake: 4.82B BLF ($21.7B)
- Avg Stake per VR: 2.01M BLF

### 1.4 Cross-Shard Bridges

**Bridge Selection**: VRs with stake in top 5% of shard become bridges.

```
Bridges per shard: 120
Total cross-shard links: 15,240
Bridge protocol: TLS 1.3 + BLS authentication
Bridge bandwidth: 10 Gbps per link
Bridge latency: 85-92ms (inter-continental)
```

**Example Bridge**:
```
Bridge-0-1: 203.0.113.9 (Shard 0)  198.51.100.14 (Shard 1)
  Protocol: TLS 1.3
  Bandwidth: 10 Gbps
  Latency: 85ms
  Role: Shard 0  Shard 1 payment routing
```

### 1.5 Network Visualization

```mermaid
graph TB
    subgraph "Global Consensus Layer (8 Notaries)"
        N1["Notary1<br/>203.0.113.1<br/>BLS: 0x1a2b...<br/>Stake: 50M BLF<br/>Location: Switzerland"]
        N2["Notary2<br/>203.0.113.2<br/>BLS: 0x3c4d...<br/>Stake: 48M BLF<br/>Location: Singapore"]
        N3["Notary3<br/>203.0.113.3<br/>BLS: 0x5e6f...<br/>Stake: 52M BLF<br/>Location: Iceland"]
        N4["Notary4<br/>203.0.113.4<br/>BLS: 0x7a8b...<br/>Stake: 45M BLF<br/>Location: Canada"]
        N5["Notary5<br/>203.0.113.5<br/>BLS: 0x9c0d...<br/>Stake: 51M BLF<br/>Location: New Zealand"]
        N6["Notary6<br/>203.0.113.6<br/>BLS: 0xae1f...<br/>Stake: 47M BLF<br/>Location: Germany"]
        N7["Notary7<br/>203.0.113.7<br/>BLS: 0xbf2a...<br/>Stake: 49M BLF<br/>Location: Japan"]
        N8["Notary8<br/>203.0.113.8<br/>BLS: 0xd03c...<br/>Stake: 46M BLF<br/>Location: USA"]
    end

    subgraph "Shard 0 (North America) - 2,407 VRs"
        subgraph "Guard VRs (Entry) - Top 30% by stake"
            G0["VR-0-001<br/>203.0.113.9<br/>Stake: 8.2M BLF<br/>Fee: 3 bps<br/>Flags: Guard, Bridge, Stable"]
            G1["VR-0-015<br/>203.0.113.42<br/>Stake: 15.7M BLF<br/>Fee: 2 bps<br/>Flags: Guard, Bridge, Fast"]
            G2["VR-0-084<br/>203.0.113.128<br/>Stake: 4.1M BLF<br/>Fee: 5 bps<br/>Flags: Guard"]
        end

        subgraph "Middle VRs - 1,200 nodes"
            M0["VR-0-341<br/>203.0.114.55<br/>Stake: 2.8M BLF<br/>Fee: 4 bps"]
            M1["VR-0-552<br/>203.0.115.72<br/>Stake: 6.3M BLF<br/>Fee: 3 bps"]
            M2["VR-0-891<br/>203.0.116.18<br/>Stake: 1.9M BLF<br/>Fee: 6 bps"]
        end

        subgraph "Settlement Executors (Exits) - 200 nodes"
            E0["SE-0-12<br/>203.0.117.5<br/>Stake: 12.3M BLF<br/>Fee: 25 bps<br/>Rails: SWIFT, ACH, BTC"]
            E1["SE-0-45<br/>203.0.117.89<br/>Stake: 8.7M BLF<br/>Fee: 10 bps<br/>Rails: ACH only"]
        end
    end

    subgraph "Shard 1 (Europe) - 2,800 VRs"
        G10["VR-1-007<br/>198.51.100.14<br/>Stake: 11.2M BLF<br/>Fee: 2 bps<br/>Flags: Guard, Bridge"]
        E10["SE-1-33<br/>198.51.101.67<br/>Stake: 9.8M BLF<br/>Fee: 15 bps<br/>Rails: SEPA, BTC"]
    end

    subgraph "Cross-Shard Bridge Links (15,240 total)"
        B0["Bridge-0-1<br/>203.0.113.9  198.51.100.14<br/>TLS 1.3<br/>Bandwidth: 10 Gbps<br/>Latency: 85ms"]
        B1["Bridge-0-1<br/>203.0.113.42  198.51.100.203<br/>TLS 1.3<br/>Bandwidth: 10 Gbps<br/>Latency: 92ms"]
    end

    subgraph "Client Infrastructure"
        FP["Finallica Proxy<br/>127.0.0.1:31337<br/>Wallet daemon<br/>Pathfinding engine<br/>Channel manager"]
        WALLET["User Wallet UI<br/>Mobile app<br/>BOLT-11 invoice scanner"]
        API["Merchant API<br/>RFC-5546 payment pointers<br/>Webhook callbacks"]
    end

    subgraph "Legacy Settlement Rails"
        SWIFT["SWIFT Network<br/>MT103 messages<br/>Settlement time: 1-3 days"]
        ACH["ACH Network<br/>NACHA files<br/>Settlement time: 1-2 days"]
        BTC["Bitcoin L1<br/>On-chain tx<br/>Settlement time: 10 min"]
        LN["Bitcoin Lightning<br/>HTLC routing<br/>Settlement time: 3 sec"]
    end

    N1 ---|BLS sign| CONS["Global State Root<br/>SHA256 of all shard roots<br/>8 BLS signatures<br/>Valid: 10 sec"]
    N2 ---|BLS sign| CONS
    N3 ---|BLS sign| CONS
    N4 ---|BLS sign| CONS
    CONS -->|pushed| G0
    CONS -->|pushed| G1
    CONS -->|pushed| M0
    CONS -->|pushed| E0

    G0 <-->|Noise_XX + DPDK<br/>Port 31337| M0
    G0 <-->|Noise_XX + DPDK| M1
    G0 <-->|Noise_XX + DPDK| G1
    M0 <-->|Noise_XX + DPDK| M1
    M0 <-->|Noise_XX + DPDK| E0
    M1 <-->|Noise_XX + DPDK| E1
    G1 <-->|Noise_XX + DPDK| E0

    G0 ---|TLS 1.3 + BLS auth| B0
    G1 ---|TLS 1.3 + BLS auth| B1
    B0 ---|shard 1| G10
    B1 ---|shard 1| G10

    WALLET -->|Noise_XK + TCP| FP
    API -->|Noise_XK + TCP| FP
    FP -->|OPEN cell<br/>Noise handshake| G0
    FP -->|OPEN cell| G1

    E0 -->|MT103| SWIFT
    E1 -->|NACHA| ACH
    E0 -->|Bitcoin RPC| BTC
    E0 -->|gRPC| LN
```

---

## Section 2: End-to-End Payment Flow

### 2.1 Overview: $100 Invoice to Settlement

Total time: **1-3 days** (dominated by SWIFT settlement)
Internal processing: **~260ms** (channel build + HTLC attachment)

```
Phase 1: Invoice Parsing & Route Selection     (12ms)
Phase 2: Channel Construction                  (247ms p50)
Phase 3: HTLC Attachment                       (5ms)
Phase 4: Settlement Execution                  (1-3 days SWIFT)
Phase 5: Channel Rebalance                     (optional, 30s)
```

### 2.2 Phase 1: Invoice Parsing & Route Selection (12ms)

```mermaid
sequenceDiagram
    participant User as User<br/>Payer
    participant Wallet as Wallet UI<br/>Mobile app
    participant FP as Finallica Proxy<br/>127.0.0.1:31337
    participant Dir as Directory Cache<br/>/var/lib/finallica/consensus.dat

    Note over User,Dir: Phase 1: Invoice Parsing & Route Selection (12ms)
    User->>Wallet: Scan BOLT-11 invoice<br/>lnbc10u1p3y...xyz
    Wallet->>Wallet: decode_bolt11()<br/>amount=$100<br/>payment_hash=0x1a2b...<br/>expiry=3600s
    Wallet->>FP: pay_invoice(invoice, amount=10,000,000 microcents)
    FP->>Dir: get_vr_path(amount=10M, dest_shard=0, currency=USD)
    Dir-->>FP: Path: G0(3bps)  M1(4bps)  E0(25bps)<br/>Total fee: 32bps ($0.32)
    FP->>FP: select_entry_guard()<br/>Chosen: VR-0-015 (stake=15.7M, fee=2bps)<br/>Recalc fee: 31bps ($0.31)
```

**Route Selection Algorithm**:

```c
struct vr_path *select_path(
  uint64_t amount_microcents,
  uint16_t dest_shard_id,
  uint8_t required_flags) {

  // Step 1: Guard selection (persistent)
  struct entry_guard *guard = get_guard_by_shard(0);

  // Formula: weight = stake^0.7 * uptime_factor / fee_bps^2
  double weight = pow(guard->stake, 0.7) *
                  (guard->uptime_days / 30.0) /
                  (guard->fee_bps * guard->fee_bps);

  // Step 2: Middle VR selection (probabilistic)
  // Top 50 by stake, reservoir sampling

  // Step 3: Exit VR selection
  // Filter by currency support, fee < 50 bps, latency < 500ms

  return path;
}
```

### 2.3 Phase 2: Channel Construction (247ms p50)

```mermaid
sequenceDiagram
    participant FP as Finallica Proxy
    participant G as Guard VR<br/>VR-0-015
    participant M as Middle VR<br/>VR-0-552
    participant E as Settlement Executor<br/>SE-0-12

    Note over FP,E: Phase 2: Channel Construction (247ms p50)
    FP->>G: OPEN2 cell (Noise_XX)<br/>channel_id=0x4f3e2d1c<br/>ephemeral=0x9f8e..., amount=10M<br/>BLS sign: _payer
    G->>G: noise_handshake_process()<br/>X25519 DH: 90s<br/>BLAKE2s KDF: 25s<br/>BLS verify: 105s (batch)
    G->>FP: OPENED2 cell<br/>channel_id=0x4f3e2d1c<br/>K_entry derived<br/>g^y, BLS sig: _guard
    FP->>FP: KDF_Noise(g^xy)  K_pay || K_settle || K_pad

    FP->>G: EXTEND cell (encrypted w/ K_pay)<br/>Target: VR-0-552 pubkey<br/>ephemeral_mid=0x7d6c...
    G->>M: OPEN2 cell (new channel_id=0x8a7b6c5d)<br/>Noise handshake
    M->>G: OPENED2 cell
    G->>FP: EXTENDED cell<br/>K_mid derived

    FP->>G: EXTEND2 cell (encrypted K_mid)<br/>Target: SE-0-12 pubkey<br/>ephemeral_exit=0x5b4a...
    M->>E: OPEN2 cell (channel_id=0x9c8d7e6f)
    E->>M: OPENED2 cell
    M->>G: EXTENDED2
    G->>FP: EXTENDED2<br/>K_exit derived<br/>Total: 3 hops built
```

**Noise_XX Handshake Transcript**:

```
// Prologue (client  VR)
-> e  (ephemeral pubkey: 32-byte X25519)

// VR response with stake proof
<- e, ee, s, es
   e = VR ephemeral pubkey
   ee = DH(e_client, e_vr)  shared secret
   s = VR BLS12-381 pubkey (48 bytes, compressed G1)
   es = DH(e_client, s_vr)  stake binding

// Client authentication
-> s, se, psk
   s = client BLS pubkey (48 bytes)
   se = DH(e_vr, s_client)
   psk = pre-shared key from stake delegation certificate
```

### 2.4 Phase 3: HTLC Attachment (5ms)

```mermaid
sequenceDiagram
    participant FP as Finallica Proxy
    participant G as Guard VR
    participant M as Middle VR
    participant E as Settlement Executor

    Note over FP,E: Phase 3: HTLC Attachment (5ms)
    FP->>FP: attach_payment_stream()<br/>stream_id=0x0042<br/>assign_htlc_id=0x123456789abc
    FP->>G: PAY cell (stream_id=0x0042)<br/>Encrypted w/ K_pay:<br/>{amount=10M, expiry=1706035200<br/>payment_hash=0x1a2b...<br/>next_hop=VR-0-552}<br/>Pedersen commitment: C = v*G + b*H
    G->>M: PAY cell (stream_id=0x0042)<br/>Encrypted w/ K_mid<br/>Deduct from channel balance: -10M microcents
    M->>E: PAY cell (stream_id=0x0042)<br/>Encrypted w/ K_exit<br/>Deduct: -10M microcents
    E->>E: Record HTLC: id=0x123456789abc<br/>amount=10M, hash=0x1a2b...<br/>timeout=1706035200
```

### 2.5 Phase 4: Settlement Execution (1-3 days SWIFT)

```mermaid
sequenceDiagram
    participant E as Settlement Executor
    participant Bank as Beneficiary Bank<br/>SWIFT: CHASUS33XXX
    participant M as Middle VR
    participant G as Guard VR
    participant FP as Finallica Proxy
    participant Wallet as Wallet UI

    Note over E,Wallet: Phase 4: Settlement Execution (1-3 days SWIFT)
    E->>Bank: SWIFT MT103 message<br/>Beneficiary: CHASUS33XXX<br/>Amount: $99.69 (after fees)<br/>Reference: SHA256(payment_preimage)
    Bank->>Bank: Process incoming SWIFT<br/>Credit beneficiary account
    Bank->>E: MT900 confirmation (1-3 days)

    E->>M: SETTLE cell (stream_id=0x0042)<br/>preimage=0xfedcba...<br/>BLS settle sig: _exit
    M->>G: SETTLE cell
    G->>FP: SETTLE cell<br/>Verify: SHA256(preimage) == payment_hash 
    FP->>Wallet: Payment settled<br/>Txid: 0xdeadbeef...<br/>Fee: $0.31<br/>Net: $99.69
```

### 2.6 Phase 5: Channel Rebalance (optional, 30s)

```mermaid
sequenceDiagram
    participant FP as Finallica Proxy
    participant E as Settlement Executor

    Note over FP,E: Phase 5: Channel Rebalance (optional, 30s)
    FP->>E: REBALANCE cell<br/>Atomic swap: 5M microcents to refill channel
    E->>FP: REBALANCE_ACK<br/>Channel: 0x4f3e2d1c<br/>New balance: 15M microcents
```

---

## Key Takeaways

1. **Network Scale**: 127 shards, 12,000 VRs, 8 notaries
2. **Path Selection**: Stake-weighted, 3 hops (Guard  Middle  Exit)
3. **Channel Build**: 247ms p50 via Noise_XX handshakes
4. **Settlement**: 200ms internal finality, 1-3 days external (SWIFT)
5. **Privacy**: Layered encryption, Pedersen commitments, 1-in-1,200 anonymity

---

*Next: [PROTOCOL_SPECIFICATION.md](./PROTOCOL_SPECIFICATION.md) - State Machines & Cell Processing*
</file>

<file path="docs/finallica/CONSENSUS_MECHANISM.md">
# Finallica Consensus Mechanism

This document describes the HotStuff BFT consensus protocol used in Finallica for global state finalization.

---

## HotStuff BFT Protocol Overview

### 8.1 4-Phase Consensus Process

Finality achieved in **200ms** (4 network RTTs  50ms each)

```mermaid
sequenceDiagram
    participant VR as Validator Router<br/>Shard 0, Replica #42
    participant Leader as Leader VR<br/>Shard 0, View #18492
    participant Notary as Consensus Notary<br/>8 of 8 BFT
    participant Mempool as Mempool<br/>Pending HTLCs

    Note over VR,Notary: View 18492, Block Height 1,234,567
    Mempool->>Leader: 2,847 pending HTLCs<br/>Total value: $1.2M
    Leader->>Leader: Propose block<br/>hash = BLAKE2s(txs)<br/>state_root = MerkleRoot(accounts)

    Note over VR,Leader: Phase 1: PREPARE (50ms RTT)
    Leader->>VR: PREPARE(hash=0xbeef..., view=18492, justify=QC_18491)
    VR->>VR: Verify QC_18491 (8 BLS sigs)<br/>0.8ms
    VR->>Leader: PREPARE-VOTE<br/>BLS partial sig: _42
    Note over Leader: Collect 67% votes (1,605 of 2,400 VRs)

    Note over Leader: Phase 2: PRE-COMMIT (50ms RTT)
    Leader->>VR: PRE-COMMIT(hash=0xbeef..., QC_prepare)
    VR->>VR: Lock block 0xbeef...<br/>persist to disk<br/>fsync() = 2ms
    VR->>Leader: PRE-COMMIT-VOTE<br/>_42_locked

    Note over Leader: Phase 3: COMMIT (50ms RTT)
    Leader->>VR: COMMIT(hash=0xbeef..., QC_precommit)
    VR->>VR: Commit to ledger<br/>Update state root<br/>Apply HTLC settlements
    VR->>Leader: COMMIT-VOTE<br/>_42_committed

    Note over Leader,Notary: Phase 4: DECIDE (50ms RTT)
    Leader->>Notary: DECIDE(hash=0xbeef..., QC_commit, state_proof)
    Notary->>Notary: Verify QC_commit (1,605 BLS sigs)<br/>Aggregate: 125ms
    Notary->>Notary: Sign global state root<br/>8 notaries, 5ms each
    Notary->>VR: SIGNED_STATE_ROOT<br/>state_root=0xdead...<br/>8 BLS sigs aggregated

    VR->>VR: Apply finality<br/>Release settled funds<br/>channel->available_to_send += settled_amount
    Note over VR: Finality achieved: 200ms
```

---

## HotStuff Message Structures

### 8.2 Vote Message

```c
struct hotstuff_vote {
  uint64_t view_number;
  uint64_t block_height;
  uint8_t  block_hash[32];
  uint8_t  partial_signature[96];  // BLS G2 share
  uint8_t  signer_pubkey[48];      // BLS G1
  uint8_t  justification[192];     // QC from previous view
} __attribute__((packed));
```

### 8.3 Quorum Certificate (QC)

```c
struct quorum_certificate {
  uint64_t view_number;
  uint8_t  block_hash[32];
  uint8_t  aggregated_signature[96];  // BLS signature aggregation
  uint8_t  signers_bitfield[SHARD_SIZE / 8];  // 300 bytes for 2400 bits
} __attribute__((packed));
```

### 8.4 Block Proposal

```c
struct hotstuff_block {
  uint64_t view_number;
  uint64_t block_height;
  uint8_t  parent_hash[32];
  uint8_t  block_hash[32];
  uint8_t  state_root[32];
  uint16_t tx_count;
  struct hotstuff_tx *transactions;  // Array of txs
  struct quorum_certificate *justify;  // QC from previous view
} __attribute__((packed));
```

---

## BLS Signature Aggregation

### 8.5 Aggregating Partial Signatures

```c
// Aggregate 1,605 partial signatures into one QC signature
bls_signature aggregate_signatures(
  bls_signature *partial_sigs[],
  uint16_t *signer_indices,
  uint16_t count) {

  bls_signature aggregated;
  bls_signature_init(&aggregated);

  // Lagrange coefficients for threshold signature
  for (int i = 0; i < count; i++) {
    // Compute Lagrange coefficient: _i = _{ji} (j / (j - i))
    mpz_t lambda;
    compute_lagrange_coefficient(lambda, signer_indices[i], signer_indices, count);

    // Multiply signature by coefficient
    bls_signature scaled;
    bls_signature_mul(&scaled, &partial_sigs[i], lambda);

    // Add to aggregate
    bls_signature_add(&aggregated, &aggregated, &scaled);
  }

  return aggregated;
}
```

### 8.6 Verifying Aggregated Signature

```c
bool verify_qc_signature(
  struct quorum_certificate *qc,
  bls_public_key *validator_pubs[],
  uint16_t validator_count) {

  bls_signature agg_sig;
  bls_signatureDeserialize(&agg_sig, qc->aggregated_signature, 96);

  // Fast aggregate verification: e(agg_sig, G1) ==  e(H(block), pk_i)
  return bls_fast_aggregate_verify(
    &agg_sig,
    validator_pubs,
    validator_count,
    &qc->block_hash,
    32
  );
}
```

---

## State Root Commitment

### 8.7 Merkle Trie Construction

```c
struct merkle_node {
  uint8_t hash[32];
  struct merkle_node *left;
  struct merkle_node *right;
  struct account_state *value;  // NULL for internal nodes
};

// Compute state root from account states
uint8_t *compute_state_root(struct account_state accounts[], uint32_t count) {
  // Build Merkle trie from account states
  struct merkle_node *root = build_merkle_trie(accounts, count);

  // Hash root node
  uint8_t *root_hash = malloc(32);
  SHA256(root->hash, 32, root_hash);

  return root_hash;
}

// Verify Merkle proof for specific account
bool verify_merkle_proof(
  uint8_t *root_hash,
  uint8_t account_key[32],
  uint8_t account_value[32],
  uint8_t proof[][32],
  uint32_t proof_length) {

  uint8_t current_hash[32];
  SHA256(account_key, 32, current_hash);
  SHA256(current_hash, 32, current_hash);
  memcpy(current_hash, account_value, 32);

  // Climb up Merkle tree using proof
  for (uint32_t i = 0; i < proof_length; i++) {
    uint8_t combined[64];
    if (account_key[i % 32] % 2 == 0) {
      memcpy(combined, current_hash, 32);
      memcpy(combined + 32, proof[i], 32);
    } else {
      memcpy(combined, proof[i], 32);
      memcpy(combined + 32, current_hash, 32);
    }
    SHA256(combined, 64, current_hash);
  }

  return memcmp(current_hash, root_hash, 32) == 0;
}
```

---

## Leader Rotation

### 8.8 Round-Robin Leader Selection

```c
struct hotstuff_view {
  uint64_t view_number;
  bls_pubkey_t leader_pubkey;
  uint64_t start_time;
  uint64_t timeout_ms;
};

// Select leader for view N
bls_pubkey_t select_leader(uint64_t view_number, bls_pubkey_t validators[], uint32_t count) {
  // Round-robin: leader = validators[view_number % count]
  uint32_t leader_index = view_number % count;
  return validators[leader_index];
}

// Check if view timeout, trigger new view
bool check_view_timeout(struct hotstuff_view *view) {
  uint64_t elapsed = get_time_ms() - view->start_time;

  if (elapsed > view->timeout_ms) {
    // Trigger view change
    view->view_number++;
    view->leader_pubkey = select_leader(view->view_number, validators, validator_count);
    view->start_time = get_time_ms();
    view->timeout_ms *= 2;  // Exponential backoff
    return true;
  }

  return false;
}
```

---

## View Change Protocol

### 8.9 New View Message

```c
struct new_view_msg {
  uint64_t new_view_number;
  bls_pubkey_t new_leader_pubkey;
  struct quorum_certificate *justify;  // QC from previous view
  uint8_t signature[96];  // Leader's signature on new view
} __attribute__((packed));
```

### 8.10 Handling View Changes

```c
void handle_new_view(struct new_view_msg *nv) {
  // Verify leader's signature
  if (!bls_verify(&nv->signature, &nv->new_leader_pubkey, nv, sizeof(*nv))) {
    return;  // Invalid signature
  }

  // Verify justification QC
  if (!verify_qc_signature(nv->justify, validator_pubs, validator_count)) {
    return;  // Invalid QC
  }

  // Accept new view
  current_view->view_number = nv->new_view_number;
  current_view->leader_pubkey = nv->new_leader_pubkey;
  current_view->start_time = get_time_ms();

  // Broadcast NEW-VOTE to new leader
  struct hotstuff_vote vote = {
    .view_number = nv->new_view_number,
    .block_height = current_block_height,
    .block_hash = {0},  // Empty for new view
    .signer_pubkey = my_pubkey
  };

  bls_sign(&vote.partial_signature, my_secret_key, &vote, sizeof(vote) - 96);
  send_to_leader(&vote);
}
```

---

## Consensus Performance

### 8.11 Latency Breakdown

| Phase | RTT | Time |
|-------|-----|------|
| PREPARE | 50ms | 50ms |
| PRE-COMMIT | 50ms | 100ms |
| COMMIT | 50ms | 150ms |
| DECIDE | 50ms | 200ms |
| **Total** | **4 RTTs** | **200ms** |

### 8.12 Throughput Analysis

| Metric | Value | Notes |
|--------|-------|-------|
| Block interval | 10 sec | State root published |
| TPS per shard | ~10,000 | Theoretical max |
| Block size | ~100K payments | 10,000 TPS  10 sec |
| State propagation | 50ms | Within shard |
| Cross-shard sync | 200ms | Via bridges |

---

## Notary BFT Parameters

### 8.13 Consensus Notary Configuration

| Parameter | Value | Description |
|-----------|-------|-------------|
| Total Notaries | 8 | Geo-distributed |
| BFT Threshold | 5 of 8 | Byzantine fault tolerance |
| Stake per Notary | 45-52M BLF | ~$200M USD |
| State Root Interval | 10 sec | Finality frequency |
| Signature Aggregation | BLS | 96 bytes (8  48) |

### 8.14 Notary Voting Process

```c
// Every 10 seconds, notaries vote on state root
void notary_vote_on_state_root() {
  // Gather state roots from all 127 shards
  uint8_t shard_roots[127][32];
  collect_shard_state_roots(shard_roots);

  // Compute global state root: SHA256 of all shard roots
  uint8_t global_root[32];
  SHA256(global_root, 32, shard_roots, 127 * 32);

  // Sign with BLS private key
  bls_signature sig;
  bls_sign(&sig, notary_secret_key, global_root, 32);

  // Broadcast signature to all notaries
  broadcast_signature(notary_id, &sig);

  // Wait for 5 more signatures
  bls_signature sigs[8];
  collect_signatures(sigs);

  // Aggregate signatures
  bls_signature agg_sig;
  bls_signature_aggregate(&agg_sig, sigs, 8);

  // Publish to network
  publish_state_root(global_root, &agg_sig);
}
```

---

## Key Takeaways

1. **4-Phase Protocol**: PREPARE  PRE-COMMIT  COMMIT  DECIDE
2. **Finality**: 200ms (4 RTTs  50ms)
3. **Quorum**: 67% threshold (1,605 of 2,400 VRs)
4. **BLS Aggregation**: 96 bytes for 1,605 signatures
5. **State Root**: Published every 10 seconds by 8 notaries

---

*Next: [SECURITY_ANALYSIS.md](./SECURITY_ANALYSIS.md) - Attack Vectors & Defenses*
</file>

<file path="docs/finallica/CONSTANTS_REFERENCE.md">
# Finallica Constants Reference

This document contains all hardcoded constants, limits, and configuration values used throughout the Finallica system.

---

## Cell Protocol Constants

```c
// Cell sizes
#define CELL_SIZE_FINALLICA      1024     // 1 KB per cell
#define PAYLOAD_SIZE_FINALLICA   1008     // Max payload size
#define RELAY_HEADER_SIZE        11       // Payment relay header
#define MAX_STREAM_DATA_SIZE     498      // Max data per PAY cell

// Command types
#define CMD_PADDING              0x00
#define CMD_OPEN                 0x01
#define CMD_PAY                  0x02
#define CMD_SETTLE               0x03
#define CMD_EXTEND               0x04
#define CMD_REKEY                0x05
#define CMD_DESTROY              0x06

// Channel IDs
#define CHANNEL_ID_MIN           1
#define CHANNEL_ID_MAX_INTRA     0x7FFFFFFF  // 2^31 - 1
#define CHANNEL_ID_MAX_INTER     0xFFFFFFFF
#define CHANNEL_ID_ZERO          0  // Reserved

// Stream IDs
#define STREAM_ID_MIN            0x0001
#define STREAM_ID_MAX            0xFFFE
#define STREAM_ID_CIRCUIT        0x0000  // Reserved
#define STREAM_ID_FOR_DIR        0x0001  // Reserved for directory fetch
#define STREAM_ID_MAX_VAL        0xFFFF
```

---

## Channel Management Constants

```c
// Channel lifecycle
#define MAX_ROUTE_LEN            8        // Maximum hops
#define DEFAULT_ROUTE_LEN        3        // Standard path length
#define MIN_CPUS_FOR_EXTEND      1        // Min CPUs for extend
#define CHANNEL_LIFETIME_MAX     21600    // 6 hours (in seconds)
#define CHANNEL_TIMEOUT_INIT     30       // Initial timeout (seconds)

// Guard selection
#define GUARD_LIFETIME           7776000  // 90 days (in seconds)
#define MAX_GUARD_FAILURES       20       // Max failures before rotation
#define GUARD_USAGE_FAILURES     4        // Failures before circuit close

// Channel limits per VR
#define MAX_CHANNELS_PER_PEER    5000
#define CHANNEL_MIN_CAPACITY     50000000 // $500 in microcents
#define CHANNEL_REKEY_INTERVAL   3600     // 1 hour (seconds)
```

---

## HTLC Constants

```c
// HTLC limits
#define HTLC_MIN_VALUE_MICROCENT 1       // $0.00001
#define HTLC_MAX_VALUE_MICROCENT 100000000000  // $1M
#define HTLC_MIN_TIMEOUT         40       // 10 blocks (~5 minutes)
#define HTLC_MAX_TIMEOUT         86400    // 1 day (in seconds)
#define MAX_HTLCS_PER_CHANNEL    483      // BOLT-03 limit

// HTLC timing (in blocks)
#define HTLC_TIMEOUT_MIN_BLOCKS  10
#define HTLC_TIMEOUT_MAX_BLOCKS  1440     // ~1 day
#define HTLC_DEFAULT_TIMEOUT     100      // Default expiry

// HTLC state
#define HTLC_STATE_OFFERED       0
#define HTLC_STATE_LOCKED        1
#define HTLC_STATE_SETTLED       2
#define HTLC_STATE_REFUNDED      3
#define HTLC_STATE_FAILED        4
```

---

## Cryptographic Constants

```c
// BLS12-381
#define BLS12_381_G1_COMPRESSED_SIZE   48   // Pubkey size
#define BLS12_381_G2_COMPRESSED_SIZE   96   // Signature size
#define BLS12_381_FP_SIZE             48   // Field element size
#define BLS_AGGREGATION_BATCH         64   // Optimal batch size

// X25519 / Noise
#define X25519_PUBLIC_KEY_SIZE        32
#define X25519_PRIVATE_KEY_SIZE       32
#define X25519_SHARED_SECRET_SIZE     32
#define NOISE_HANDSHAKE_HASH_SIZE     32

// ChaCha20-Poly1305
#define CHACHA20_KEY_SIZE             32
#define CHACHA20_NONCE_SIZE           12
#define POLY1305_TAG_SIZE             16

// Pedersen Commitment
#define PEDERSEN_COMMITMENT_SIZE      33   // Compressed
#define PEDERSEN_BLINDING_SIZE        32   // Scalar size
#define PEDERSEN_VALUE_BITS           64   // Range: [0, 2^64)

// SHA256 / BLAKE2s
#define SHA256_DIGEST_SIZE            32
#define BLAKE2S_DIGEST_SIZE           32
#define BLAKE2S_KEY_SIZE              32

// Ed25519 (rekey signatures)
#define ED25519_PUBLIC_KEY_SIZE       32
#define ED25519_PRIVATE_KEY_SIZE      64
#define ED25519_SIGNATURE_SIZE        64
```

---

## Network Protocol Constants

```c
// Ports
#define DATAPLANE_PORT           31337    // UDP (DPDK)
#define CONTROLPLANE_PORT        31338    // TCP (TLS)
#define ABUSE_REPORT_PORT        31339    // TCP

// Shard configuration
#define SHARD_COUNT              127      // Total shards
#define SHARD_ID_MIN             0
#define SHARD_ID_MAX             126
#define SHARD_ID_GLOBAL          127      // Reserved

// VR counts
#define VR_PER_SHARD_MIN         1000
#define VR_PER_SHARD_AVG         2400
#define VR_PER_SHARD_MAX         5000
#define BRIDGE_VR_PERCENT        5        // Top 5% become bridges

// Consensus
#define NOTARY_COUNT             8
#define NOTARY_SIG_THRESHOLD     5        // 5 of 8 BFT
#define CONSENSUS_INTERVAL_SEC   10       // State root every 10 sec
#define HOTSTUFF_VIEW_TIMEOUT    50000    // 50ms initial (s)
#define HOTSTUFF_QC_THRESHOLD    0.67     // 67% voting power
```

---

## Performance Tuning Constants

```c
// DPDK configuration
#define DPDK_MEMPOOL_SIZE        2097152  // 2M packets
#define DPDK_CACHE_SIZE          512      // Per-core cache
#define DPDK_RING_SIZE           4096     // RX/TX ring
#define DPDK_BURST_SIZE          32       // Packets per burst

// Cell queuing
#define CELL_QUEUE_HIGHWATER     512000   // 1000 cells  512B
#define CELL_QUEUE_LOWWATER      51200    // 100 cells  512B
#define MAX_REFILLED_CELLS       10       // Per tick

// Scheduling
#define SCHEDULING_INTERVAL_MSEC 10       // KIST interval
#define KIST_MAX_SCHED_BURST     32       // Max cells per schedule
#define KIST_SOCK_OUTQ_MIN       514      // Min socket queue

// CPU affinity
#define CPU_PIN_CONTROL          true
#define CPU_PIN_DATAPLANE        false
```

---

## Fee Structure Constants

```c
// Basis points (1 bp = 0.01%)
#define FEE_BPS_GUARD_MIN        2
#define FEE_BPS_GUARD_MAX        10
#define FEE_BPS_MIDDLE_MIN       3
#define FEE_BPS_MIDDLE_MAX       15
#define FEE_BPS_EXIT_MIN         10
#define FEE_BPS_EXIT_MAX         100

// Settlement rail fees
#define FEE_BPS_SWIFT            25       // 0.25%
#define FEE_BPS_ACH              10       // 0.10%
#define FEE_BPS_SEPA             15       // 0.15%
#define FEE_BPS_BTC              50       // 0.50%
#define FEE_BPS_LN               5        // 0.05%

// Liquidity fees
#define LIQUIDITY_FEE_BASE_BPS   2        // 0.02%
#define LIQUIDITY_UTIL_HIGH      0.85     // 85% threshold
#define LIQUIDITY_UTIL_EXP       4        // Exponential factor

// Padding cost (per user)
#define PADDING_RATE_CELLS_PER_SEC 1     // 1 cell/sec
#define DUST_PAYMENT_AMOUNT      1        // $0.01 (microcents)
```

---

## Staking & Economics Constants

```c
// Token supply
#define TOTAL_SUPPLY_BLF         21000000 // 21M BLF total
#define STAKED_SUPPLY_TARGET     0.878    // 87.8% target
#define INFLATION_RATE_ANNUAL    0.04     // 4% per year

// Minimum stake requirements
#define MIN_STAKE_VR             500000   // 500K BLF (~$2.25M)
#define MIN_STAKE_SE             2000000  // 2M BLF (~$9M)
#define MIN_STAKE_NOTARY         10000000 // 10M BLF (~$45M)

// Unbonding
#define UNBONDING_PERIOD_SEC     2592000  // 30 days

// Slashing penalties (basis points)
#define SLASH_DOUBLE_SIGN        10000    // 100%
#define SLASH_CENSORSHIP         1000     // 10%
#define SLASH_INVALID_SETTLEMENT 500      // 5%
#define SLASH_DOWNTIME           100      // 1% per day

// Liquidity mining
#define LIQUIDITY_APY_MIN        800      // 8% APY minimum
#define LIQUIDITY_TARGET_UTIL    0.60     // 60% utilization optimal
#define CHANNEL_REBALANCE_THRESHOLD_HIGH 0.85  // 85%
#define CHANNEL_REBALANCE_THRESHOLD_LOW  0.15  // 15%
```

---

## Memory Management Constants

```c
// Per-channel memory (40,736 bytes total)
#define CHANNEL_STATE_SIZE       224      // struct channel_t
#define CRYPTO_KEYS_SIZE         1536     // 6 cipher states
#define HTLC_TABLE_SIZE          30912    // 483 entries  64B
#define QUEUE_BUFFERS_SIZE       4096     // Input + output rings
#define REPLAY_PROTECTION_SIZE   8192     // Bloom filter
#define PATH_STATE_SIZE          640      // Guard + middle info

// Memory limits
#define MAX_MEM_IN_QUEUES_MB     1024     // 1 GB default
#define OOM_KILL_THRESHOLD       0.90     // 90% memory usage

// Channel capacity by memory
#define CHANNELS_PER_4GB         98000    // Theoretical
#define CHANNELS_PER_8GB         150000   // Practical
#define CHANNELS_PER_16GB        250000   // High-end
#define CHANNELS_PER_64GB        1000000  // Max
```

---

## Flow Control Constants

```c
// SENDME windows
#define PACKAGE_WINDOW_DEFAULT   1000     // Cells
#define DELIVER_WINDOW_DEFAULT   1000     // Cells
#define SENDME_CELL_THRESHOLD   100      // Send SENDME every 100 cells

// Token bucket rate limits
#define RATE_LIMIT_NORMAL        1000     // cells/sec
#define RATE_LIMIT_HIGH_PRIORITY 5000    // cells/sec
#define RATE_LIMIT_SETTLEMENT    10000    // cells/sec
#define RATE_LIMIT_PADDING       1        // cell/sec

// Burst sizes
#define BURST_NORMAL             100      // cells
#define BURST_HIGH_PRIORITY      500      // cells
#define BURST_SETTLEMENT         1000     // cells
#define BURST_PADDING            10       // cells

// Congestion control
#define CWND_MIN                 100
#define CWND_MAX                 10000
#define CWND_INITIAL             1000
#define SSTHRESH_INITIAL         10000
```

---

## Timing Constants

```c
// Adaptive timeout parameters
#define TIMEOUT_INITIAL_MS       200      // Initial circuit timeout
#define TIMEOUT_MIN_MS           50       // Minimum timeout
#define TIMEOUT_MAX_MS           5000     // Maximum timeout

// Timeout calculation weights
#define TIMEOUT_EWMA_ALPHA       0.8      // Exponential moving average
#define_TIMEOUT_SAMPLE_WEIGHT    0.2

// Keepalive
#define KEEPALIVE_INTERVAL_SEC   60       // PING every 60 sec
#define KEEPALIVE_TIMEOUT_SEC    300      // 5 minutes without response

// Circuit build timing
#define CIRCUIT_BUILD_TIMEOUT_MIN 50     // ms
#define CIRCUIT_BUILD_TIMEOUT_MAX 10000   // ms

// Payment expiry
#define PAYMENT_EXPIRY_MIN_SEC   60       // 1 minute
#define PAYMENT_EXPIRY_MAX_SEC   86400    // 1 day
#define PAYMENT_EXPIRY_DEFAULT   3600     // 1 hour
```

---

## Directory & Consensus Constants

```c
// Consensus document
#define CONSENSUS_PERIOD_SEC     3600     // Vote every hour
#define CONSENSUS_VALID_AFTER_SEC 7200     // Valid 2 hours
#define CONSENSUS_FRESH_UNTIL_SEC 10800   // Fresh for 3 hours
#define CONSENSUS_VALID_UNTIL_SEC 18000   // Valid for 5 hours

// Voting
#define VOTE_DELAY_SEC           300      // 5 minutes
#define CONSENSUS_METHOD_MIN     27       // Minimum supported method
#define CONSENSUS_METHOD_MAX     30       // Maximum supported method

// Descriptor sizes
#define MICRODESC_DIGEST_SIZE    32       // SHA256
#define ROUTER_DESC_MAX_SIZE     8192     // 8 KB max
```

---

## Padding Constants

```c
// Link padding
#define PADDING_SCHEDULE_SINE_WAVE 1      // Sine wave pattern
#define PADDING_CYCLE_SECONDS    86400    // 24-hour cycle
#define PADDING_MIN_RATE_BPS     1250000  // 1.25 MB/s min
#define PADDING_MAX_RATE_BPS     10000000 // 10 MB/s max

// Cell padding
#define PADDING_CELL_BURST_LAMBDA 5.0    // Poisson 
#define PADDING_CELL_MIN_SIZE    0        // Can be zero
#define PADDING_CELL_MAX_SIZE    255      // Bytes

// Payment padding (dust)
#define DUST_PAYMENTS_PER_DAY    1000     // Target dust payments
#define DUST_PAYMENT_AMOUNT      1        // $0.01 (microcents)
```

---

## Path Selection Weights

```c
// Weight calculation
#define WEIGHT_STAKE_EXPONENT   0.7      // stake^0.7
#define WEIGHT_FEE_EXPONENT     2.0      // fee^2 (penalty)
#define WEIGHT_UPTIME_DAYS     30       // Uptime normalization

// Bandwidth weights
#define BW_WEIGHT_FLOOR         5120     // 5 KB/s minimum
#define BW_WEIGHT_CAP           10485760 // 10 MB/s cap

// Guard fraction
#define GUARD_FRACTION_MIN      0.20     // 20% of nodes
#define GUARD_FRACTION_MAX      0.40     // 40% of nodes
```

---

## Debug & Logging Constants

```c
// Log levels
#define LOG_DEBUG               0
#define LOG_INFO                1
#define LOG_NOTICE              2
#define LOG_WARN                3
#define LOG_ERROR               4

// Logging domains
#define LD_GENERAL              "GENERAL"
#define LD_NET                  "NET"
#define LD_CONFIG               "CONFIG"
#define LD_CRYPTO               "CRYPTO"
#define LD_HTLC                 "HTLC"
#define LD_CONSENSUS            "CONSENSUS"

// Tracing
#define TRACE                   1        // Enable trace logging
#define DEBUG_CELL              0        // Log all cells
```

---

## Compatibility Versions

```c
// Protocol versions
#define PROTO_VERSION_MIN       4
#define PROTO_VERSION_MAX       4
#define PROTO_VERSION_CURRENT   4

// Consensus methods
#define CONSENSUS_METHOD_MIN    27
#define CONSENSUS_METHOD_MAX    30
#define CONSENSUS_METHOD_CURRENT 28

// Supported link protocols
#define LINK_PROTO_MIN          2
#define LINK_PROTO_MAX          3        // 1=TLS 1.2, 2=TLS 1.3, 3=Noise_XX
```

---

## Security Thresholds

```c
// Path bias detection
#define PATH_BIAS_PERCENTAGE_WARN   25    // Warning at 25%
#define PATH_BIAS_PERCENTAGE_ABORT  10    // Abort at 10%
#define PATH_BISECT_THRESHOLD       5     // Extends b/w this

// DoS limits
#define DOS_CONN_PER_ADDRESS     4        // Max conns per IP
#define DOS_CONCURRENT_CONN_BONUS 32     // Allow bonus for good behavior
#define DOS_MAX_CIRCUITS_PER_SEC 10     // Max circuits per second

// Abuse detection
#define ABUSE_PORT_SCAN_THRESHOLD 3      // Flag after 3 port scans
#define ABUSE_DMCA_PER_DAY        1       // DMCA notice limit
#define ABUSE_SSH_BRUTE_PER_HOUR  12     // SSH brute force limit
```

---

## Unit Conversion Macros

```c
// Time conversions
#define MS_TO_US(ms)             ((ms) * 1000)
#define SEC_TO_MS(sec)           ((sec) * 1000)
#define SEC_TO_US(sec)           ((sec) * 1000000)
#define MIN_TO_SEC(min)          ((min) * 60)
#define HOURS_TO_SEC(hr)         ((hr) * 3600)
#define DAYS_TO_SEC(day)         ((day) * 86400)

// Microcent conversions (1 microcent = $0.00001)
#define USD_TO_MICROCENTS(usd)   ((uint64_t)((usd) * 100000))
#define MICROCENTS_TO_USD(uc)    (((uc) / 100.0) / 1000.0)
#define CENTS_TO_MICROCENTS(c)   ((c) * 10000)

// Basis points (1 bp = 0.01%)
#define BPS_TO_RATIO(bps)        ((bps) / 10000.0)
#define RATIO_TO_BPS(ratio)      ((int)((ratio) * 10000))

// Token conversions (1 BLF = $4.50)
#define BLF_TO_USD(blf)          ((blf) * 4.50)
#define USD_TO_BLF(usd)          ((usd) / 4.50)
```

---

## Summary Table: Critical Constants

| Category | Constant | Value | Notes |
|----------|----------|-------|-------|
| **Cell** | CELL_SIZE | 1,024 bytes | Fixed packet size |
| **Cell** | MAX_HTLCS_PER_CHANNEL | 483 | BOLT-03 limit |
| **Channel** | CHANNEL_LIFETIME_MAX | 21,600 sec | 6 hours |
| **Channel** | CHANNEL_MIN_CAPACITY | $500 | In microcents |
| **Guard** | GUARD_LIFETIME | 7,776,000 sec | 90 days |
| **Fees** | FEE_BPS_EXIT_MIN | 10 bp | 0.10% |
| **Fees** | FEE_BPS_SWIFT | 25 bp | 0.25% |
| **Stake** | MIN_STAKE_VR | 500K BLF | ~$2.25M |
| **Stake** | MIN_STAKE_SE | 2M BLF | ~$9M |
| **Crypto** | BLS12_381_G1_SIZE | 48 bytes | Pubkey |
| **Crypto** | BLS12_381_G2_SIZE | 96 bytes | Signature |
| **Network** | SHARD_COUNT | 127 | Total shards |
| **Network** | NOTARY_COUNT | 8 | Consensus authorities |
| **Timing** | CONSENSUS_INTERVAL | 10 sec | State root period |
| **Window** | PACKAGE_WINDOW_DEFAULT | 1,000 cells | Flow control |

---

*Back to [README.md](./README.md)*
</file>

<file path="docs/finallica/CRYPTOGRAPHIC_DETAILS.md">
# Finallica Cryptographic Details

This document describes the payment cell flow, nested commitment unwrapping, and cryptographic primitives used in Finallica.

---

## Payment Cell Flow: Nested Commitment Unwrapping

### 6.1 Cell Structure & Encryption Layers

All Finallica payments use **3 layers of nested encryption** (one per hop):

```
Ciphertext = Encrypt_Guard(
  Encrypt_Middle(
    Encrypt_Exit(
      PaymentPayload + NextHopAddress + Amount
    )
  )
)
```

Each layer uses **ChaCha20-Poly1305** with independent keys derived via Noise_XX handshake.

### 6.2 Per-Hop Processing Diagram

```mermaid
graph LR
    subgraph "Finallica Proxy (Origin)"
        APP["User Payment<br/>$100.00 = 10,000,000 microcents<br/>BOLT-11 invoice"]
        COMMIT["Pedersen Commitment<br/>C = v*G + b*H<br/>v = 10,000,000<br/>b = random scalar<br/>33 bytes compressed"]
        RELAY_HDR["Payment Relay Header<br/>stream_id: 0x0042<br/>amount_commit: C<br/>expiry: 1706035200<br/>payment_hash: 0x1a2b...<br/>next_hop: 0x7d6c... (BLS)"]
        PLAINTEXT["Plaintext Payload: 867 bytes<br/>relay_hdr + invoice_data + padding"]

        ENCRYPT_EXIT["Encrypt with Exit Key K_exit<br/>ChaCha20-Poly1305<br/>nonce = 0..11<br/>auth_tag = 0..15"]
        ENCRYPT_MID["Encrypt with Middle Key K_mid<br/>ChaCha20-Poly1305"]
        ENCRYPT_GUARD["Encrypt with Guard Key K_guard<br/>ChaCha20-Poly1305"]

        CELL_FINAL["Final Cell<br/>channel_id=0x4f3e2d1c<br/>cmd=PAY (0x02)<br/>payload: 867 bytes onion-encrypted<br/>BLS sig: _payer (96 bytes)"]
    end

    subgraph "Guard VR (Hop 1)"
        G_RECV["DPDK RX<br/>mbuf ptr: 0x7f3a...<br/>Direct cell access"]
        G_PARSE["Parse: channel_id=0x4f3e2d1c, cmd=PAY"]
        G_DEC_GUARD["Decrypt layer 1<br/>ChaCha20-Poly1305 with K_guard<br/>Verify auth_tag<br/>0.002ms"]
        G_BLS["Verify BLS _payer<br/>Batch verify: 0.15ms<br/>Pedersen verify: 45ms"]
        G_RELAY["Parse relay_hdr<br/>amount_commit = C<br/>next_hop = 0x7d6c..."]
        G_BALANCE["Homomorphic subtract<br/>C_new = C_channel - C<br/>Verify C_new > 0"]
        G_FORWARD["Forward to Middle<br/>New channel_id=0x8a7b6c5d<br/>DPDK TX queue"]
    end

    subgraph "Middle VR (Hop 2)"
        M_RECV["DPDK RX<br/>channel_id=0x8a7b6c5d"]
        M_DEC_MID["Decrypt layer 2<br/>ChaCha20 with K_mid<br/>0.002ms"]
        M_RELAY["Parse: still encrypted<br/>next_hop = 0x9c8d..."]
        M_BALANCE["Update balance: -C<br/>Check expiry > block"]
        M_FORWARD["Forward to Exit<br/>channel_id=0x9c8d7e6f"]
    end

    subgraph "Settlement Executor (Hop 3)"
        E_RECV["DPDK RX<br/>channel_id=0x9c8d7e6f"]
        E_DEC_EXIT["Decrypt layer 3<br/>ChaCha20 with K_exit<br/>0.002ms"]
        E_RELAY_CLEAR["Relay header plaintext<br/>stream_id: 0x0042<br/>amount: 10M microcents<br/>payment_hash: 0x1a2b..."]
        E_LOOKUP["Lookup HTLC<br/>htlc_table_find(payment_hash)"]
        E_SETTLE["Initiate settlement<br/>SWIFT API call<br/>15,000ms"]
        E_PREIMAGE["Receive preimage from bank<br/>Reveal: preimage=0xfedcba..."]
        E_BLS_AGG["BLS aggregate settle sig<br/>_exit =  _i<br/>125ms for 64 payments"]
    end

    APP --> COMMIT
    COMMIT --> RELAY_HDR
    RELAY_HDR --> PLAINTEXT
    PLAINTEXT --> ENCRYPT_EXIT
    ENCRYPT_EXIT --> ENCRYPT_MID
    ENCRYPT_MID --> ENCRYPT_GUARD
    ENCRYPT_GUARD --> CELL_FINAL

    CELL_FINAL --> G_RECV
    G_DEC_GUARD --> G_BLS
    G_BLS --> G_RELAY
    G_RELAY --> G_BALANCE
    G_BALANCE --> G_FORWARD

    G_FORWARD --> M_RECV
    M_DEC_MID --> M_RELAY
    M_RELAY --> M_BALANCE
    M_BALANCE --> M_FORWARD

    M_FORWARD --> E_RECV
    E_DEC_EXIT --> E_RELAY_CLEAR
    E_RELAY_CLEAR --> E_LOOKUP
    E_LOOKUP --> E_SETTLE
    E_SETTLE --> E_PREIMAGE
    E_PREIMAGE --> E_BLS_AGG
```

---

## Pedersen Commitments

### 7.1 Commitment Scheme

**Pedersen commitments** hide payment amounts while allowing homomorphic operations:

```
C = v*G + b*H

where:
  C = commitment (33 bytes compressed)
  v = value (amount in microcents)
  G = secp256k1 generator point
  b = blinding factor (random scalar)
  H = second generator point (H = hash(G))
```

### 7.2 Commitment Creation

```c
secp256k1_pedersen_commitment commitment;
secp256k1_scalar blinding_factor;
secp256k1_scalar value;

// Set value
secp256k1_scalar_set_u64(&value, amount_microcents);

// Generate random blinding factor
randombytes_buf(&blinding_factor, 32);

// Create commitment
secp256k1_pedersen_commit(
  secp256k1_ctx,
  &commitment,
  &blinding_factor,
  amount_microcents,
  &secp256k1_generator_h
);

// Serialize to 33 bytes (compressed)
secp256k1_pedersen_commitment_serialize(
  &cell->commitment[0],
  &commitment
);
```

### 7.3 Homomorphic Operations

```c
// Subtract payment from channel balance
secp256k1_pedersen_commitment new_balance;
secp256k1_pedersen_commitment_negate(&payment_commit, &payment_commit);
secp256k1_pedersen_commitment_sum(
  &new_balance,
  (const secp256k1_pedersen_commitment *[]){
    &channel_balance,
    &payment_commit
  },
  2
);

// Verify balance is positive
bool is_positive = secp256k1_pedersen_commitment_verify_positive(&new_balance);
```

### 7.4 Range Proofs (Bulletproofs+)

To prevent negative amounts while keeping value hidden:

```c
// Generate range proof: 0  value < 2^64
secp256k1_bulletproofs_plus_proof bp_proof;
secp256k1_bulletproofs_plus_prove(
  secp256k1_ctx,
  &bp_proof,
  &commitment,
  &value,
  &blinding_factor,
  NULL,  // no additional commits
  0,     // n_additional_commits
  64,    // bit_range
  NULL   // custom_nonce
);

// Verification: 5-10ms (single), 0.5ms (batch 64)
bool valid = secp256k1_bulletproofs_plus_verify(
  secp256k1_ctx,
  &bp_proof,
  &commitment,
  NULL,
  0,
  64
);
```

---

## BLS12-381 Signatures

### 8.1 Key Generation

```c
bls_secret_key secret_key;
bls_public_key public_key;

// Generate
bls_bls_keygen(&secret_key, entropy, 32);

// Derive public key
bls_get_public_key(&public_key, &secret_key);

// Serialize (48 bytes compressed G1)
bls_public_key_serialize(&cell->bls_pubkey[0], &public_key);
```

### 8.2 Signing

```c
bls_signature signature;

// Sign commitment (33 bytes)
bls_sign(
  &signature,
  &secret_key,
  &cell->commitment[0],
  33,
  NULL  // no proof of possession
);

// Serialize (96 bytes G2)
bls_signature_serialize(&cell->bls_signature[0], &signature);
```

### 8.3 Verification (Single)

```c
bls_signature sig;
bls_public_key pk;
bls_signatureDeserialize(&sig, &cell->bls_signature[0], 96);
bls_public_keyDeserialize(&pk, &cell->bls_pubkey[0], 48);

bool valid = bls_verify(
  &sig,
  &pk,
  &cell->commitment[0],
  33
);
// Time: ~2-3ms (single)
```

### 8.4 Batch Verification

```c
// Aggregate 64 signatures for verification
bls_signature agg_sig;
bls_signature_aggregate(&agg_sig, signatures, 64);

// Verify all at once
bool valid = bls_fast_aggregate_verify(
  &agg_sig,
  public_keys,
  64,
  messages,
  message_lengths
);
// Time: ~0.15ms for 64 signatures (40x faster)
```

### 8.5 Signature Aggregation

Used by Exit VRs to aggregate settlement signatures:

```c
// Combine 64 payment signatures
bls_signature aggregated;
bls_signature_aggregate(&aggregated, settle_sigs, 64);

// Broadcast aggregated signature to notaries
bls_signature_serialize(&agg_sig_bytes[0], &aggregated);
```

---

## ChaCha20-Poly1305 Encryption

### 9.1 Key Derivation

```c
uint8_t chaining_key[32];
uint8_t pay_key[32];
uint8_t nonce[12];

// Extract phase
BLAKE2s(chaining_key, 32, NULL, 0,
        handshake_hash, BLAKE2S_OUTBYTES,
        "FinallicaExtract", 16);

// Expand phase (3 keys)
HKDF_BLAKE2s_Expand(pay_key, 32, chaining_key, 32,
                    "FinallicaPayKey", 15);
HKDF_BLAKE2s_Expand(settle_key, 32, chaining_key, 32,
                    "FinallicaSettleKey", 18);
HKDF_BLAKE2s_Expand(padding_key, 32, chaining_key, 32,
                    "FinallicaPaddingKey", 17);

// Initialize cipher
crypto_aead_chacha20poly1305_ietf_keygen(cipher_state, pay_key);
```

### 9.2 Encryption (Per Hop)

```c
// Nonce: 12-byte counter (incremented per cell)
uint64_t *nonce_counter = (uint64_t *)nonce;
*nonce_counter = cell_sequence;

// Encrypt payload
crypto_aead_chacha20poly1305_ietf_encrypt(
  cell->payload,        // ciphertext output
  &cell->payload_len,   // ciphertext length
  plaintext,            // plaintext input
  plaintext_len,        // plaintext length
  NULL,                 // additional data
  0,                    // AD length
  NULL,                 // nonce (set separately)
  cipher->key           // key
);

// Set nonce explicitly
memcpy(cell->nonce, nonce, 12);
```

### 9.3 Decryption (Per Hop)

```c
uint8_t plaintext[867];
size_t plaintext_len;

int result = crypto_aead_chacha20poly1305_ietf_decrypt(
  plaintext,              // plaintext output
  &plaintext_len,         // plaintext length
  NULL,                   // unused
  cell->payload,          // ciphertext
  cell->payload_len,      // ciphertext length
  cell->auth_tag,         // auth tag (16 bytes)
  cell->nonce,            // nonce (12 bytes)
  cipher->key             // key
);

if (result != 0) {
  // Authentication failed - reject cell
  channel_penalty(channel_id, 100);
  return;
}
```

---

## Key Rotation Schedule

| Key Type | Rotation Trigger | Max Lifetime |
|----------|-----------------|--------------|
| K_pay (Pay Cipher) | 2^20 cells OR 1 hour | ~1M cells |
| K_settle (Settle Cipher) | 2^20 cells OR 1 hour | ~1M cells |
| K_pad (Padding Cipher) | 1 hour (fixed) | 1 hour |
| Rekey Key | 6 hours | 6 hours |

**Rekeying Process** (in-band, zero-RTT):

```c
struct rekey_cell {
  uint8_t command: 0xFF;  // REKEY
  uint32_t channel_id;
  uint8_t new_ephemeral[32];  // X25519
  uint8_t signature[64];       // Ed25519(new_ephemeral || old_key || channel_id)
  uint8_t auth_tag[16];        // Poly1305
} __attribute__((packed));
```

---

## Cryptographic Performance

| Operation | Time (single) | Time (batch 64) |
|-----------|---------------|-----------------|
| ChaCha20-Poly1305 encrypt | 1.2 s | N/A |
| ChaCha20-Poly1305 decrypt | 1.2 s | N/A |
| BLS sign | 2-3 ms | N/A |
| BLS verify (single) | 2-3 ms | N/A |
| BLS verify (batch 64) | N/A | 0.15 ms |
| BLS aggregate (64) | 0.125 ms | N/A |
| Pedersen commit | 45 s | N/A |
| Bulletproofs+ prove | 780 s | N/A |
| Bulletproofs+ verify | 5-10 ms | 0.5 ms |
| X25519 scalar mult | 90 s | N/A |
| BLAKE2s hash | 25 s | N/A |

---

## Key Takeaways

1. **Nested Encryption**: 3 layers (Guard  Middle  Exit)
2. **Amount Hiding**: Pedersen commitments + Bulletproofs+ range proofs
3. **Stake Binding**: BLS12-381 signatures (batch verification 40x faster)
4. **Fast Symmetric**: ChaCha20-Poly1305 (1.2 s per hop)
5. **Key Rotation**: Every 1M cells or 1 hour (whichever first)

---

*Next: [LIQUIDITY_MANAGEMENT.md](./LIQUIDITY_MANAGEMENT.md) - Flow Control & Channel Windows*
</file>

<file path="docs/finallica/LIQUIDITY_MANAGEMENT.md">
# Finallica Liquidity Management

This document describes the flow control mechanisms, channel windows, and liquidity rebalancing in Finallica.

---

## Channel Capacity Windows

### 7.1 Sender-Side Flow Control

```mermaid
graph TB
    subgraph "Channel Capacity Window (Sender Side)"
        FP_SEND["FP sends PAY cell<br/>channel->available_to_send -= amount"]
        FP_WINDOW["Initial: $25,000<br/>After $100 payment: $24,900<br/>Window = $24,900"]
        FP_BLOCK["Block when window < min_payment<br/>min_payment = $1.00<br/>Return INSUFFICIENT_LIQUIDITY"]

        E_SETTLE["Exit settles HTLC<br/>Preimage revealed<br/>Settlement confirmed"]
        E_ACK["Exit sends SETTLE_ACK<br/>channel->available_to_send += amount<br/>Window = $24,900 + $100 = $25,000"]
    end

    FP_SEND --> FP_WINDOW
    FP_WINDOW --> FP_BLOCK
    E_SETTLE --> E_ACK
```

### Channel Window Structure

```c
struct channel_window {
  int64_t available_to_send;   // Payer's liquidity (microcents)
  int64_t available_to_recv;   // Payee's settlement capacity
  uint32_t max_inflight_htlcs; // Default: 483 (BOLT-03 limit)
  uint64_t min_payment;        // $1.00 = 100,000 microcents
};

// Default initialization
struct channel_window default_window = {
  .available_to_send = 25000000,    // $25,000
  .available_to_recv = 25000000,
  .max_inflight_htlcs = 483,
  .min_payment = 100000
};
```

### Window Update Logic

```c
// When sending payment
bool can_send_payment(struct channel *chan, uint64_t amount) {
  if (chan->window.available_to_send < amount + chan->window.min_payment) {
    return false;  // Would drop below minimum
  }
  if (chan->htlc_count >= chan->window.max_inflight_htlcs) {
    return false;  // Too many inflight HTLCs
  }
  return true;
}

// Deduct from window
void deduct_from_window(struct channel *chan, uint64_t amount) {
  chan->window.available_to_send -= amount;
  chan->htlc_count++;
}

// Refund on settlement
void refund_window(struct channel *chan, uint64_t amount) {
  chan->window.available_to_send += amount;
  chan->htlc_count--;
}
```

---

## HTLC Slot Windows

### 7.2 Per-Channel HTLC Limits

```mermaid
graph TB
    subgraph "HTLC Slot Window (Per-Channel)"
        M_RECV["VR receives PAY<br/>Check htlc_table->count"]
        M_SLOTS["HTLC slots: 483 max<br/>Used: 482<br/>Free: 1"]
        M_BLOCK["Reject when slots = 0<br/>Return MAX_HTLCS_EXCEEDED"]

        M_SETTLE["HTLC settles<br/>htlc_table_free(entry)<br/>count--: 482"]
    end

    M_RECV --> M_SLOTS
    M_SLOTS --> M_BLOCK
    M_SETTLE --> M_SLOTS
```

### HTLC Table Management

```c
#define HTLC_MAX_PER_CHANNEL 483

struct htlc_table {
  htlc_entry_t *entries[HTLC_MAX_PER_CHANNEL];
  uint16_t count;
  bitarray_t *used_slots;  // 483 bits
};

// Allocate HTLC slot
htlc_entry_t *htlc_allocate(struct htlc_table *table) {
  if (table->count >= HTLC_MAX_PER_CHANNEL) {
    return NULL;  // Table full
  }

  // Find free slot
  for (int i = 0; i < HTLC_MAX_PER_CHANNEL; i++) {
    if (!bitarray_test(table->used_slots, i)) {
      bitarray_set(table->used_slots, i);
      table->entries[i] = calloc(1, sizeof(htlc_entry_t));
      table->count++;
      return table->entries[i];
    }
  }

  return NULL;
}

// Free HTLC slot
void htlc_free(struct htlc_table *table, htlc_entry_t *entry) {
  int index = entry->index;
  bitarray_clear(table->used_slots, index);
  free(table->entries[index]);
  table->entries[index] = NULL;
  table->count--;
}
```

---

## Rate Limiting (Per-Stream)

### 7.3 Token Bucket Rate Limiter

```mermaid
graph TB
    subgraph "Rate Limiting (Per-Stream)"
        P_STREAM["Payment stream<br/>stream_id=0x0042"]
        R_BUCKET["Token bucket<br/>rate = 1000 cells/sec<br/>burst = 100 cells"]
        R_DROP["Drop when tokens = 0<br/>Send NACK upstream"]

        R_TOKENS["Ack received<br/>tokens += 100<br/>Max: 1000"]
    end

    P_STREAM --> R_BUCKET
    R_BUCKET --> R_DROP
    R_TOKENS --> R_BUCKET
```

### Token Bucket Implementation

```c
struct token_bucket {
  uint64_t rate;         // tokens per second
  uint64_t burst;        // max tokens
  uint64_t tokens;       // current tokens
  uint64_t last_update;  // timestamp (s)
};

// Check if tokens available
bool token_bucket_consume(struct token_bucket *bucket, uint64_t tokens) {
  uint64_t now = get_time_us();
  uint64_t elapsed = now - bucket->last_update;

  // Refill based on elapsed time
  bucket->tokens += (elapsed * bucket->rate) / 1000000;
  if (bucket->tokens > bucket->burst) {
    bucket->tokens = bucket->burst;
  }
  bucket->last_update = now;

  // Check if enough tokens
  if (bucket->tokens < tokens) {
    return false;  // Rate limited
  }

  bucket->tokens -= tokens;
  return true;
}

// Add tokens on ACK
void token_bucket_add(struct token_bucket *bucket, uint64_t tokens) {
  bucket->tokens += tokens;
  if (bucket->tokens > bucket->burst) {
    bucket->tokens = bucket->burst;
  }
}
```

### Rate Limits by Stream Type

| Stream Type | Rate | Burst |
|-------------|------|-------|
| Normal payments | 1,000 cells/sec | 100 cells |
| High-priority | 5,000 cells/sec | 500 cells |
| Settlement | 10,000 cells/sec | 1,000 cells |
| Padding | 1 cell/sec | 10 cells |

---

## Cross-Shard Liquidity Rebalancing

### 7.4 Atomic Swap Protocol

```mermaid
graph TB
    subgraph "Cross-Shard Liquidity Rebalancing"
        SHARD_0["Shard 0<br/>Channel: $500 capacity<br/>Used: $425 (85%)"]
        SHARD_1["Shard 1<br/>Channel: $500 capacity<br/>Used: $75 (15%)"]
        BRIDGE["Atomic Swap<br/>HTLAS protocol<br/>3-second lock time"]

        SHARD_0 -->|Swap $200| BRIDGE
        BRIDGE -->|Swap $200| SHARD_1
        SHARD_0 -->|New balance: $225| SHARD_0
        SHARD_1 -->|New balance: $275| SHARD_1
    end
```

### HTLAS (Hashed Timelock Atomic Swap) Protocol

```c
struct htlas_swap {
  uint64_t amount;
  uint8_t payment_hash[32];
  uint32_t timeout_block;  // 3 seconds = ~15 blocks
  bls_pubkey_t shard_a_pubkey;
  bls_pubkey_t shard_b_pubkey;
};

// Step 1: Shard A creates HTLC
bool shard_a_create_htlc(struct htlas_swap *swap) {
  // Lock funds on Shard A
  htlc_entry_t *htlc = htlc_allocate(&shard_a->htlc_table);
  htlc->amount = swap->amount;
  htlc->payment_hash = swap->payment_hash;
  htlc->expiry = current_block + swap->timeout_block;

  // Broadcast to Shard B via bridge
  bridge_send_htlc(swap);
  return true;
}

// Step 2: Shard B creates mirrored HTLC
bool shard_b_create_htlc(struct htlas_swap *swap) {
  // Lock funds on Shard B (refundable if timeout)
  htlc_entry_t *htlc = htlc_allocate(&shard_b->htlc_table);
  htlc->amount = swap->amount;
  htlc->payment_hash = swap->payment_hash;
  htlc->expiry = current_block + swap->timeout_block;
  return true;
}

// Step 3: Reveal preimage, claim both HTLCs
bool claim_htlc(struct htlas_swap *swap, uint8_t *preimage) {
  // Verify preimage matches hash
  if (SHA256(preimage) != swap->payment_hash) {
    return false;
  }

  // Claim on Shard A
  shard_a_claim_htlc(swap, preimage);

  // Claim on Shard B
  shard_b_claim_htlc(swap, preimage);

  return true;
}

// Step 4: Refund if timeout
bool refund_htlc(struct htlas_swap *swap) {
  if (current_block < swap->timeout_block) {
    return false;  // Not yet expired
  }

  // Refund both HTLCs
  shard_a_refund_htlc(swap);
  shard_b_refund_htlc(swap);
  return true;
}
```

### Rebalancing Trigger Conditions

| Condition | Threshold | Action |
|-----------|-----------|--------|
| High utilization | >85% capacity | Rebalance OUT |
| Low utilization | <15% capacity | Rebalance IN |
| Rebalance amount | Min $50, Max $500 | Atomic swap |
| Lock time | 3 seconds (15 blocks) | HTLAS timeout |

---

## Liquidity Fee Structure

### 7.5 Dynamic Fee Calculation

Fees increase with channel utilization:

```c
uint64_t calculate_liquidity_fee(
  uint64_t amount,
  struct channel *chan) {

  double utilization = (double)chan->used / chan->capacity;

  // Fee multiplier: 1.0x at 0%, 1.5x at 85%, 2.5x at 95%
  double multiplier = 1.0 + pow(utilization / 0.9, 4);

  // Base rate: 2 bps
  uint64_t fee = amount * 0.0002 * multiplier;

  return fee;
}
```

### Fee Examples

| Utilization | Multiplier | Fee on $100 |
|-------------|------------|-------------|
| 0% | 1.0x | $0.02 |
| 50% | 1.1x | $0.022 |
| 85% | 1.5x | $0.03 |
| 90% | 1.8x | $0.036 |
| 95% | 2.7x | $0.054 |

---

## Channel Rebalance Threshold

```c
#define REBALANCE_THRESHOLD_HIGH 0.85  // 85%
#define REBALANCE_THRESHOLD_LOW  0.15  // 15%
#define REBALANCE_MIN_AMOUNT    50000000  // $50
#define REBALANCE_MAX_AMOUNT    500000000 // $500

void check_rebalance_needed(struct channel *chan) {
  double utilization = (double)chan->used / chan->capacity;

  if (utilization > REBALANCE_THRESHOLD_HIGH) {
    // Need to rebalance OUT
    uint64_t amount = (chan->used - (chan->capacity * 0.6));
    amount = MAX(amount, REBALANCE_MIN_AMOUNT);
    amount = MIN(amount, REBALANCE_MAX_AMOUNT);

    initiate_rebalance(chan, amount, REBALANCE_OUT);
  }
  else if (utilization < REBALANCE_THRESHOLD_LOW) {
    // Need to rebalance IN
    uint64_t amount = ((chan->capacity * 0.4) - chan->used);
    amount = MAX(amount, REBALANCE_MIN_AMOUNT);
    amount = MIN(amount, REBALANCE_MAX_AMOUNT);

    initiate_rebalance(chan, amount, REBALANCE_IN);
  }
}
```

---

## Key Takeaways

1. **Channel Windows**: $25,000 default capacity, 483 HTLC slots max
2. **Rate Limiting**: Token bucket, 1,000 cells/sec per stream
3. **Rebalancing**: Atomic swaps at 85%/15% thresholds
4. **Dynamic Fees**: Increase with utilization (1x  2.7x)
5. **HTLAS Protocol**: 3-second lock time for cross-shard swaps

---

*Next: [CONSENSUS_MECHANISM.md](./CONSENSUS_MECHANISM.md) - HotStuff BFT Protocol*
</file>

<file path="docs/finallica/OPERATIONAL_METRICS.md">
# Finallica Operational Metrics

This document provides the live production metrics and operational dashboards for the Finallica network.

---

## Client FP Metrics

### Finallica Proxy (Wallet Side)

```mermaid
graph TB
    subgraph "Client FP Metrics"
        C_CIRC["Active Channels: 12<br/>Building: 1<br/>Closed (24h): 8<br/>Reuse rate: 94%"]
        C_STREAM["Payment Streams: Active: 34<br/>Inflight HTLCs: 127<br/>Avg per channel: 2.8"]
        C_BW["Bandwidth: TX: 2.8 MB/s<br/>RX: 1.9 MB/s<br/>Padding overhead: 22%<br/>Dust payments: 1,200/day"]
        C_LATENCY["Latency: Channel build: 340ms p95<br/>Payment RTT: 580ms<br/>Guard RTT: 42ms<br/>Settlement: 1.8 days SWIFT"]
        C_FEES["Fees (24h): Total paid: $18.42<br/>Avg per payment: $0.31<br/>Routing: $0.12<br/>Settlement: $0.18<br/>Liquidity: $0.01"]
    end
```

### FP Statistics Breakdown

| Metric | Value | Notes |
|--------|-------|-------|
| **Channels** | | |
| Active | 12 | Currently usable |
| Building | 1 | In handshake phase |
| Closed (24h) | 8 | Natural expiration |
| Reuse Rate | 94% | High efficiency |
| **Streams** | | |
| Active Streams | 34 | Concurrent payments |
| Inflight HTLCs | 127 | Pending settlement |
| Avg/Channel | 2.8 | Stream multiplexing |
| **Bandwidth** | | |
| TX Rate | 2.8 MB/s | Outbound traffic |
| RX Rate | 1.9 MB/s | Inbound traffic |
| Padding Overhead | 22% | Privacy cost |
| Dust Payments | 1,200/day | $0.01 each |
| **Latency** | | |
| Channel Build (p50) | 127ms | Median |
| Channel Build (p95) | 340ms | 95th percentile |
| Payment RTT | 580ms | Round-trip time |
| Guard RTT | 42ms | Entry hop latency |
| Settlement Time | 1.8 days | SWIFT average |
| **Fees (24h)** | | |
| Total Paid | $18.42 | All payments |
| Avg Per Payment | $0.31 | 0.31% of $100 |
| Routing Fee | $0.12 | 3 hops  2-5 bps |
| Settlement Fee | $0.18 | SWIFT rail |
| Liquidity Fee | $0.01 | Dynamic |

---

## Guard VR Metrics

### VR-0-015 (Example Guard Node)

```mermaid
graph TB
    subgraph "Guard VR-0-015 Metrics"
        G_CIRC["Active Channels: 5,823<br/>Client conns: 5,823<br/>VR-to-VR: 2,406<br/>Total: 8,229"]
        G_CONN["DPDK Flows: 8,229 / 1,048,576<br/>UDP port 31337<br/>TCP port 31338: 2,406"]
        G_CPU["CPU: 16 cores @ 98%<br/>ChaCha20: 18,200 ops/sec<br/>BLS verify: 4,800 sigs/sec<br/>Load avg: 15.8"]
        G_NET["Network: RX: 45.2 Gbps<br/>TX: 46.1 Gbps<br/>Drops: 0.0008%<br/>Retrans: 0% UDP"]
        G_PAY["Payments: 12,847 last epoch<br/>Success: 99.91%<br/>Avg fee revenue: 2.1 bps = $2,697/epoch"]
    end
```

### Guard VR Statistics

| Metric | Value | Capacity |
|--------|-------|----------|
| **Connections** | | |
| Active Channels | 5,823 | Max: 15,000 |
| Client Connections | 5,823 | |
| VR-to-VR Peers | 2,406 | Shard size |
| Total Flows | 8,229 | DPDK max: 1,048,576 |
| **CPU** | | |
| Core Utilization | 98% | 16 cores @ 3.5 GHz |
| ChaCha20 Ops/sec | 18,200 | Max: 25,000 |
| BLS Verify/sec | 4,800 | Max: 64,000 |
| Load Average | 15.8 | |
| **Network** | | |
| RX Throughput | 45.2 Gbps | NIC: 100 Gbps |
| TX Throughput | 46.1 Gbps | |
| Packet Drops | 0.0008% | |
| Retransmissions | 0% | UDP (no retrans) |
| **Payments** | | |
| Per Epoch | 12,847 | |
| Success Rate | 99.91% | |
| Fee Revenue | $2,697/epoch | 2.1 bps avg |

---

## Settlement Executor Metrics

### SE-0-12 (Example Exit Node)

```mermaid
graph TB
    subgraph "Settlement SE-0-12 Metrics"
        E_STREAM["Active Settlements: 1,247<br/>SWIFT: 892<br/>ACH: 324<br/>BTC: 31<br/>LN: 0"]
        E_API["API Rate: SWIFT: 8.9 req/sec<br/>ACH: 32.4 req/sec<br/>Quota: 10/100 req/sec<br/>429 errors: 0.02%"]
        E_MEM["Memory: Used: 4.2 GB<br/>Per-settlement: 3.4 MB<br/>Buffers: 2.1 GB<br/>OOM risk: Low"]
        E_ABUSE["Abuse: Failed settlements: 3<br/>AML flags: 12<br/>Fraud score: 0.8%<br/>Frozen: $12,400"]
    end
```

### Settlement Executor Statistics

| Metric | Value | Capacity |
|--------|-------|----------|
| **Active Settlements** | | |
| SWIFT | 892 | 60% of total |
| ACH | 324 | 26% of total |
| Bitcoin | 31 | 2.5% of total |
| Lightning | 0 | 0% |
| Total | 1,247 | Max: 2,000 |
| **API Rates** | | |
| SWIFT (req/sec) | 8.9 | Quota: 10 |
| ACH (req/sec) | 32.4 | Quota: 100 |
| 429 Errors | 0.02% | Rate limit rejects |
| **Memory** | | |
| Used | 4.2 GB | Max: 8 GB |
| Per Settlement | 3.4 MB | |
| Buffers | 2.1 GB | TX/RX queues |
| OOM Risk | Low | < 50% |
| **Abuse** | | |
| Failed Settlements | 3 | Per day |
| AML Flags | 12 | Suspicious activity |
| Fraud Score | 0.8% | Flagged rate |
| Frozen Amount | $12,400 | Pending review |

---

## Network Health Dashboard

### Global Statistics (Epoch 18492)

```mermaid
graph TB
    subgraph "Network Health"
        N_CONS["Consensus: Age: 7 sec<br/>Signatures: 8/8<br/>Next in: 3 sec<br/>HotStuff QCs: 1,605/2,400 votes"]
        N_EPOCH["Epoch 18492<br/>Payments: 38.4M<br/>Value: $4.27B<br/>Avg payment: $111.20"]
        N_STAKE["Staked: 18.43M BLF $82.9B<br/>Slashed: 45,000 BLF $202K<br/>Inflation: 2,301 BLF/epoch $10K"]
        N_USERS["Estimated Users: 4.2M daily<br/>Active wallets: 1.8M<br/>Channels opened: 52K/day"]
    end
```

### Network Health Statistics

| Category | Metric | Value |
|----------|--------|-------|
| **Consensus** | | |
| State Root Age | 7 sec | Refresh interval: 10 sec |
| Notary Signatures | 8/8 | All notaries signed |
| Next State Root | 3 sec | Countdown |
| HotStuff Quorum | 1,605/2,400 | 67% threshold met |
| **Epoch** | | |
| Epoch Number | 18492 | |
| Total Payments | 38.4M | Per epoch (10 sec) |
| Total Value | $4.27B | Settlement value |
| Avg Payment | $111.20 | |
| **Staking** | | |
| Total Staked | 18.43M BLF | $82.9B USD |
| Staked Supply | 87.8% | Of total 21M BLF |
| Slashed (24h) | 45,000 BLF | $202K USD |
| Inflation Reward | 2,301 BLF | Per epoch (~$10K) |
| **Users** | | |
| Daily Users | 4.2M | Estimated |
| Active Wallets | 1.8M | With balance |
| Channels Opened | 52K/day | New channels |

---

## Fee Structure Breakdown

### $100 Payment Example

```

                      $100.00 Payment                    

 Routing Fees (Guard + Middle + Exit VR)               
   Guard VR (15.7M stake, 2 bps):     $0.020           
   Middle VR (6.3M stake, 3 bps):     $0.030           
   Exit SE (12.3M stake, 25 bps):     $0.250           
   Subtotal:                          $0.300           
                                                        
 Settlement Rail Fee (SWIFT MT103)                     
   Intermediary bank:                 $0.150           
   Correspondent fee:                 $0.100           
   Subtotal:                          $0.250           
                                                        
 Liquidity Fee (85% utilization penalty)               
   Base rate (2 bps)  1.5:          $0.030           
                                                        
 Payment Padding (Privacy overhead)                    
   1,200 dust cells/day  34 payments  $0.352          
                                                        
 Total Fees:                          $0.932           
                                                        
 Beneficiary Receives:                $99.068          
                                                        
 Settlement Time: 1.8 days (SWIFT)                     
 Privacy: 1-in-1,200 anonymity set                     

```

### Fee Distribution by Component

| Component | Fee | Percentage |
|-----------|-----|------------|
| Guard VR | $0.020 | 2.1% |
| Middle VR | $0.030 | 3.2% |
| Exit SE | $0.250 | 26.8% |
| SWIFT Bank | $0.250 | 26.8% |
| Liquidity | $0.030 | 3.2% |
| Padding | $0.352 | 37.8% |
| **Total** | **$0.932** | **100%** |

---

## Performance Baselines

### Target vs Actual Performance

| Metric | Target | Actual (p50) | Status |
|--------|--------|--------------|--------|
| Channel Build | 200-500ms | 127ms |  Better |
| Payment RTT | 600ms | 580ms |  On target |
| Consensus Finality | 200ms | 200ms |  On target |
| Cell Processing | 0.8 s | 0.76 s |  On target |
| TPS per Shard | 10,000 | 8,423 |  Below target |
| SWIFT Settlement | 2 days | 1.8 days |  Better |
| Success Rate | 99.5% | 99.91% |  Better |

---

## Key Takeaways

1. **FP Metrics**: 12 channels, 34 active streams, $0.31 avg fee
2. **Guard VR**: 5,823 channels, 98% CPU, 45 Gbps throughput
3. **Settlement SE**: 1,247 active settlements, SWIFT 8.9 req/sec
4. **Network Health**: 4.2M daily users, $4.27B/epoch volume
5. **Fees**: $0.932 on $100 payment (0.93% total)

---

*Next: [TOR_FINALLIKA_MAPPING.md](./TOR_FINALLIKA_MAPPING.md) - Complete Analogy Reference*
</file>

<file path="docs/finallica/PERFORMANCE_ANALYSIS.md">
# Finallica Performance Analysis

This document provides a detailed breakdown of CPU, memory, and network bottlenecks in the Finallica system.

---

## CPU Flame Graph: $100 Payment Processing Cost

### Total CPU Time: 1,847 s per payment

```mermaid
graph TD
    subgraph "Total CPU Time: 1,847 s per payment"
        subgraph "Entry VR (Client  Guard): 1,198 s"
            E_TLS["TLS 1.3 handshake: 850 s<br/>ECDSA P-256 verify: 320 s<br/>X25519 key schedule: 180 s<br/>Kernel copy_user: 350 s"]
            E_NOISE["Noise_XX handshake: 230 s<br/>X25519 scalar mult: 90 s<br/>BLAKE2s Hash: 25 s<br/>BLS verify (batch): 105 s<br/>HKDF Expand: 10 s"]
            E_PAY["BLS sign payment: 110 s<br/>Pedersen commitment: 45 s<br/>Range proof (Bulletproofs+): 780 s<br/>SHA256(payment_hash): 0.5 s"]
            E_ROUTE["Path selection: 12 s<br/>Routerlist lookup: 4 s<br/>Stake weight calc: 8 s"]
            E_CELL["Cell crypto: 2 s<br/>ChaCha20 (AVX2): 1.2 s<br/>Poly1305: 0.8 s"]
        end

        subgraph "Middle VR (Hop 2): 4 s"
            M_DEC["Decrypt/verify: 3 s<br/>ChaCha20: 1.2 s<br/>Poly1305: 0.8 s<br/>BLS batch: 0.15 s<br/>Digest update: 0.85 s"]
            M_FWD["Forward cell: 1 s<br/>rte_ring_enqueue: 0.5 s<br/>KIST schedule: 0.5 s"]
        end

        subgraph "Exit VR (Settlement): 15,231 s"
            X_SETTLE["SWIFT MT103: 15,000 s<br/>API call: 14,800 s<br/>Response parse: 200 s"]
            X_BLS["BLS aggregate: 125 s<br/>Combine 64 settlement sigs"]
            X_STATE["State root update: 106 s<br/>Merkle trie: 80 s<br/>HotStuff propose: 26 s"]
        end
    end

    E_TLS --> E_NOISE
    E_NOISE --> E_PAY
    E_PAY --> E_ROUTE
    E_ROUTE --> E_CELL

    M_DEC --> M_FWD

    style X_SETTLE fill:#f66
    style E_PAY fill:#fb0
```

### CPU Breakdown by Component

| Component | Time (s) | Percentage | Bottleneck |
|-----------|-----------|------------|------------|
| **Entry VR** | 1,198 | 65% | TLS + BLS + Pedersen |
| TLS 1.3 | 850 | 46% | ECDSA verify |
| Noise_XX | 230 | 12% | X25519 |
| BLS operations | 110 | 6% | Pairing operations |
| Pedersen + Range Proof | 825 | 45% | Bulletproofs+ |
| **Middle VR** | 4 | 0.2% | Minimal overhead |
| **Exit VR** | 15,231 | 82% | SWIFT API dominates |
| SWIFT API | 15,000 | 81% | External call |
| BLS aggregate | 125 | 0.7% | Batch operations |
| State update | 106 | 0.6% | Merkle trie |

### Optimization Opportunities

| Bottleneck | Current | Optimized | Improvement |
|------------|---------|-----------|-------------|
| TLS 1.3 handshake | 850 s | 0-RTT resumption | 85% |
| Bulletproofs+ verify | 780 s | Batch verify (64) | 70% |
| BLS verify | 105 s | Pre-computed pairings | 40% |
| SWIFT API | 15,000 s | Async + caching | N/A (external) |

---

## Memory Allocation: Per-Channel Resource Consumption

### Total: 40,736 bytes per channel

```mermaid
graph LR
    subgraph "Heap Memory per Channel (40,736 bytes)"
        C_STATE["Channel State<br/>struct channel_t<br/>224 bytes<br/>{channel_id, state, peer_pubkey, stake}"]

        subgraph "Cryptographic Keys (1,536 bytes)"
            K_PAY["Pay Cipher<br/>crypto_aead_state<br/>ChaCha20-Poly1305<br/>32-byte key + 12-byte nonce<br/>256 bytes"]
            K_SETTLE["Settle Cipher<br/>crypto_aead_state<br/>256 bytes"]
            K_PAD["Pad Cipher<br/>crypto_aead_state<br/>256 bytes"]
            K_REKEY["Rekey Key<br/>uint8_t[32]<br/>32 bytes"]
            K_HANDSHAKE["Noise Handshake State<br/>handshake_state_t<br/>384 bytes"]
            K_BLS["BLS Keypair<br/>bls_secret_key<br/>32 bytes + 48 bytes pubkey<br/>80 bytes"]
            K_PED["Pedersen Blinding<br/>secp256k1_scalar<br/>32 bytes"]
        end

        subgraph "HTLC Table (30,912 bytes)"
            HTLC["HTLC Entry Array<br/>struct htlc[HTLC_MAX_PER_CHANNEL]<br/>483 entries  64 bytes<br/>{payment_hash, amount, expiry, status}"]
        end

        subgraph "Queue Buffers (4,096 bytes)"
            Q_IN["Input Ring<br/>rte_ring<br/>1024 entries  4 bytes<br/>Lockless producer-consumer"]
            Q_OUT["Output Ring<br/>rte_ring<br/>1024 entries  4 bytes"]
        end

        subgraph "Replay Protection (8,192 bytes)"
            REPLAY["Bloom Filter<br/>cell_sequence cache<br/>10,000 bits<br/>FP rate: 0.1%"]
        end

        subgraph "Path State (640 bytes)"
            P_GUARD["Guard Info<br/>entry_guard_t pointer<br/>128 bytes"]
            P_MIDDLE["Middle VR List<br/>smartlist_t *vrs<br/>64 bytes + 3 pointers"]
        end
    end

    C_STATE --> K_PAY
    C_STATE --> K_SETTLE
    C_STATE --> HTLC
    K_PAY --> K_REKEY
    HTLC --> Q_IN
    Q_OUT --> REPLAY
```

### Memory Breakdown

| Component | Size (bytes) | Percentage |
|-----------|--------------|------------|
| Channel State | 224 | 0.5% |
| Cryptographic Keys | 1,536 | 3.8% |
| HTLC Table | 30,912 | 75.9% |
| Queue Buffers | 4,096 | 10.1% |
| Replay Protection | 8,192 | 2.0% |
| Path State | 640 | 1.6% |
| Overhead | 224 | 0.5% |
| **Total** | **40,736** | **100%** |

### Channel Capacity by Memory

| Memory | Max Channels | Notes |
|--------|--------------|-------|
| 4 GB | ~98,000 | Theoretical (no overhead) |
| 8 GB | ~150,000 | Practical max |
| 16 GB | ~250,000 | High-end VR |
| 64 GB | ~1,000,000 | With kernel + stack |

**OOM Killer**: Activates at 90% memory usage, closes lowest-capacity channels first.

---

## Network Saturation: Shard Capacity Limits

### Guard VR Capacity (100 Gbps NIC)

```mermaid
graph TB
    subgraph "Shard 0 Capacity (Guard VR: 100 Gbps NIC)"
        G_BW_TOTAL["Total Bandwidth: 100 Gbps<br/>12.5 GB/s theoretical"]

        subgraph "Traffic Breakdown"
            G_BW_CLIENT["Client Uplinks: 25%<br/>3.125 GB/s<br/>50,000 concurrent FP connections<br/>Avg: 62.5 Mbps per FP"]
            G_BW_VR["VR-to-VR (Data Plane): 55%<br/>6.875 GB/s<br/>2,406 VR peers  2.86 Gbps each"]
            G_BW_BRIDGE["Cross-Shard Bridges: 10%<br/>1.25 GB/s<br/>120 bridges  10.4 Gbps each"]
            G_BW_CONTROL["Consensus/Control: 5%<br/>0.625 GB/s<br/>TLS 1.3, port 31338"]
            G_BW_PADDING["Payment Padding: 5%<br/>0.625 GB/s<br/>Constant 1 cell/sec per channel"]
        end

        G_CONN_LIMIT["Connection Limits<br/>DPDK max flows: 1,048,576<br/>Actual: 50,000 client + 2,406 VR = 52,406<br/>Per-flow memory: 128 bytes"]
        G_CPU_LIMIT["CPU Saturation<br/>16 cores @ 3.5 GHz<br/>Max ChaCha20: 25M cells/sec (AVX2)<br/>Max BLS verify: 64K sigs/sec (batch)<br/>Limiting factor: BLS @ 6,000 payments/sec"]
    end

    G_BW_CLIENT --> G_CONN_LIMIT
    G_BW_VR --> G_CPU_LIMIT
```

### Middle VR Capacity (200 Gbps NIC)

| Metric | Value | Notes |
|--------|-------|-------|
| Total Bandwidth | 200 Gbps | 25 GB/s theoretical |
| Pure Relay | 92% | 23 GB/s |
| Consensus Gossip | 3% | 0.75 GB/s |
| Padding | 5% | 1.25 GB/s |
| Max Channels | 15,000 | 64 GB RAM limit |
| OOM Threshold | 48 GB | Activates killer |

**Per-Channel Bandwidth**: 1.92 Gbps (23 GB/s  12,000 channels)

### Settlement Executor (Exit VR) Capacity

| Metric | Value | Limiting Factor |
|--------|-------|-----------------|
| Total Uplink | 40 Gbps | 5 GB/s |
| SWIFT/ACH API | 60% | 3 GB/s |
| VR Mesh | 25% | 1.25 GB/s |
| Consensus | 10% | 0.5 GB/s |
| API Rate (SWIFT) | 10 req/sec | Per SE |
| API Rate (ACH) | 100 req/sec | Per SE |
| Max Settlements | 1,000 | Concurrent |

**File Descriptors**: 2 per settlement stream (in + out)
**Max**: 2,000 FDs
**TCP keepalive**: 300 seconds

---

## Performance Benchmarks

### Latency Distribution (Channel Build)

| Percentile | Latency | Notes |
|------------|---------|-------|
| p50 | 127 ms | Median |
| p95 | 340 ms | Typical SLA |
| p99 | 1,250 ms | Timeout failures |
| p99.9 | 5,000 ms | Adaptive timeout limit |

### Payment Processing Rate

| Node Type | Payments/sec | Limiting Factor |
|-----------|--------------|-----------------|
| Guard VR | 6,000 | BLS verification |
| Middle VR | 25,000 | ChaCha20 (AVX2) |
| Exit VR | 50 | SWIFT API rate |

### Network-Wide Throughput

| Metric | Value |
|--------|-------|
| Total TPS (all shards) | ~10,000 |
| Total Value/sec | ~$1.1M |
| Avg Payment | $111.20 |
| Peak (observed) | 12,847 TPS |

---

## Key Takeaways

1. **CPU Bottleneck**: Entry VR (TLS 850s + Pedersen 780s)
2. **Memory Bottleneck**: HTLC table (76% per-channel)
3. **Network Bottleneck**: Guard VR CPU (BLS verification @ 6K TPS)
4. **External Bottleneck**: SWIFT API (15ms, dominates Exit VR)
5. **Scaling Limit**: 15K channels per VR (64 GB RAM)

---

*Next: [CRYPTOGRAPHIC_DETAILS.md](./CRYPTOGRAPHIC_DETAILS.md) - Commitment Unwrapping & Encryption*
</file>

<file path="docs/finallica/PROTOCOL_SPECIFICATION.md">
# Finallica Protocol Specification

This document describes the state machines and cell processing pipeline of the Finallica network.

---

## Section 3: State Machines

### 3.1 Channel Lifecycle State Machine

```mermaid
graph TB
    subgraph "Channel Lifecycle"
        C_INIT["INIT<br/>channel->state = CHANNEL_BUILDING<br/>channel->n_hops = 0<br/>local_balance = capacity<br/>remote_balance = 0"]
        C_G_WAIT["GUARD_WAIT<br/>awaiting OPENED<br/>channel->n_hop_build = 1<br/>noise_hs_state = 'e, ee, s, es'"]
        C_M_WAIT["MID_WAIT<br/>awaiting EXTENDED<br/>channel->n_hop_build = 2<br/>K_pay derived"]
        C_OPEN["OPEN<br/>channel->state = CHANNEL_OPEN<br/>n_hops = 3<br/>valid_for = 21600 sec (6h)<br/>cells_sent = 0<br/>last_rekey = now()"]
        C_ACTIVE["ACTIVE<br/>channel->package_window = 1000<br/>htlc_table[483] active<br/>rebalance_threshold = 0.85"]
        C_SETTLING["SETTLING<br/>settle_timer = 60 sec<br/>pending_htlcs = 0<br/>finalize_state_root()"]
        C_CLOSED["CLOSED<br/>channel->state = CLOSED<br/>reason: TIMEOUT|SLASH|USER_CLOSE<br/>balances settled on-chain"]
    end

    C_INIT -->|OPEN cell sent| C_G_WAIT
    C_G_WAIT -->|OPENED received| C_M_WAIT
    C_M_WAIT -->|EXTENDED received| C_OPEN
    C_OPEN -->|First PAY cell| C_ACTIVE
    C_ACTIVE -->|Channel timeout| C_SETTLING
    C_ACTIVE -->|User close| C_SETTLING
    C_ACTIVE -->|Slashing event| C_CLOSED
    C_SETTLING -->|Settlement confirmed| C_CLOSED
```

#### Channel State Transitions

| From State | To State | Trigger | Conditions |
|------------|----------|---------|------------|
| INIT | GUARD_WAIT | OPEN cell sent | Client initiates channel |
| GUARD_WAIT | MID_WAIT | OPENED received | Guard VR responds |
| MID_WAIT | OPEN | EXTENDED received | All hops built |
| OPEN | ACTIVE | First PAY cell | Channel ready for payments |
| ACTIVE | SETTLING | Timeout / User close | 6h elapsed or manual close |
| ACTIVE | CLOSED | Slashing event | 100% stake slash |
| SETTLING | CLOSED | Settlement confirmed | All HTLCs resolved |
| Any | CLOSED | DESTROY cell | Immediate teardown |

#### Channel State Structure

```c
enum channel_state_t {
  CHANNEL_BUILDING,
  CHANNEL_GUARD_WAIT,
  CHANNEL_MID_WAIT,
  CHANNEL_OPEN,
  CHANNEL_ACTIVE,
  CHANNEL_SETTLING,
  CHANNEL_CLOSED
};

struct channel_t {
  uint32_t channel_id;
  channel_state_t state;
  uint8_t n_hops;
  uint8_t n_hop_build;

  // Balances (in microcents)
  uint64_t local_balance;
  uint64_t remote_balance;
  uint64_t capacity;

  // Cryptographic keys
  crypto_aead_state *k_pay;
  crypto_aead_state *k_settle;
  crypto_aead_state *k_pad;

  // HTLC table
  htlc_entry_t *htlc_table[HTLC_MAX_PER_CHANNEL]; // 483 entries
  uint16_t htlc_count;

  // Timing
  uint64_t created_at;
  uint64_t last_rekey;
  uint64_t valid_until; // 6 hours

  // Flow control
  int package_window;   // 1000 cells
  int deliver_window;   // 1000 cells
};
```

### 3.2 HTLC State Machine

```mermaid
graph TB
    subgraph "Payment HTLC State"
        H_INIT["HTLC_INIT<br/>htlc->payment_hash = SHA256(preimage)<br/>htlc->amount = 10M microcents<br/>htlc->expiry = block+100<br/>status = OFFERED"]
        H_LOCKED["HTLC_LOCKED<br/>Sent PAY cell<br/>All hops acked<br/>status = LOCKED<br/>locked_at = now()"]
        H_SETTLED["HTLC_SETTLED<br/>Preimage revealed<br/>settled_on_chain = true<br/>status = SETTLED<br/>finality_time = 200ms"]
        H_REFUNDED["HTLC_REFUNDED<br/>expiry < block_height<br/>preimage NOT revealed<br/>status = REFUNDED<br/>refund_tx_broadcast = true"]
        H_FAILED["HTLC_FAILED<br/>Channel closed mid-route<br/>reason: INSUFFICIENT_LIQUIDITY|TIMEOUT<br/>status = FAILED"]
    end

    H_INIT -->|PAY cell forwarded| H_LOCKED
    H_LOCKED -->|SETTLE cell + preimage| H_SETTLED
    H_LOCKED -->|expiry passed| H_REFUNDED
    H_LOCKED -->|channel_destroyed| H_FAILED
```

#### HTLC State Transitions

| From State | To State | Trigger | Timeout |
|------------|----------|---------|----------|
| OFFERED | LOCKED | All hops ACK | 30 seconds |
| LOCKED | SETTLED | Preimage revealed | Block expiry |
| LOCKED | REFUNDED | Expiry passed | Block+100 |
| Any | FAILED | Channel closed / Insufficient liquidity | Immediate |

#### HTLC Entry Structure

```c
enum htlc_state_t {
  HTLC_OFFERED,
  HTLC_LOCKED,
  HTLC_SETTLED,
  HTLC_REFUNDED,
  HTLC_FAILED
};

struct htlc_entry_t {
  uint64_t htlc_id;
  uint8_t payment_hash[32]; // SHA256 of preimage
  uint64_t amount;          // In microcents
  uint32_t expiry;          // Block height
  htlc_state_t state;
  uint64_t created_at;
  uint64_t locked_at;

  // Routing
  bls_pubkey_t next_hop;
  uint16_t stream_id;
};
```

---

## Section 4: Cell Processing Pipeline

### 4.1 Per-Hop Processing Pipeline

Target latency: **0.8 s** per cell (fast path)

```mermaid
graph LR
    subgraph "Per-Hop Cell Processing (0.8 s target)"
        DPDK_RECV["DPDK RX Queue<br/>rte_eth_rx_burst()<br/>Poll mode, no IRQ<br/>32 mbufs per batch"]
        PREFETCH["Prefetch: __builtin_prefetch()<br/>L2 cache load<br/>64-byte alignment check"]
        PARSE_CELL["Parse Header<br/>Extract: channel_id, cmd, shard_id<br/>CRC32C verification: 0.02 s"]

        subgraph "Cryptographic Operations"
            CMD_SWITCH["Switch Command"]

            PADDING["Command: PADDING<br/>Dummy cell<br/>Update padding stats<br/>Free mbuf"]

            OPEN["Command: OPEN<br/>Noise_XX handshake<br/>X25519: 90s (slow path)<br/>BLS verify: 105s<br/>Derive K_pay, K_settle"]

            PAY["Command: PAY<br/>Decrypt: ChaCha20-Poly1305<br/>pedersen_verify: 45s<br/>BLS batch verify: 0.15s<br/>Update running digest"]

            SETTLE["Command: SETTLE<br/>Verify preimage: SHA256<br/>Check expiry > block<br/>BLS aggregate: 125s<br/>Commit to state root"]

            REKEY["Command: REKEY<br/>Verify sig: Ed25519<br/>Rotate ChaCha20 keys<br/>Reset nonce counter"]

            DESTROY["Command: DESTROY<br/>channel_mark_for_close()<br/>Settle remaining HTLCs<br/>Emit Close event"]
        end

        BALANCE_UPDATE["Update Channel Balance<br/>Homomorphic subtract:<br/>C_new = C_old - payment_commit<br/>Check C_new > 0"]

        FORWARD["Forward Cell<br/>rte_ring_enqueue()<br/>KIST scheduler<br/>Next hop: lookup_route(channel_id)"]

        DPDK_SEND["DPDK TX Queue<br/>rte_eth_tx_burst()<br/>Batch 32 cells<br/>Zero-copy"]
    end

    DPDK_RECV --> PREFETCH
    PREFETCH --> PARSE_CELL
    PARSE_CELL --> CMD_SWITCH
    CMD_SWITCH -->|cmd=0x00| PADDING
    CMD_SWITCH -->|cmd=0x01| OPEN
    CMD_SWITCH -->|cmd=0x02| PAY
    CMD_SWITCH -->|cmd=0x03| SETTLE
    CMD_SWITCH -->|cmd=0x04| REKEY
    CMD_SWITCH -->|cmd=0x05| DESTROY

    PAY --> BALANCE_UPDATE
    SETTLE --> BALANCE_UPDATE

    BALANCE_UPDATE --> FORWARD
    FORWARD --> DPDK_SEND
```

### 4.2 Cell Structure

All Finallica traffic flows in **1,024-byte transaction cells**:

```c
struct finallica_cell {
  // Byte offset 0: Channel identification
  uint32_t channel_id;      // Big-endian, connection-scoped
  uint8_t  shard_id;        // 0-126, shard topology
  uint8_t  command;         // PAY=0x01, SETTLE=0x02, OPEN=0x03, etc.
  uint16_t stream_id;       // Big-endian, 0x0000 = circuit-level
  uint64_t cell_seq;        // Big-endian, monotonic counter

  // Byte offset 16: Cryptographic metadata
  uint8_t  commitment[33];  // Compressed Pedersen commitment
  uint8_t  bls_signature[96]; // BLS12-381 G2 signature

  // Byte offset 145: Payment payload (encrypted)
  uint8_t  nonce[12];       // ChaCha20 nonce (counter mode)
  uint8_t  payload[867];    // Encrypted payment data
  uint16_t payload_len;     // Big-endian, 0-867 bytes
  uint8_t  auth_tag[16];    // Poly1305 MAC
} __attribute__((packed, aligned(64)));
```

**Total size: 1,042 bytes  Padded to 1,024 bytes**

### 4.3 Command Types

| Command | Value | Description | Processing Time |
|---------|-------|-------------|-----------------|
| PADDING | 0x00 | Dummy cell for traffic shaping | 0.01 s |
| OPEN | 0x01 | Channel initiation (Noise_XX) | 230 s (slow path) |
| PAY | 0x02 | Payment data with HTLC | 45 s |
| SETTLE | 0x03 | Settlement with preimage | 125 s |
| EXTEND | 0x04 | Extend channel to next hop | 230 s |
| REKEY | 0x05 | Rotate encryption keys | 5 s |
| DESTROY | 0x06 | Channel teardown | 10 s |

### 4.4 Payment Payload Structure (PAY cell)

```c
struct payment_relay_t {
  uint16_t stream_id;          // Payment stream identifier
  uint64_t amount_microcents;  // 8-byte fixed-point: 1 = $0.00001
  uint32_t timeout_unix;       // Settlement deadline
  uint8_t  next_hop[32];       // BLS pubkey hash of next VR
  uint8_t  payment_hash[32];   // SHA256 of preimage
  uint8_t  command;            // FORWARD=0x01, SETTLE=0x02, REFUND=0x03
  uint8_t  data[];             // Variable-length invoice metadata
} __attribute__((packed));
```

### 4.5 Processing Code Example

```c
void process_payment_cell(struct finallica_cell *cell,
                          crypto_aead_state *cipher) {
  // Prefetch for cache efficiency
  __builtin_prefetch(cell, 0, 3);

  // Verify BLS signature (fast-fail)
  if (!bls_verify_fast(&cell->bls_signature,
                       cell->commitment, 33,
                       vr_bls_pubkey)) {
    channel_mark_for_close(cell->channel_id, REASON_INVALID_SIG);
    return;
  }

  // Decrypt payload (ChaCha20-Poly1305)
  uint8_t plaintext[867];
  if (crypto_aead_chacha20poly1305_decrypt(
        plaintext, NULL, NULL,
        cell->payload, cell->payload_len,
        cell->auth_tag, 16,
        cell->nonce, cipher->key) != 0) {
    channel_penalty(cell->channel_id, 100);
    return;
  }

  // Parse payment relay header
  struct payment_relay_t *relay = (struct payment_relay_t *)plaintext;

  // Update channel balance (homomorphic subtraction)
  secp256k1_pedersen_commitment new_commit;
  secp256k1_pedersen_commitment_subtract(
    &new_commit, &cell->commitment, &relay->amount_commit);

  // Verify balance > 0
  if (!secp256k1_pedersen_commitment_verify_positive(&new_commit)) {
    channel_mark_for_close(cell->channel_id, REASON_INSUFFICIENT_FUNDS);
    return;
  }

  // Re-encrypt for next hop and forward
  crypto_aead_chacha20poly1305_encrypt(
    cell->payload, NULL,
    plaintext, relay->data_len,
    NULL, 0,
    cell->nonce, next_hop_cipher->key,
    cell->auth_tag);

  forward_cell(cell);
}
```

### 4.6 DPDK Integration

**Kernel bypass for maximum throughput**:

```c
// DPDK initialization
int finallica_dpdk_init(int argc, char **argv) {
  ret = rte_eal_init(argc, argv);

  // Memory pool per NUMA node
  pkt_pool = rte_pktmbuf_pool_create(
    "finallica_pkt_pool",
    FINALLICA_PKT_POOL_SIZE,  // 2,097,152 packets
    FINALLICA_CACHE_SIZE,      // 512 per core
    0,
    FINALLICA_CELL_SIZE,       // 1024 + headroom
    rte_socket_id()
  );

  // NIC setup: disable IRQ, enable RSS
  struct rte_eth_conf port_conf = {
    .rxmode = {
      .mq_mode = ETH_MQ_RX_RSS,
      .offloads = DEV_RX_OFFLOAD_CHECKSUM,
    },
    .rss_conf = {
      .rss_key = rss_key,
      .rss_key_len = 40,
      .rss_hf = ETH_RSS_NONFRAG_IPV4_UDP,
    }
  };

  rte_eth_dev_configure(port_id, rx_rings, tx_rings, &port_conf);

  return 0;
}

// Zero-copy cell processing
void finallica_cell_process(struct rte_mbuf *m) {
  struct finallica_cell *cell = rte_pktmbuf_mtod(m, struct finallica_cell *);

  // Prefetch next mbuf while processing current
  __builtin_prefetch(rte_pktmbuf_mtod(m->next, void *), 0, 1);

  // Process cell inline, no queueing
  vr_process_cell(cell);

  // Free mbuf back to pool
  rte_pktmbuf_free(m);
}
```

### 4.7 Performance Targets

| Operation | Target | Actual (p50) |
|-----------|--------|--------------|
| Cell receive (DPDK) | 0.1 s | 0.08 s |
| Parse header | 0.02 s | 0.015 s |
| ChaCha20 decrypt | 1.2 s | 1.1 s |
| Poly1305 verify | 0.8 s | 0.75 s |
| BLS batch verify | 0.15 s | 0.12 s |
| Balance update | 0.5 s | 0.45 s |
| Forward | 0.1 s | 0.08 s |
| **Total (fast path)** | **0.8 s** | **0.76 s** |

---

## Key Takeaways

1. **Channel States**: 7 states from INIT to CLOSED, 6-hour lifetime
2. **HTLC States**: 5 states (OFFERED  LOCKED  SETTLED/REFUNDED/FAILED)
3. **Cell Processing**: 0.8 s target via DPDK + lockless queues
4. **Commands**: 7 types (PADDING, OPEN, PAY, SETTLE, EXTEND, REKEY, DESTROY)
5. **Cryptography**: ChaCha20-Poly1305 (fast path), BLS12-381 (signatures)

---

*Next: [PERFORMANCE_ANALYSIS.md](./PERFORMANCE_ANALYSIS.md) - CPU/Memory/Network Bottlenecks*
</file>

<file path="docs/finallica/README.md">
# Finallica: Global Financial Privacy Network

## Executive Summary

**Finallica** is a global, trust-minimized payment overlay network that adapts Tor's anonymity architecture for financial value transfer. It operates as a 127-shard network of ~12,000 Validator-Routers (VRs) processing payments through layered encryption, stake-weighted routing, and BFT consensus.

### Key Characteristics

| Attribute | Value |
|-----------|-------|
| **Network Size** | 12,000 Validator-Routers across 127 jurisdictional shards |
| **Consensus** | HotStuff BFT with 8 notaries, 200ms finality |
| **Cryptography** | BLS12-381 (staking), Noise_XX (handshakes), ChaCha20-Poly1305 (payments) |
| **Throughput** | ~10,000 payments/sec per shard (theoretical) |
| **Settlement** | SWIFT (1-3 days), ACH (1-2 days), Bitcoin (10 min), Lightning (3 sec) |
| **Anonymity Set** | ~1,200 users per payment |
| **Avg Fee** | 0.3% ($0.31 on $100 payment) |
| **Staking Required** | 500K BLF (~$2.25M) for VR, 2M BLF (~$9M) for Settlement Executor |

---

## Quick Concepts

### Core Components

1. **Finallica Proxy (FP)**: Local wallet daemon that handles pathfinding, channel construction, and payment stream multiplexing. Analogous to Tor's Onion Proxy.

2. **Validator-Router (VR)**: Network nodes that forward encrypted payment cells. Three types:
   - **Guard VR**: Entry point (persistent, high-stake)
   - **Middle VR**: Pure forwarding
   - **Settlement Executor (SE)**: Exit node connecting to legacy rails (SWIFT, ACH, BTC)

3. **Consensus Notary**: 8 geo-distributed authorities that sign global state roots every 10 seconds.

4. **Payment Channel**: 3-hop encrypted path (Guard  Middle  Exit) with HTLC-locked funds, valid for 6 hours.

### How a Payment Flows

```
User Scan Invoice  FP Selects Path  Channel Built (Noise_XX)  HTLC Attached  Settlement  Beneficiary Paid
        (12ms)              (247ms p50)              (5ms)          (1-3 days SWIFT)
```

---

## Tor vs Finallica Comparison

| **Tor Concept** | **Finallica Analogue** | **Key Differences** |
|----------------|------------------------|---------------------|
| Onion Router (OR) | Validator-Router (VR) | VRs stake BLF tokens; ORs volunteer |
| Guard Node | Entry VR (persistent) | 90-day persistence vs Tor's variable |
| Middle Node | Middle VR (ephemeral) | Identical forwarding role |
| Exit Node | Settlement Executor (SE) | SE connects to fiat rails; Tor exits to Internet |
| Directory Authority (9) | Consensus Notary (8) | Notaries sign state roots; Dir authorities vote on consensus |
| Circuit (3 hops) | Payment Channel (3 hops) | Channels have HTLC balances; circuits are stateless |
| RELAY cell | PAY cell | Payments include Pedersen commitments |
| AES-128-CTR | ChaCha20-Poly1305 | Different cipher, same layered encryption |
| NTor (X25519) | Noise_XX (X25519) | Similar handshake, Finallica adds BLS stake binding |
| No financial state | HTLC balance table | Channels track locked funds |
| Free to use | 0.3% avg fee | Economic incentives for operators |
| No finality | HotStuff BFT (200ms) | Finallica has settlement finality |

---

## Key Metrics at a Glance

### Network Health (Epoch 18492)
- **Total Payments**: 38.4M per epoch
- **Transaction Value**: $4.27B per epoch
- **Average Payment**: $111.20
- **Estimated Users**: 4.2M daily, 1.8M active wallets
- **Staked Supply**: 18.43M BLF ($82.9B) = 87.8% of total supply

### Performance
- **Channel Build Time**: 127ms (p50), 340ms (p95)
- **Payment RTT**: 580ms average
- **Consensus Finality**: 200ms (4-phase HotStuff)
- **Cell Processing**: 0.8 s per hop (target)

### Security
- **Guard Compromise Probability**: 0.31% per payment
- **Timing Correlation Success**: 12% (global passive adversary)
- **Anonymity Set**: 1-in-1,200 users
- **Slashing (24h)**: 45,000 BLF ($202K)

---

## Documentation Index

| Document | Description | Points Covered |
|----------|-------------|----------------|
| [ARCHITECTURE_OVERVIEW.md](./ARCHITECTURE_OVERVIEW.md) | 127-shard topology, E2E payment flow | 1-2 |
| [PROTOCOL_SPECIFICATION.md](./PROTOCOL_SPECIFICATION.md) | State machines, cell processing pipeline | 3-4 |
| [PERFORMANCE_ANALYSIS.md](./PERFORMANCE_ANALYSIS.md) | CPU/memory/network bottlenecks | 5 |
| [CRYPTOGRAPHIC_DETAILS.md](./CRYPTOGRAPHIC_DETAILS.md) | Commitment unwrapping, encryption layers | 6 |
| [LIQUIDITY_MANAGEMENT.md](./LIQUIDITY_MANAGEMENT.md) | Flow control, channel windows | 7 |
| [CONSENSUS_MECHANISM.md](./CONSENSUS_MECHANISM.md) | HotStuff BFT, state roots | 8 |
| [SECURITY_ANALYSIS.md](./SECURITY_ANALYSIS.md) | Attack vectors, defenses | 9 |
| [OPERATIONAL_METRICS.md](./OPERATIONAL_METRICS.md) | Live production dashboards | 10 |
| [TOR_FINALLIKA_MAPPING.md](./TOR_FINALLIKA_MAPPING.md) | Complete analogy reference | All |
| [RESEARCH_PROPOSALS.md](./RESEARCH_PROPOSALS.md) | v5.0 roadmap (Fin-340, Fin-N23, Fin-PQ) | Future |
| [CONSTANTS_REFERENCE.md](./CONSTANTS_REFERENCE.md) | All hardcoded values | Reference |

---

## System Architecture Overview

```mermaid
graph TB
    subgraph "Global Consensus Layer (8 Notaries)"
        N1[Notary1: 50M BLF]
        N2[Notary2: 48M BLF]
        N3[Notary3: 52M BLF]
        N4[Notary4: 45M BLF]
    end

    subgraph "Shard 0 (North America) - 2,407 VRs"
        G1[Guard: 15.7M BLF]
        M1[Middle: 6.3M BLF]
        E1[Exit SE: 12.3M BLF]
    end

    subgraph "Client Infrastructure"
        FP[Finallica Proxy]
        WALLET[Wallet UI]
    end

    subgraph "Legacy Rails"
        SWIFT[SWIFT: 1-3 days]
        ACH[ACH: 1-2 days]
        BTC[Bitcoin: 10 min]
    end

    N1 -->|BLS sign| CONS[Global State Root<br/>Every 10 sec]
    N2 -->|BLS sign| CONS
    N3 -->|BLS sign| CONS
    N4 -->|BLS sign| CONS

    CONS --> G1
    G1 <-->|Noise_XX + DPDK| M1
    M1 <-->|Noise_XX + DPDK| E1

    WALLET -->|Noise_XK| FP
    FP -->|OPEN cell| G1
    E1 -->|MT103| SWIFT
    E1 -->|NACHA| ACH
    E1 -->|RPC| BTC
```

---

## Payment Flow Sequence

```mermaid
sequenceDiagram
    participant User as User
    participant FP as Finallica Proxy
    participant G as Guard VR
    participant M as Middle VR
    participant E as Settlement Executor
    participant Bank as Bank

    User->>FP: Scan BOLT-11 invoice
    FP->>FP: Select path (12ms)
    FP->>G: OPEN2 cell (Noise_XX)
    G->>FP: OPENED2 cell
    FP->>G: EXTEND to Middle
    M->>G: OPENED
    FP->>M: EXTEND to Exit
    E->>M: OPENED
    FP->>G: PAY cell (HTLC)
    G->>M: PAY (decrypt/forward)
    M->>E: PAY (decrypt/forward)
    E->>Bank: SWIFT MT103
    Bank->>E: MT900 (1-3 days)
    E->>FP: SETTLE cell + preimage
    FP->>User: Payment settled
```

---

## Roadmap

### v4.2 (Current)
- BLS12-381 stake attestations
- Noise_XX handshakes
- HotStuff BFT consensus
- Bulletproofs+ range proofs

### v5.0 (2026 - Proposed)
- **Fin-340**: RingCT with MLSAG ring signatures (anonymity: 1,331)
- **Fin-N23**: eBPF flow control (0.3 s latency, per-stream windows)
- **Fin-PQ**: Post-quantum STARK proofs (quantum-resistant)
- **Fin-Sharding**: Dynamic shard splitting (unlimited TPS)

---

## License & Disclaimer

This is a theoretical architecture specification for educational purposes. Finallica is not a deployed network.

---

*Last Updated: 2024-12-22*
</file>

<file path="docs/finallica/RESEARCH_PROPOSALS.md">
# Finallica Research Proposals

This document describes proposed enhancements to the Finallica system, targeting the v5.0 release in 2026.

---

## Overview: Roadmap to v5.0

```mermaid
graph LR
    subgraph "Current System (v4.2)"
        CURR["Current<br/>BLS signatures<br/>ChaCha20 encryption<br/>HotStuff consensus<br/>Bulletproofs+ range proofs"]
    end

    subgraph "Proposal Fin-340: RingCT"
        RINGCT["RingCT Integration<br/>MLSAG ring sig (size 11)<br/>Bulletproofs+ aggregated<br/>Anonymity: 11 = 1,331<br/>Overhead: +2KB/payment"]
    end

    subgraph "Proposal Fin-N23: eBPF Flow Control"
        EBPF["eBPF Rate Limiter<br/>Token bucket in kernel<br/>0.3 s latency<br/>Per-stream windows<br/>Head-of-line blocking eliminated"]
    end

    subgraph "Proposal Fin-PQ: Post-Quantum"
        PQ["STARK State Proofs<br/>192 KB proof size<br/>45 ms verification<br/>Quantum-resistant<br/>BLS  STARK migration"]
    end

    subgraph "Proposal Fin-Sharding: Dynamic Shards"
        DYN["Dynamic Sharding<br/>Split at 8K TPS<br/>Verifiable shuffle<br/>Stake redistribution<br/>Unlimited scalability"]
    end

    CURR --> RINGCT
    CURR --> EBPF
    CURR --> PQ
    CURR --> DYN

    RINGCT -->|"Impact: +15% CPU, +25% privacy"| FUTURE
    EBPF -->|"Impact: -65% latency, +40% throughput"| FUTURE
    PQ -->|"Impact: +24 proof size, -0% quantum risk"| FUTURE
    DYN -->|"Impact: Unlimited TPS, +complexity"| FUTURE

    FUTURE["Finallica v5.0 (2026)"]
```

---

## Proposal Fin-340: RingCT Integration

### 11.1 Confidential Transactions with Ring Signatures

**Goal**: Hide payment amounts and increase anonymity set using ring signatures.

**Current System**:
```
- Pedersen commitment: C = v*G + b*H (33 bytes)
- Bulletproofs+ range proof: ~700 bytes
- Total per payment: ~733 bytes overhead
- Anonymity: 1-in-1,200 (from path diversity)
```

**Fin-340 System**:
```
- Ring commitment: C_ring = (C_i) for i in ring (11 decoys)
- MLSAG ring signature: ~1,000 bytes
- Bulletproofs+ (aggregated): ~500 bytes
- Total overhead: ~1,500 bytes per payment
- Anonymity: 11 = 1,331 (from ring size 11)
```

### 11.2 RingCT Payment Structure

```c
struct ringct_payment {
  // Ring of 11 inputs (1 real + 10 decoys)
  secp256k1_pedersen_commitment ring_commitments[11];

  // MLSAG ring signature proving ownership of ONE input
  secp256k1_mlsag_sig mlsag;

  // Aggregated range proof for all commitments
  secp256k1_bulletproofs_proof bp_proof;

  // Actual payment (encrypted)
  uint64_t amount;
  uint8_t blinding_factor[32];
  uint8_t recipient_pubkey[32];
} __attribute__((packed));
```

### 11.3 Verification Process

```c
bool ringct_verify_payment(struct ringct_payment *payment) {
  // Step 1: Verify MLSAG ring signature
  secp256k1_pubkey *pubkeys[11];
  for (int i = 0; i < 11; i++) {
    pubkeys[i] = &payment->ring_commitments[i].pubkey;
  }

  if (!secp256k1_mlsag_verify(
        secp_ctx,
        &payment->mlsag,
        pubkeys,
        11,
        &payment->mlsag.ring_sig)) {
    return false;  // Invalid ring signature
  }

  // Step 2: Verify aggregated range proof
  if (!secp256k1_bulletproofs_rangeproof_verify(
        secp_ctx,
        &payment->bp_proof,
        payment->ring_commitments,
        11,
        NULL,
        0,
        64)) {  // bit_range
    return false;  // Invalid range proof
  }

  // Step 3: Verify ring commitment sum
  secp256k1_pedersen_commitment sum;
  secp256k1_pedersen_commitment_sum(&sum, payment->ring_commitments, 11);

  if (!secp256k1_pedersen_commitment_verify_positive(&sum)) {
    return false;  // Sum is negative
  }

  return true;
}
```

### 11.4 Performance Impact

| Metric | Current | Fin-340 | Change |
|--------|---------|---------|--------|
| Proof Size | 733 bytes | 1,500 bytes | +104% |
| Verification Time | 5ms (single) | 7ms (single) | +40% |
| Verification Time (batch) | 0.5ms (64) | 0.7ms (64) | +40% |
| Anonymity Set | 1,200 | 1,331 | +11% |
| CPU Usage | +45s/payment | +52s/payment | +15% |

### 11.5 Implementation Timeline

- **Q1 2025**: Research ring signature variants
- **Q2 2025**: Prototype MLSAG integration
- **Q3 2025**: Security audit
- **Q4 2025**: Testnet deployment
- **Q1 2026**: Mainnet rollout (Fin-340)

---

## Proposal Fin-N23: eBPF Flow Control

### 11.6 Kernel-Bypass Rate Limiting

**Goal**: Eliminate head-of-line blocking and reduce latency using eBPF.

**Current System**:
```
- Userspace token bucket
- Latency: 1.0 s per cell
- Per-channel windows only
- Head-of-line blocking: YES
```

**Fin-N23 System**:
```
- eBPF token bucket (in-kernel)
- Latency: 0.3 s per cell
- Per-stream windows
- Head-of-line blocking: NO
```

### 11.7 eBPF Program

```c
// In bpf/kern/finallica_n23_kern.c
SEC("xdp")
int xdp_n23_flow_control(struct xdp_md *ctx) {
  void *data = (void *)(long)ctx->data;
  void *data_end = (void *)(long)ctx->data_end;
  struct finallica_cell *cell = data;

  // Parse cell
  if ((void *)(cell + 1) > data_end) {
    return XDP_PASS;  // Not a full cell
  }

  // Lookup payment flow state in eBPF map
  struct payment_flow_key key = {
    .channel_id = cell->channel_id,
    .stream_id = cell->stream_id
  };

  struct payment_flow_val *val =
    bpf_map_lookup_elem(&payment_flows, &key);

  if (!val) {
    // New flow: initialize with initial window
    struct payment_flow_val new_val = {
      .window = 100,  // cells
      .last_ack = bpf_ktime_get_ns(),
      .rate_limit = 1000  // cells/sec
    };
    bpf_map_update_elem(&payment_flows, &key, &new_val, BPF_ANY);
    return XDP_PASS;
  }

  // Token bucket rate limiting
  uint64_t now = bpf_ktime_get_ns();
  uint64_t elapsed = now - val->last_ack;
  val->window += (elapsed / 1000000) * val->rate_limit;  // 1ms granularity
  val->window = min(val->window, 1000);  // Max burst

  if (val->window < 1) {
    // Drop and send NACK to upstream
    bpf_xdp_adjust_tail(ctx, -1024);  // Drop cell
    send_nack(cell->channel_id, cell->stream_id);
    return XDP_DROP;
  }

  val->window--;
  return XDP_PASS;
}
```

### 11.8 Performance Impact

| Metric | Current | Fin-N23 | Change |
|--------|---------|---------|--------|
| Rate Limit Latency | 1.0 s | 0.3 s | -70% |
| Throughput | 6,000 TPS | 8,500 TPS | +42% |
| Head-of-Line Blocking | YES | NO |  Eliminated |
| Granularity | Per-channel | Per-stream |  Improved |
| CPU Usage | 98% | 85% | -13% |

### 11.9 Implementation Timeline

- **Q2 2025**: eBPF prototype
- **Q3 2025**: Kernel module development
- **Q4 2025**: Testnet deployment
- **Q2 2026**: Mainnet rollout (Fin-N23)

---

## Proposal Fin-PQ: Post-Quantum STARK Proofs

### 11.10 Quantum-Resistant State Proofs

**Goal**: Replace BLS signatures with STARK proofs for quantum resistance.

**Current Vulnerability**:
```
BLS12-381: Vulnerable to quantum computers
- Shor's algorithm breaks discrete log
- Estimated quantum computer: 2028-2032
- Impact: 100% stake compromise
```

**Fin-PQ Solution**:
```
STARK (Scalable Transparent Argument of Knowledge)
- Quantum-resistant under conservative assumptions
- Proof size: 192 KB (vs 8 KB BLS aggregate)
- Verification: 45ms (vs 1ms BLS)
- Security: 128-bit post-quantum
```

### 11.11 STARK Proof Generation

```python
# In src/finallica/consensus/stark/settle.py
def prove_state_transition(
  prev_state_root: bytes32,
  transactions: List[Transaction],
  new_state_root: bytes32,
  validator_set: List[BlsPubkey]
) -> STARKProof:

  # Arithmetic circuit: verify 10,000 txs in parallel
  # Field: 256-bit prime field (same as Cairo)
  # Trace: 2^16 rows, 64 columns

  # Constraints:
  # 1. Payment signatures verify (switch to Crystals-Dilithium)
  # 2. Channel commitments balanced:  inputs =  outputs
  # 3. No HTLC expired unclaimed
  # 4. Validator stake unchanged except rewards/slashes

  # Proof generation: 12 seconds on 64-core AWS c6i.32xlarge
  # Proof size: 192 KB (vs 8 KB BLS aggregate)
  # Verification: 45 ms on single core
  # Quantum security: Provable under RAM model

  return stark_prove(
    program=state_transition_circuit,
    public_inputs=[prev_state_root, new_state_root],
    private_inputs=transactions,
    security_bits=128
  )
```

### 11.12 Hybrid Migration Path

```c
struct hybrid_signature {
  // BLS signature (classical)
  bls_signature bls_sig;

  // STARK proof (post-quantum)
  uint8_t stark_proof[192000];  // 192 KB
  uint8_t stark_pubkey[32];     // Prover identifier
};

// Verification: accept either
bool verify_hybrid(struct hybrid_signature *hybrid) {
  // Try BLS first (fast)
  if (bls_verify(&hybrid->bls_sig, ...)) {
    return true;
  }

  // Fall back to STARK (slow but quantum-safe)
  if (stark_verify(hybrid->stark_proof, ...)) {
    return true;
  }

  return false;
}
```

### 11.13 Performance Impact

| Metric | BLS | STARK | Change |
|--------|-----|-------|--------|
| Proof Size | 8 KB | 192 KB | +2400% |
| Verification Time | 1ms | 45ms | +4400% |
| Proof Generation | 10ms | 12,000ms | +120000% |
| Quantum Security |  |  | N/A |
| Bandwidth (per epoch) | 1 MB | 24 MB | +2400% |

### 11.14 Implementation Timeline

- **Q3 2025**: STARK circuit design
- **Q4 2025**: Proof system integration
- **Q1 2026**: Hybrid BLS+STARK deployment
- **Q2 2026**: STARK-only testnet
- **Q4 2026**: Mainnet rollout (Fin-PQ)

---

## Proposal Fin-Sharding: Dynamic Sharding

### 11.15 Unlimited Scalability via Shard Splitting

**Goal**: Enable unlimited TPS by dynamically splitting shards at high load.

**Current Limit**:
```
- 127 fixed shards
- 10,000 TPS per shard limit
- Total capacity: ~1.27M TPS (theoretical)
- Actual: ~350K TPS (observed)
```

**Fin-Sharding Solution**:
```
- Dynamic shard splitting at 8,000 TPS threshold
- Verifiable random shuffle of stake
- Automatic merge at low load
- Theoretical capacity: UNLIMITED
```

### 11.16 Shard Splitting Algorithm

```c
// Triggered when shard TPS > 8,000 for 10 consecutive epochs
bool should_split_shard(shard_id_t shard) {
  struct shard_stats *stats = get_shard_stats(shard);

  if (stats->avg_tps < 8000) {
    return false;
  }

  if (stats->high_load_epochs < 10) {
    return false;
  }

  return true;
}

// Split shard into two
struct shard_split_result split_shard(shard_id_t shard) {
  // Step 1: Verifiable shuffle of stake
  struct vr_assignment *assignments = verifiable_shuffle(
    shard->vrs,
    shard->vr_count,
    shard->random_beacon  // DRB from notaries
  );

  // Step 2: Partition into two new shards
  shard_id_t shard_a = shard * 2;      // Even
  shard_id_t shard_b = shard * 2 + 1;  // Odd

  for (int i = 0; i < shard->vr_count; i++) {
    if (i % 2 == 0) {
      assignments[i].new_shard = shard_a;
    } else {
      assignments[i].new_shard = shard_b;
    }
  }

  // Step 3: Sign new shard assignments
  struct shard_split_result result = {
    .shard_a = shard_a,
    .shard_b = shard_b,
    .assignment_sig = notaries_sign(assignments)
  };

  // Step 4: Broadcast to network
  broadcast_shard_split(&result);

  return result;
}
```

### 11.17 Performance Impact

| Metric | Current | Fin-Sharding | Change |
|--------|---------|--------------|--------|
| Max TPS per Shard | 10,000 | 10,000 | Same |
| Total Shards | 127 | Unlimited |  |
| Max Network TPS | 1.27M | Unlimited |  |
| Shard Split Time | N/A | 30 min | New |
| Shard Merge Time | N/A | 60 min | New |

### 11.18 Implementation Timeline

- **Q4 2025**: Verifiable shuffle design
- **Q1 2026**: Shard split/merge protocols
- **Q2 2026**: Testnet deployment (4 shards  8)
- **Q4 2026**: Mainnet rollout (Fin-Sharding)

---

## v5.0 Target Specifications

### Combined Impact

| Metric | v4.2 (Current) | v5.0 (Proposed) | Improvement |
|--------|----------------|-----------------|-------------|
| **Privacy** | | | |
| Anonymity Set | 1,200 | 1,331 | +11% |
| Amount Hiding | Pedersen | RingCT |  Stronger |
| **Performance** | | | |
| TPS per Shard | 10,000 | 14,000 | +40% |
| Latency | 580ms | 200ms | -65% |
| Throughput | 350K | 500K+ | +43% |
| **Security** | | | |
| Quantum Resistant |  |  | Critical |
| Slashable | 100% | 100% | Same |
| **Scalability** | | | |
| Max Shards | 127 | Unlimited |  |
| Max TPS | 1.27M | Unlimited |  |

---

## Key Takeaways

1. **Fin-340**: RingCT adds +25% privacy (1,331 anonymity set) at +15% CPU cost
2. **Fin-N23**: eBPF reduces latency by 65% (1.0s  0.3s) and eliminates HoL blocking
3. **Fin-PQ**: STARK proofs provide quantum resistance at 24 bandwidth cost
4. **Fin-Sharding**: Dynamic splitting enables unlimited TPS scalability
5. **v5.0 Target**: All four proposals deployed by 2026

---

*Next: [CONSTANTS_REFERENCE.md](./CONSTANTS_REFERENCE.md) - All Hardcoded Values*
</file>

<file path="docs/finallica/SECURITY_ANALYSIS.md">
# Finallica Security Analysis

This document describes the attack surface, vulnerabilities, and defensive mechanisms of the Finallica network.

---

## Attack Surface Analysis

### 9.1 Timing Correlation Attacks

```mermaid
graph TB
    subgraph "Timing Correlation Attack"
        ADV["Global Adversary<br/>NSA/FVEY<br/>AS-level taps<br/>FinSpy at IXPs"]

        subgraph "Side A (Entry)"
            A_ENTRY["Observe FP  Guard<br/>Cell timing: burst of 3 cells @ t=0ms<br/>Payment amount: $100 quantized to $0.01  10,000 cells"]
        end

        subgraph "Side B (Exit)"
            B_EXIT["Observe Exit  Bank<br/>SWIFT MT103 @ t=150ms<br/>Amount: $99.69<br/>Unique payment ref: SHA256(preimage)"]
        end

        ADV -->|Correlate timing + amount| A_ENTRY
        ADV -->|Correlate timing + amount| B_EXIT
        A_ENTRY -->|Latency diff: =150ms  20ms| B_EXIT
        ADV -->|Success probability: 12% per payment<br/>Anonymity set reduces to 1,200| B_EXIT
    end
```

### Attack Probability Calculation

```
P[deanonymize] = (t / N)^(h-1) + 

where:
  t = timing resolution (100ms)
  N = network latency variance (800ms)
  h = hops (3)
   = statistical leakage from padding (0.08)

P = (100 / 800)^2 + 0.08 = 0.0156 + 0.08 = 0.0956  9.6%

With advanced packet sizing analysis: P  12%
```

### Defense: Payment Padding

```c
// Constant-rate padding: 1 cell/sec
void inject_padding_cells(struct channel *chan) {
  uint64_t now = get_time_sec();

  if (now - chan->last_padding_time >= 1) {
    struct finallica_cell pad_cell = {
      .channel_id = chan->id,
      .command = PADDING,
      .payload_len = 0,
      .nonce = {0},
    };

    // Send dummy cell with zero-value HTLC
    send_cell(chan, &pad_cell);
    chan->last_padding_time = now;
  }
}

// Burst padding: Poisson-distributed
void inject_burst_padding(struct channel *chan) {
  double lambda = 5.0;  // 5 cells/sec avg

  // Generate Poisson-distributed count
  unsigned int count = generate_poisson(lambda);

  for (unsigned int i = 0; i < count; i++) {
    inject_padding_cells(chan);
  }
}
```

---

## Guard Discovery + Stake Grinding

### 9.2 Compromising Entry Guards

```mermaid
graph TB
    subgraph "Guard Discovery + Stake Grinding"
        MAL_GUARD["Malicious Guard VR<br/>Run by adversary<br/>Stake: 15M BLF<br/>Probability: 15M / 4.85B = 0.31%<br/>Expected guards to corrupt: 7.4 VRs"]
        USER["User's FP<br/>Persistent guard: VR-0-015<br/>Prob(guard is malicious): 0.31%"]

        MAL_GUARD -->|Logs IP + payment_hash| ADV
        USER -->|Pays through malicious guard| MAL_GUARD
        ADV -->|Knows payer IP after 1 payment| MAL_GUARD

        subgraph "Defense: Guard Rotation"
            ROTATE["Guard rotation every 90 days<br/>If guard fails: immediate rotate<br/>After 30 days: forced rotate<br/>Probability attack succeeds: 1 - (1-0.0031)^3 = 0.9%"]
        end
    end
```

### Attack Cost Analysis

```
To deanonymize 1 payer:
  Guard discovery probability = stake_fraction_guard

  Average guard stake = 2.01M BLF
  Total shard stake = 4.82B BLF
  P(guard) = 2.01M / 4.82B = 0.000417

  Over 90 days: 1 - (1 - 0.000417)^720 = 26.1% chance

  Cost to operate 2 guards for 90 days:
    Stake: 2  2.01M BLF  $4.50 = $18.09M USD
    Infra: $50K/month  3 months = $150K
    Total: $18.24M
```

### Defense: Guard Selection Algorithm

```c
// Weighted guard selection reduces grinding effectiveness
struct entry_guard *select_guard() {
  // Exclude guards owned by same entity (family flag)
  smartlist_t *candidates = get_guards_without_conflicts(my_guards);

  // Bias toward higher-stake guards (harder to corrupt)
  double total_weight = 0;
  SMARTLIST_FOREACH(candidates, entry_guard_t *, guard) {
    guard->weight = pow(guard->stake, 0.7) * guard->uptime_factor;
    total_weight += guard->weight;
  }

  // Random weighted selection
  double rand = crypto_rand_double() * total_weight;
  SMARTLIST_FOREACH_BEGIN(candidates, entry_guard_t *, guard) {
    rand -= guard->weight;
    if (rand <= 0) return guard;
  SMARTLIST_FOREACH_END(guard);

  return NULL;
}
```

---

## Settlement Executor Compromise

### 9.3 Malicious Exit Nodes

```mermaid
graph TB
    subgraph "Settlement Executor Compromise"
        MAL_EXIT["Malicious Exit SE<br/>Runs settlement API<br/>Refuses to settle unless bribe: 50%<br/>Probability: 200 exits, corrupt 20 = 10%"]
        PAYMENT["Payment: $100<br/>Exit fee: $0.25<br/>Bribe demand: extra $50"]

        USER -->|Route through malicious exit| MAL_EXIT
        MAL_EXIT -->|Censor settlement| ADV
        MAL_EXIT -->|Extort payer| USER

        subgraph "Defense: Redundant Settlement"
            REDUNDANT["3 exit redundancy<br/>Payment splits: $33.33  3<br/>Require 2-of-3 settlement<br/>Prob(all 3 exits malicious): 0.1^3 = 0.001 = 0.1%<br/>Prob(2 malicious): 3.7%"]
        end
    end
```

### Attack: Exit Censorship

```c
// Malicious exit refuses to settle
bool malicious_settle_filter(struct htlc_entry *htlc) {
  // Check if beneficiary is on blacklist
  if (is_blacklisted(htlc->beneficiary_pubkey)) {
    return false;  // Refuse to settle
  }

  // Check if bribe paid
  if (htlc->bribe_amount < EXPECTED_BRIBE) {
    return false;  // Demand bribe
  }

  return true;
}
```

### Defense: Redundant Settlement

```c
// Split payment across 3 exits
struct split_payment {
  uint64_t total_amount;
  uint64_t split_amount;  // total / 3
  bls_pubkey_t exits[3];
  uint8_t payment_hashes[3][32];
};

// Require 2-of-3 settlements to release funds
bool verify_redundant_settlement(struct split_payment *split) {
  int settled_count = 0;

  for (int i = 0; i < 3; i++) {
    if (verify_settlement_signature(&split->exits[i], split->payment_hashes[i])) {
      settled_count++;
    }
  }

  return settled_count >= 2;  // 2-of-3 threshold
}
```

---

## Sybil Attacks

### 9.4 Fake Identity Creation

```
Attack: Adversary creates multiple fake VRs to increase influence

  Minimum stake per VR: 500K BLF ($2.25M USD)
  Cost to create 10 fake VRs: 10  $2.25M = $22.5M USD

Defense: Stake grinding resistance
  - Guards selected by stake^0.7 (reduces benefit of splitting)
  - Family flags prevent same operator from controlling multiple guards
  - Slash 100% for Sybil detection
```

### Sybil Detection Algorithm

```c
// Detect multiple VRs operated by same entity
bool detect_sybil_attack(vr_info_t *vr1, vr_info_t *vr2) {
  // Check for overlapping IP ranges
  if (ip_in_same_subnet(vr1->ip, vr2->ip, /24)) {
    return true;
  }

  // Check for identical BLS keys
  if (memcmp(vr1->bls_pubkey, vr2->bls_pubkey, 48) == 0) {
    return true;
  }

  // Check for temporal correlation (uptime patterns)
  if (uptime_correlation(vr1, vr2) > 0.95) {
    return true;
  }

  // Check for payment routing bias (prefer each other)
  if (routing_bias(vr1, vr2) > 0.3) {
    return true;
  }

  return false;
}
```

---

## Eclipse Attacks

### 9.5 Isolating a Target

```
Attack: Adversary eclipses a VR by controlling all its peers

  Target: VR-0-341 (Stake: 2.8M BLF)
  Adversary controls: 2,400 peers
  Cost: 2,400  500K BLF = 1.2B BLF ($5.4B USD) - infeasible

Defense: Peer diversity requirements
  - Minimum unique peers: 100
  - Max from same /16 subnet: 10
  - Periodic random peer sampling
```

---

## DDoS Mitigation

### 9.6 Connection Rate Limiting

```c
struct dos_client_stats {
  uint32_t conncount;           // Active connections
  uint32_t creation_count;      // CREATE cells in 1s window
  time_t   last_creation_time;
  token_bucket_t rate_limit;    // 3 cells/sec burst, 0.1 cell/sec sustained
};

// Token bucket filter per client IP
bool check_rate_limit(struct in_addr *client_ip) {
  struct dos_client_stats *stats = get_or_create_stats(client_ip);

  // Refill tokens
  uint64_t elapsed = now() - stats->last_creation_time;
  stats->rate_limit.tokens += elapsed * 0.1;
  if (stats->rate_limit.tokens > 3.0) {
    stats->rate_limit.tokens = 3.0;
  }

  // Check if allowed
  if (stats->rate_limit.tokens < 1.0) {
    return false;  // Rate limited
  }

  stats->rate_limit.tokens -= 1.0;
  return true;
}
```

---

## Anonymity Set Analysis

### 9.7 Effective Anonymity Set Size

```
|AS| = (N_shards  N_vrs_per_shard) / (c  f)

where:
  N_shards = 127
  N_vrs_per_shard = 2,400 (avg)
  c = concurrency factor = 8 (payments per second per VR)
  f = fee clustering factor = 10 (pools of similar fees)

|AS| = (127  2400) / (8  10) = 304,800 / 80 = 3,810

With padding + amount quantization:
  Effective |AS|  1,200 (12% deanonymization probability)
```

---

## Security Summary

| Attack Vector | Success Probability | Defense | Cost to Attack |
|---------------|---------------------|---------|----------------|
| Timing Correlation | 12% | Padding + quantization | AS-level tap (~$1M) |
| Guard Discovery | 26% (90 days) | Rotation + family flags | $18M (90 days) |
| Exit Compromise | 10% | 2-of-3 redundancy | Stake 200 exits |
| Sybil Attack | Low | Stake^0.7 weighting | $22.5M per 10 VRs |
| Eclipse Attack | Very Low | Peer diversity | $5.4B (infeasible) |
| DDoS | Low | Token bucket | Minimal |

---

## Key Takeaways

1. **Timing Attacks**: 12% success probability, mitigated by padding
2. **Guard Discovery**: 0.31% per guard, 90-day rotation limits exposure
3. **Exit Compromise**: 2-of-3 redundancy reduces success to 0.1%
4. **Anonymity Set**: ~1,200 users after defenses
5. **Sybil Resistance**: Stake-weighted selection + family flags

---

*Next: [OPERATIONAL_METRICS.md](./OPERATIONAL_METRICS.md) - Live Production Dashboards*
</file>

<file path="docs/finallica/TOR_FINALLIKA_MAPPING.md">
# Tor  Finallica Mapping Reference

This document provides a complete analogy mapping between Tor's onion router architecture and Finallica's financial privacy network.

---

## Component-Level Mapping

| **Tor Concept** | **Finallica Analogue** | **Key Similarities** | **Key Differences** |
|----------------|------------------------|---------------------|---------------------|
| **Onion Router (OR)** | **Validator-Router (VR)** |  Relay encrypted cells<br/> 3-hop paths<br/> Persistent mesh connections |  VRs stake BLF tokens<br/> VRs earn fees<br/> Economic incentives |
| **Onion Proxy (OP)** | **Finallica Proxy (FP)** |  Local client software<br/> Pathfinding engine<br/> Manages circuits/channels |  FP manages payment streams<br/> HTLC balance tracking<br/> Liquidity management |
| **Directory Authority (9)** | **Consensus Notary (8)** |  Trusted infrastructure<br/> Sign network state<br/> Distributed trust |  Notaries sign state roots<br/> HotStuff BFT consensus<br/> 10-sec finality |
| **Guard Node** | **Guard VR (Entry)** |  First hop, persistent<br/> Anti-profiling<br/> High-capacity selection |  90-day persistence<br/> Stake-weighted selection<br/> Entry only (no exit) |
| **Middle Node** | **Middle VR** |  Pure forwarding<br/> No external identity<br/> 2nd hop in path |  Identical role<br/> Same cryptography |
| **Exit Node** | **Settlement Executor (SE)** |  Bridge to external networks<br/> See plaintext metadata<br/> Policy-based routing |  SE connects to fiat rails<br/> Economic settlement<br/> 2-of-3 redundancy |
| **Circuit** | **Payment Channel** |  3-hop encrypted path<br/> Timeout-based expiry<br/> Tear-down on close |  Channels have HTLC balances<br/> 6-hour lifetime<br/> Homomorphic commitments |
| **Stream** | **Payment Stream** |  Multiplexed within circuit/channel<br/> Identified by stream_id<br/> Independent lifecycle |  Payments have amounts<br/> HTLC lock/unlock<br/> Settlement finality |
| **Cell (514 bytes)** | **Cell (1,024 bytes)** |  Fixed-size network packets<br/> Command-based routing<br/> Relay encrypted payload |  2 size for commitments<br/> BLS signatures (96 bytes)<br/> Pedersen commitments |
| **CREATE/CREATED** | **OPEN/OPENED** |  Circuit/channel initiation<br/> Diffie-Hellman handshake<br/> Key derivation |  Noise_XX (vs TAP/NTor)<br/> BLS stake binding<br/> Faster (230s vs 1.2ms) |
| **RELAY_DATA** | **PAY** |  Data-bearing cells<br/> End-to-end encrypted<br/> Stream multiplexing |  Payment amounts<br/> Pedersen commitments<br/> HTLC locking |
| **RELAY_SENDME** | **Channel Window** |  Flow control window<br/> End-to-end acknowledgments<br/> Prevent overrun |  Capacity-based ($25K)<br/> HTLC slot limits<br/> Liquidity rebalancing |
| **Padding** | **Payment Padding** |  Constant-rate traffic<br/> Obfuscates timing<br/> Dummy cells |  Monetary cost ($0.01)<br/> Dust payments<br/> 1 cell/sec minimum |
| **Consensus (none)** | **HotStuff BFT** |  N/A (Tor has no state) |  200ms finality<br/> State root commitment<br/> Global ledger |
| **Free to use** | **0.3% avg fee** |  N/A |  Economic incentives<br/> Stake required<br/> Fee revenue |

---

## Cryptographic Mapping

| **Tor Cryptography** | **Finallica Analogue** | **Purpose** | **Performance** |
|---------------------|------------------------|------------|-----------------|
| **RSA-1024** | **BLS12-381** | Identity signatures | BLS: 2ms sign, 0.15ms batch verify |
| **NTor (X25519)** | **Noise_XX (X25519)** | Handshake ECDH | Same curve, different pattern |
| **AES-128-CTR** | **ChaCha20-Poly1305** | Symmetric encryption | ChaCha20: 1.2s vs AES: 2s |
| **SHA1 (digest)** | **BLAKE2s** | Hash function | BLAKE2s: 25s vs SHA1: 10s |
| **SHA256** | **SHA256** (same) | Payment hashes | Identical |
| **Ed25519** | **Ed25519** (same) | Rekey signatures | Identical |
| **N/A** | **Pedersen Commitment** | Amount hiding | Commit: 45s |
| **N/A** | **Bulletproofs+** | Range proofs | Prove: 780s, Verify: 5ms (batch: 0.5ms) |

---

## Protocol Mapping

### Handshake Comparison

**Tor TAP (Theorem 1)**:
```
Client  Server: RSA(PK_or, g^x)
Server  Client: g^y, K = SHA1(g^xy)
```

**Tor NTor**:
```
Client  Server: g^x
Server  Client: g^y, g^xy
Client  Server: MAC(K, g^xy)
```

**Finallica Noise_XX**:
```
Client  Server: e (ephemeral X25519)
Server  Client: e, ee, s, es (BLS stake binding)
Client  Server: s, se, psk (client BLS auth)
```

### Cell Command Mapping

| Tor Command | Value | Finallica Command | Value | Purpose |
|-------------|-------|-------------------|-------|---------|
| PADDING | 0x00 | PADDING | 0x00 | Dummy cell |
| CREATE | 0x01 | OPEN | 0x01 | Initiate path |
| CREATED | 0x02 | OPENED | 0x02 | Path acknowledgment |
| RELAY | 0x03 | PAY | 0x02 | Data/payment |
| DESTROY | 0x04 | DESTROY | 0x06 | Teardown |
| RELAY_BEGIN | 0x01 | N/A | - | TCP connect (not used) |
| RELAY_DATA | 0x02 | FORWARD | 0x01 | Forward payment |
| RELAY_END | 0x03 | SETTLE | 0x03 | Settlement |
| RELAY_EXTEND | 0x06 | EXTEND | 0x04 | Extend path |
| N/A | - | REKEY | 0x05 | Rotate keys |

---

## Performance Comparison

| Metric | Tor | Finallica | Ratio |
|--------|-----|-----------|-------|
| **Network Size** | 7,000 relays | 12,000 VRs | 1.7 |
| **Circuit/Channel Build** | 200-500ms | 127-340ms | 0.63 |
| **Cell Processing** | 2ms/hop | 0.8s/hop | 0.0004 |
| **Total Throughput** | 350 Gbps | 500 Gbps | 1.4 |
| **Anonymity Set** | ~3,000 | ~1,200 | 0.4 |
| **Finality** | None (best-effort) | 200ms | N/A |
| **Cost to Use** | Free | 0.3% fee | N/A |
| **Staking Required** | No (volunteer) | Yes ($2.25M min) | N/A |
| **Settlement Time** | Instant (TCP) | 1-3 days (SWIFT) | N/A |

---

## Economic Model Comparison

| Aspect | Tor | Finallica |
|--------|-----|-----------|
| **Funding** | Donations, grants | Transaction fees |
| **Operator Incentives** | Altruism | Fee revenue |
| **Entry Cost** | $0 | $2.25M (500K BLF) |
| **Slashable** | No | Yes (up to 100%) |
| **Revenue per VR** | $0 | $2,697/epoch (avg) |
| **APY** | N/A | ~12% (guard) |
| **Inflation** | None | 4% annually |

---

## Anonymity Model Comparison

| Property | Tor | Finallica |
|----------|-----|-----------|
| **Adversary Model** | Global passive | Global passive + economic |
| **Anonymity Definition** | Probable innocence | Untraceable indistinguishability |
| |AS| Size** | ~3,000 | ~1,200 |
| **Timing Resistance** | Padding (weak) | Padding + quantization |
| **Amount Hiding** | N/A | Pedersen commitments |
| **Exit Compromise** | See plaintext | See plaintext + can censor |
| **Guard Discovery** | 1/7000 per guard | 0.31% per guard (stake-weighted) |

---

## Routing Algorithm Comparison

### Tor Path Selection

```
weight = bandwidth_fraction

where:
  bandwidth_fraction = node_bandwidth / total_bandwidth

Guard selection:
  - Persistent for 2-3 months
  - Bandwidth-weighted random
  - Exclude same /16 subnet
```

### Finallica Path Selection

```
weight = stake^0.7  uptime_factor / fee_bps^2

where:
  stake_fraction = node_stake / shard_stake
  uptime_factor = min(uptime_days / 30, 1.0)
  fee_bps = configured_routing_fee

Guard selection:
  - Persistent for 90 days
  - Stake-weighted random
  - Exclude same family (operator)
  - Higher-stake guards preferred
```

---

## Summary Table: Side-by-Side

```

 Tor                   Finallica            Difference          

 7,000 relays          12,000 VRs           1.7 larger         
 Volunteer-run         Stake-required       Economic incentives 
 RSA-1024/Ed25519      BLS12-381/Ed25519    Aggregate sigs      
 AES-128-CTR           ChaCha20-Poly1305    Different cipher    
 514-byte cells        1,024-byte cells     2 size             
 3 hops                3 hops               Same                
 No state              HTLC balances        Financial state     
 No finality           200ms finality       BFT consensus       
 Free                  0.3% fee             Paid service        
 Instant               1-3 days (SWIFT)     Settlement delay    
 ~3,000 anonymity set  ~1,200 anonymity set Smaller set         
 Directory (9)         Notaries (8)         BFT vs voting       

```

---

## Key Insight

Finallica adapts Tor's layered encryption and path diversity architecture to financial value transfer, but adds:

1. **Economic security**: Stake slashing reduces Sybil attacks
2. **Settlement finality**: BFT consensus provides irreversible transactions
3. **Amount privacy**: Pedersen commitments hide payment values
4. **Liquidity management**: Channel windows and rebalancing
5. **Regulatory compliance**: 127 shards for jurisdictional partitioning

The tradeoff: **smaller anonymity set (1,200 vs 3,000)** due to stake-weighted routing and payment timing correlation.

---

*Back to [README.md](./README.md)*
</file>

<file path="frontend/app.js">
// Finallica Documentation System - Main Application
// This file handles all frontend logic including document management,
// AI chat, proposals, voting, and consensus

const CONFIG = {
    API_BASE: 'http://localhost:3000/api',
    WS_BASE: 'ws://localhost:3000/ws',
    CHAIN_ID: 31337, // Finallica testnet chain ID
    MIN_STAKE_PROPOSAL: 1000, // BLF
    VOTING_PERIOD: 7 * 24 * 60 * 60 * 1000, // 7 days in ms
    QUORUM_PCT: 0.67 // 67% needed
};

// State Management
const state = {
    wallet: null,
    account: null,
    stake: 0,
    currentDoc: 'README.md',
    documents: {},
    proposals: {},
    consensus: {},
    chatHistory: [],
    activity: [],
    // AI Configuration
    aiProviders: {},
    aiDefaults: { provider: 'anthropic', model: 'claude-3-5-sonnet-20241022' },
    selectedProvider: null,
    selectedModel: null,
    // Privacy Configuration
    privacy: {
        enabled: false,
        available: false,
        notes: [],
        selectedPool: null,
        pools: []
    }
};

// Utility Functions
const $ = (selector) => document.querySelector(selector);
const $$ = (selector) => document.querySelectorAll(selector);

function formatNumber(num) {
    return new Intl.NumberFormat().format(num);
}

function formatAddress(addr) {
    return `${addr.substring(0, 6)}...${addr.substring(addr.length - 4)}`;
}

function showToast(message, type = 'info') {
    const container = $('#toastContainer');
    const toast = document.createElement('div');
    toast.className = `toast ${type}`;
    toast.innerHTML = `<div class="toast-content">${message}</div>`;
    container.appendChild(toast);
    setTimeout(() => toast.remove(), 5000);
}

// ============================================
// DOCUMENT MANAGEMENT
// ============================================

async function loadDocuments() {
    try {
        const response = await fetch(`${CONFIG.API_BASE}/documents`);
        const data = await response.json();
        state.documents = data.documents;
        renderDocTree();

        // Load initial document
        if (state.documents['README.md']) {
            loadDocument('README.md');
        }
    } catch (error) {
        console.error('Failed to load documents:', error);
        showToast('Failed to load documents', 'error');
    }
}

function renderDocTree() {
    const tree = $('#docTree');
    tree.innerHTML = '';

    const structure = {
        'Overview': ['README.md'],
        'Architecture': ['ARCHITECTURE_OVERVIEW.md', 'NETWORK_TOPOLOGY.md'],
        'Protocol': ['PROTOCOL_SPECIFICATION.md', 'STATE_MACHINES.md'],
        'Performance': ['PERFORMANCE_ANALYSIS.md'],
        'Cryptography': ['CRYPTOGRAPHIC_DETAILS.md'],
        'Liquidity': ['LIQUIDITY_MANAGEMENT.md'],
        'Consensus': ['CONSENSUS_MECHANISM.md'],
        'Security': ['SECURITY_ANALYSIS.md'],
        'Operations': ['OPERATIONAL_METRICS.md'],
        'Reference': ['TOR_FINALLIKA_MAPPING.md', 'RESEARCH_PROPOSALS.md', 'CONSTANTS_REFERENCE.md']
    };

    for (const [section, docs] of Object.entries(structure)) {
        const sectionEl = document.createElement('div');
        sectionEl.className = 'doc-tree-section';
        sectionEl.textContent = section;
        tree.appendChild(sectionEl);

        for (const doc of docs) {
            const link = document.createElement('a');
            link.className = 'doc-tree-item';
            link.textContent = doc.replace('.md', '');
            link.dataset.doc = doc;
            if (doc === state.currentDoc) link.classList.add('active');
            link.addEventListener('click', () => loadDocument(doc));
            tree.appendChild(link);
        }
    }
}

async function loadDocument(docName) {
    try {
        state.currentDoc = docName;
        $('#currentDoc').textContent = docName;

        const response = await fetch(`${CONFIG.API_BASE}/documents/${docName}`);
        const data = await response.json();

        $('#docContent').innerHTML = renderMarkdown(data.content);
        $('#documentViewer').classList.remove('hidden');
        $('#editorPanel').classList.add('hidden');

        // Update active state in tree
        $$('.doc-tree-item').forEach(el => {
            el.classList.toggle('active', el.dataset.doc === docName);
        });

        // Track view
        trackActivity('view', { document: docName });
    } catch (error) {
        console.error('Failed to load document:', error);
        showToast('Failed to load document', 'error');
    }
}

function renderMarkdown(content) {
    // Simple markdown renderer (in production, use marked.js)
    return content
        .replace(/^### (.*$)/gim, '<h3>$1</h3>')
        .replace(/^## (.*$)/gim, '<h2>$1</h2>')
        .replace(/^# (.*$)/gim, '<h1>$1</h1>')
        .replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>')
        .replace(/\*(.*?)\*/g, '<em>$1</em>')
        .replace(/`([^`]+)`/g, '<code>$1</code>')
        .replace(/```([\s\S]*?)```/g, '<pre><code>$1</code></pre>')
        .replace(/\n/g, '<br>');
}

function editDocument() {
    const content = state.documents[state.currentDoc];
    $('#docEditor').value = content;
    $('#editorTitle').textContent = `Edit ${state.currentDoc}`;
    $('#documentViewer').classList.add('hidden');
    $('#editorPanel').classList.remove('hidden');
}

function previewChanges() {
    const content = $('#docEditor').value;
    $('#editPreview').innerHTML = renderMarkdown(content);
    $('#editPreview').classList.remove('hidden');
}

async function saveEdit() {
    const content = $('#docEditor').value;
    const diff = generateDiff(state.documents[state.currentDoc], content);

    // Create as a proposal
    showProposalModal({
        type: 'document_edit',
        document: state.currentDoc,
        diff: diff,
        title: `Edit ${state.currentDoc}`
    });
}

function cancelEdit() {
    $('#documentViewer').classList.remove('hidden');
    $('#editorPanel').classList.add('hidden');
}

function generateDiff(original, modified) {
    // Simple diff generator
    const originalLines = original.split('\n');
    const modifiedLines = modified.split('\n');
    let diff = '';

    let i = 0, j = 0;
    while (i < originalLines.length || j < modifiedLines.length) {
        if (i < originalLines.length && j < modifiedLines.length && originalLines[i] === modifiedLines[j]) {
            i++; j++;
        } else {
            if (j < modifiedLines.length) {
                diff += `+ ${modifiedLines[j]}\n`;
                j++;
            }
            if (i < originalLines.length) {
                diff += `- ${originalLines[i]}\n`;
                i++;
            }
        }
    }

    return diff;
}

// ============================================
// PROPOSALS & VOTING
// ============================================

async function loadProposals() {
    try {
        const response = await fetch(`${CONFIG.API_BASE}/proposals`);
        const data = await response.json();
        state.proposals = data.proposals;
        renderProposals();
        updatePendingCount();
    } catch (error) {
        console.error('Failed to load proposals:', error);
    }
}

function renderProposals() {
    // Summary
    const summary = $('#proposalsSummary');
    const pending = Object.values(state.proposals).filter(p => p.status === 'pending').length;
    const approved = Object.values(state.proposals).filter(p => p.status === 'approved').length;
    const rejected = Object.values(state.proposals).filter(p => p.status === 'rejected').length;

    summary.innerHTML = `
        <div class="proposal-card">
            <h4>Pending</h4>
            <div class="stat">${pending}</div>
        </div>
        <div class="proposal-card">
            <h4>Approved</h4>
            <div class="stat">${approved}</div>
        </div>
        <div class="proposal-card">
            <h4>Rejected</h4>
            <div class="stat">${rejected}</div>
        </div>
    `;

    // Detail list
    const detail = $('#proposalsDetail');
    detail.innerHTML = '';

    const sortedProposals = Object.values(state.proposals)
        .sort((a, b) => b.createdAt - a.createdAt);

    for (const proposal of sortedProposals) {
        const forPct = (proposal.votesFor / proposal.totalStake) * 100;
        const againstPct = (proposal.votesAgainst / proposal.totalStake) * 100;

        const item = document.createElement('div');
        item.className = `proposal-item ${proposal.status}`;
        item.innerHTML = `
            <div class="proposal-header">
                <span class="proposal-title">${proposal.title}</span>
                <span class="proposal-id">#${proposal.id.substring(0, 8)}</span>
            </div>
            <div class="proposal-meta">
                <span>Type: ${proposal.type}</span>
                <span>By: ${formatAddress(proposal.proposer)}</span>
                <span>${new Date(proposal.createdAt).toLocaleDateString()}</span>
            </div>
            <div class="proposal-votes">
                <div class="vote-bar">
                    <div class="vote-bar-fill for" style="width: ${forPct}%"></div>
                </div>
                <div class="vote-bar">
                    <div class="vote-bar-fill against" style="width: ${againstPct}%"></div>
                </div>
            </div>
            <div style="font-size: 0.75rem; margin-top: 0.5rem; color: var(--color-text-muted)">
                ${formatNumber(proposal.votesFor)} for  ${formatNumber(proposal.votesAgainst)} against  ${formatNumber(proposal.totalStake - proposal.votesFor - proposal.votesAgainst)} abstain
            </div>
            <button class="btn btn-secondary" style="margin-top: 0.5rem; font-size: 0.75rem;" onclick="openVotingModal('${proposal.id}')">
                Vote
            </button>
        `;
        detail.appendChild(item);
    }
}

function updatePendingCount() {
    const pending = Object.values(state.proposals).filter(p => p.status === 'pending').length;
    $('#pendingCount').textContent = pending;
    $('#pendingCount').classList.toggle('hidden', pending === 0);
}

function showProposalModal(preFill = {}) {
    $('#proposalModal').classList.remove('hidden');

    // Populate document options
    const docSelect = $('#proposalDoc');
    docSelect.innerHTML = '';
    for (const doc of Object.keys(state.documents)) {
        const option = document.createElement('option');
        option.value = doc;
        option.textContent = doc;
        docSelect.appendChild(option);
    }

    // Pre-fill if provided
    if (preFill.type) $('#proposalType').value = preFill.type;
    if (preFill.document) $('#proposalDoc').value = preFill.document;
    if (preFill.diff) $('#proposalDiff').value = preFill.diff;
    if (preFill.title) $('#proposalTitle').value = preFill.title;
}

function closeModal() {
    $('#proposalModal').classList.add('hidden');
    $('#proposalForm').reset();
}

async function submitProposal() {
    if (!state.account) {
        showToast('Please connect wallet first', 'error');
        return;
    }

    const proposal = {
        id: generateId(),
        type: $('#proposalType').value,
        title: $('#proposalTitle').value,
        document: $('#proposalDoc').value,
        diff: $('#proposalDiff').value,
        rationale: $('#proposalRationale').value,
        stake: parseInt($('#proposalStake').value),
        proposer: state.account,
        createdAt: Date.now(),
        status: 'pending',
        votesFor: 0,
        votesAgainst: 0,
        votesAbstain: 0,
        totalStake: 0,
        voters: {}
    };

    try {
        const response = await fetch(`${CONFIG.API_BASE}/proposals`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(proposal)
        });

        if (response.ok) {
            state.proposals[proposal.id] = proposal;
            renderProposals();
            closeModal();
            showToast('Proposal submitted successfully', 'success');
            trackActivity('propose', { proposalId: proposal.id, title: proposal.title });
        }
    } catch (error) {
        console.error('Failed to submit proposal:', error);
        showToast('Failed to submit proposal', 'error');
    }
}

function openVotingModal(proposalId) {
    const proposal = state.proposals[proposalId];
    if (!proposal) return;

    $('#votingProposalDetails').innerHTML = `
        <h4>${proposal.title}</h4>
        <p style="font-size: 0.875rem; color: var(--color-text-muted); margin-top: 0.5rem;">
            ${proposal.rationale || proposal.diff.substring(0, 200)}...
        </p>
        <div style="margin-top: 1rem;">
            <strong>Current Standings:</strong><br>
            For: ${formatNumber(proposal.votesFor)} BLF<br>
            Against: ${formatNumber(proposal.votesAgainst)} BLF<br>
            Abstain: ${formatNumber(proposal.totalStake - proposal.votesFor - proposal.votesAgainst)} BLF
        </div>
    `;

    // Store current proposal for voting
    $('#votingModal').dataset.proposalId = proposalId;
    $('#votingModal').classList.remove('hidden');
}

function closeVotingModal() {
    $('#votingModal').classList.add('hidden');
}

async function vote(direction) {
    if (!state.account) {
        showToast('Please connect wallet first', 'error');
        return;
    }

    const proposalId = $('#votingModal').dataset.proposalId;
    const stakeWeight = parseInt($('#stakeWeight').value) / 100;
    const voteAmount = Math.floor(state.stake * stakeWeight);

    const voteData = {
        proposalId,
        voter: state.account,
        direction, // 'for', 'against', 'abstain'
        stake: voteAmount,
        timestamp: Date.now()
    };

    try {
        const response = await fetch(`${CONFIG.API_BASE}/vote`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify(voteData)
        });

        if (response.ok) {
            const result = await response.json();
            state.proposals[proposalId] = result.proposal;
            renderProposals();
            closeVotingModal();
            showToast(`Vote cast: ${direction}`, 'success');
            trackActivity('vote', { proposalId, direction, amount: voteAmount });
        }
    } catch (error) {
        console.error('Failed to cast vote:', error);
        showToast('Failed to cast vote', 'error');
    }
}

// ============================================
// AI CHAT
// ============================================

async function sendChatMessage() {
    const input = $('#chatInput');
    const message = input.value.trim();

    if (!message) return;

    // Add user message
    addChatMessage('user', message);
    input.value = '';

    // Show typing indicator
    showTyping();

    try {
        const response = await fetch(`${CONFIG.API_BASE}/chat`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                message,
                provider: state.selectedProvider || state.aiDefaults.provider,
                model: state.selectedModel || state.aiDefaults.model,
                context: {
                    currentDoc: state.currentDoc,
                    documents: Object.keys(state.documents),
                    proposals: state.proposals,
                    history: state.chatHistory.slice(-20) // Last 20 messages
                }
            })
        });

        const data = await response.json();
        hideTyping();

        if (data.error && data.fallback) {
            // Using fallback demo mode
            addChatMessage('ai', data.fallback);
            showToast(`AI API Error: ${data.error}. Using demo mode.`, 'warning');
            state.chatHistory.push({ role: 'user', content: message });
            state.chatHistory.push({ role: 'assistant', content: data.fallback });
        } else if (data.error) {
            addChatMessage('system', `Error: ${data.error}`);
            showToast(data.error, 'error');
        } else {
            addChatMessage('ai', data.response);
            state.chatHistory.push({ role: 'user', content: message });
            state.chatHistory.push({ role: 'assistant', content: data.response });

            // Show token usage if available
            if (data.tokensUsed) {
                const tokenInfo = `${data.tokensUsed.input + data.tokensUsed.output} tokens (${data.tokensUsed.input} in, ${data.tokensUsed.out} out)`;
                showToast(tokenInfo, 'info');
            }
        }
    } catch (error) {
        console.error('Chat error:', error);
        hideTyping();
        addChatMessage('system', 'Sorry, I encountered an error. Please try again.');
        showToast('Chat error: ' + error.message, 'error');
    }
}

function addChatMessage(type, content) {
    const messages = $('#chatMessages');
    const msgDiv = document.createElement('div');
    msgDiv.className = `chat-message ${type}`;

    const avatar = type === 'ai' ? '' : type === 'user' ? '' : '';

    msgDiv.innerHTML = `
        <div class="chat-avatar">${avatar}</div>
        <div class="chat-message-content">
            <div class="message-bubble">
                <div class="message-content">${renderMarkdown(content)}</div>
            </div>
            <div class="message-meta">${new Date().toLocaleTimeString()}</div>
        </div>
    `;

    messages.appendChild(msgDiv);
    messages.scrollTop = messages.scrollHeight;
}

function showTyping() {
    const messages = $('#chatMessages');
    const typingDiv = document.createElement('div');
    typingDiv.className = 'chat-message ai typing-indicator';
    typingDiv.id = 'typingIndicator';
    typingDiv.innerHTML = `
        <div class="chat-avatar"></div>
        <div class="message-bubble">
            <div class="message-content"><span class="spinner"></span> Thinking...</div>
        </div>
    `;
    messages.appendChild(typingDiv);
    messages.scrollTop = messages.scrollHeight;
}

function hideTyping() {
    $('#typingIndicator')?.remove();
}

function clearChat() {
    $('#chatMessages').innerHTML = `
        <div class="chat-message system">
            <div class="message-content">
                Chat cleared. Ask about Finallica architecture, protocols, or any topic.
            </div>
        </div>
    `;
    state.chatHistory = [];
}

// ============================================
// CONSENSUS
// ============================================

async function loadConsensus() {
    try {
        const response = await fetch(`${CONFIG.API_BASE}/consensus`);
        const data = await response.json();
        state.consensus = data;
        renderConsensus();
    } catch (error) {
        console.error('Failed to load consensus:', error);
    }
}

function renderConsensus() {
    // Stats
    $('#currentBlock').textContent = formatNumber(state.consensus.blockNumber || 0);
    $('#currentEpoch').textContent = formatNumber(state.consensus.epoch || 0);
    $('#totalVotes').textContent = formatNumber(state.consensus.totalVotes || 0);

    $('#totalStake').textContent = `${formatNumber(state.consensus.totalStake || 0)} BLF`;

    const quorumReached = (state.consensus.totalVotes || 0) >= (state.consensus.quorum || 0);
    $('#quorumStatus').textContent = quorumReached ? 'Reached' : 'Not Reached';
    $('#quorumStatus').style.color = quorumReached ? 'var(--color-success)' : 'var(--color-warning)';

    const approvalRate = state.consensus.totalStake > 0
        ? ((state.consensus.votesFor || 0) / state.consensus.totalStake * 100).toFixed(1)
        : 0;
    $('#approvalRate').textContent = `${approvalRate}%`;

    // List
    const list = $('#consensusList');
    list.innerHTML = '';

    const items = state.consensus.items || [];
    for (const item of items) {
        const itemEl = document.createElement('div');
        itemEl.className = 'consensus-item';
        itemEl.innerHTML = `
            <div style="display: flex; justify-content: space-between; align-items: start; margin-bottom: 0.5rem;">
                <div>
                    <strong>${item.title}</strong>
                    <span class="consensus-status ${item.status}">${item.status}</span>
                </div>
                <span class="proposal-id">#${item.id.substring(0, 8)}</span>
            </div>
            <p style="font-size: 0.875rem; color: var(--color-text-muted);">${item.description}</p>
            <div style="margin-top: 0.5rem; font-size: 0.75rem;">
                Ends: ${new Date(item.deadline).toLocaleString()}
            </div>
        `;
        list.appendChild(itemEl);
    }
}

// ============================================
// WALLET CONNECTION
// ============================================

async function connectWallet() {
    // Check for MetaMask or compatible wallet
    if (typeof window.ethereum !== 'undefined') {
        try {
            const accounts = await window.ethereum.request({ method: 'eth_requestAccounts' });
            const account = accounts[0];

            state.account = account;
            state.wallet = window.ethereum;

            // Get balance (assuming BLF token contract)
            const balance = await getTokenBalance(account);
            state.stake = balance;

            updateWalletUI();
            showToast('Wallet connected', 'success');
            trackActivity('connect', { address: account });

            // Setup listeners
            window.ethereum.on('accountsChanged', handleAccountsChanged);
            window.ethereum.on('chainChanged', handleChainChanged);

        } catch (error) {
            console.error('Wallet connection error:', error);
            showToast('Failed to connect wallet', 'error');
        }
    } else {
        // Demo mode - create mock wallet
        state.account = '0xdemo' + generateId().substring(0, 38);
        state.stake = 1000000; // 1M BLF demo stake

        updateWalletUI();
        showToast('Demo wallet connected', 'info');
    }
}

async function getTokenBalance(account) {
    // In production, call actual BLF token contract
    // For demo, return mock value
    return 1000000; // 1M BLF
}

function updateWalletUI() {
    $('#connectWallet').classList.add('hidden');
    $('#walletInfo').classList.remove('hidden');
    $('.wallet-address').textContent = formatAddress(state.account);
    $('.wallet-balance').textContent = `${formatNumber(state.stake)} BLF`;
}

function handleAccountsChanged(accounts) {
    if (accounts.length === 0) {
        disconnectWallet();
    } else {
        state.account = accounts[0];
        updateWalletUI();
    }
}

function handleChainChanged() {
    window.location.reload();
}

function disconnectWallet() {
    state.account = null;
    state.wallet = null;
    state.stake = 0;

    $('#connectWallet').classList.remove('hidden');
    $('#walletInfo').classList.add('hidden');
    showToast('Wallet disconnected', 'info');
}

// ============================================
// ACTIVITY TRACKING
// ============================================

function trackActivity(type, data) {
    const activity = {
        type,
        data,
        timestamp: Date.now(),
        user: state.account || 'anonymous'
    };

    state.activity.unshift(activity);
    if (state.activity.length > 100) state.activity.pop();

    renderActivity();

    // Send to server
    fetch(`${CONFIG.API_BASE}/activity`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(activity)
    }).catch(console.error);
}

function renderActivity() {
    const feed = $('#activityFeed');
    feed.innerHTML = '';

    const icons = {
        'view': '',
        'edit': '',
        'propose': '',
        'vote': '',
        'connect': '',
        'consensus': '',
        'merge': ''
    };

    for (const activity of state.activity.slice(0, 20)) {
        const item = document.createElement('div');
        item.className = 'activity-item';
        item.innerHTML = `
            <div class="activity-icon">${icons[activity.type] || ''}</div>
            <div class="activity-content">
                <div class="activity-title">${getActivityText(activity)}</div>
                <div class="activity-time">${getTimeAgo(activity.timestamp)}</div>
            </div>
        `;
        feed.appendChild(item);
    }
}

function getActivityText(activity) {
    const user = activity.user ? formatAddress(activity.user) : 'Anonymous';

    switch (activity.type) {
        case 'view':
            return `${user} viewed ${activity.data.document || 'a document'}`;
        case 'propose':
            return `${user} proposed "${activity.data.title}"`;
        case 'vote':
            return `${user} voted ${activity.data.direction} on proposal`;
        case 'connect':
            return `${user} connected wallet`;
        case 'consensus':
            return `Consensus reached on ${activity.data.proposalId}`;
        case 'merge':
            return `Changes merged to ${activity.data.document}`;
        default:
            return `${user} performed ${activity.type}`;
    }
}

function getTimeAgo(timestamp) {
    const seconds = Math.floor((Date.now() - timestamp) / 1000);

    if (seconds < 60) return `${seconds}s ago`;
    if (seconds < 3600) return `${Math.floor(seconds / 60)}m ago`;
    if (seconds < 86400) return `${Math.floor(seconds / 3600)}h ago`;
    return `${Math.floor(seconds / 86400)}d ago`;
}

// ============================================
// WEBSOCKET CONNECTION
// ============================================

function connectWebSocket() {
    const ws = new WebSocket(CONFIG.WS_BASE);

    ws.onopen = () => {
        console.log('WebSocket connected');
    };

    ws.onmessage = (event) => {
        const data = JSON.parse(event.data);
        handleWebSocketMessage(data);
    };

    ws.onerror = (error) => {
        console.error('WebSocket error:', error);
    };

    ws.onclose = () => {
        console.log('WebSocket disconnected, reconnecting...');
        setTimeout(connectWebSocket, 5000);
    };

    state.ws = ws;
}

function handleWebSocketMessage(data) {
    switch (data.type) {
        case 'document_update':
            state.documents[data.doc] = data.content;
            if (state.currentDoc === data.doc) {
                loadDocument(data.doc);
            }
            showToast(`Document updated: ${data.doc}`, 'info');
            break;

        case 'new_proposal':
            state.proposals[data.proposal.id] = data.proposal;
            renderProposals();
            showToast(`New proposal: ${data.proposal.title}`, 'info');
            break;

        case 'vote_cast':
            if (state.proposals[data.proposalId]) {
                state.proposals[data.proposalId] = data.proposal;
                renderProposals();
            }
            break;

        case 'consensus_update':
            state.consensus = data.consensus;
            renderConsensus();
            break;

        case 'proposal_merged':
            const proposal = state.proposals[data.proposalId];
            if (proposal) {
                proposal.status = 'approved';
                renderProposals();
                showToast(`Proposal merged: ${proposal.title}`, 'success');
                trackActivity('merge', { proposalId: data.proposalId, title: proposal.title });
            }
            break;
    }
}

// ============================================
// UTILITY FUNCTIONS
// ============================================

function generateId() {
    return '0x' + Array.from({ length: 40 }, () =>
        Math.floor(Math.random() * 16).toString(16)
    ).join('');
}

// ============================================
// ============================================
// AI MODEL MANAGEMENT
// ============================================

async function loadAIModels() {
    try {
        const response = await fetch(`${CONFIG.API_BASE}/ai/models`);
        const data = await response.json();

        state.aiProviders = data.providers || {};
        state.aiDefaults = data.defaults || { provider: 'anthropic', model: 'claude-3-5-sonnet-20241022' };

        // Set default selections
        state.selectedProvider = state.aiDefaults.provider;
        state.selectedModel = state.aiDefaults.model;

        renderModelSelector();
    } catch (error) {
        console.error('Failed to load AI models:', error);
        // Use demo mode defaults
        renderModelSelector();
    }
}

function renderModelSelector() {
    const container = $('#aiModelSelector');
    if (!container) return;

    const providers = Object.entries(state.aiProviders);
    if (providers.length === 0) {
        container.innerHTML = '<div class="ai-status">Demo Mode (no API keys)</div>';
        return;
    }

    let html = '<div class="ai-selector">';

    // Provider dropdown
    html += '<select id="aiProvider" class="ai-select">';
    for (const [id, config] of providers) {
        const selected = id === state.selectedProvider ? 'selected' : '';
        html += `<option value="${id}" ${selected}>${config.name}</option>`;
    }
    html += '</select>';

    // Model dropdown (will be populated by provider selection)
    html += '<select id="aiModel" class="ai-select">';
    const currentProvider = state.aiProviders[state.selectedProvider];
    if (currentProvider && currentProvider.models) {
        for (const [id, config] of Object.entries(currentProvider.models)) {
            const selected = id === state.selectedModel ? 'selected' : '';
            html += `<option value="${id}" ${selected}>${config.name}</option>`;
        }
    }
    html += '</select>';

    html += '</div>';

    container.innerHTML = html;

    // Add event listeners
    $('#aiProvider')?.addEventListener('change', (e) => {
        state.selectedProvider = e.target.value;
        const provider = state.aiProviders[e.target.value];
        const firstModel = Object.keys(provider.models)[0];
        state.selectedModel = firstModel;
        renderModelSelector();
    });

    $('#aiModel')?.addEventListener('change', (e) => {
        state.selectedModel = e.target.value;
    });
}

// ============================================
// PRIVACY FUNCTIONS
// ============================================

/**
 * Initialize privacy service - check availability
 */
async function loadPrivacyStatus() {
    try {
        const response = await fetch(`${CONFIG.API_BASE}/privacy/status`);
        const data = await response.json();
        state.privacy.available = data.available;
        state.privacy.enabled = data.enabled;

        if (data.available) {
            // Show privacy toggle
            $('#privacyToggleContainer')?.classList.remove('hidden');
            await loadPrivacyPools();
        }
    } catch (error) {
        console.error('Failed to load privacy status:', error);
    }
}

/**
 * Load available privacy pools
 */
async function loadPrivacyPools() {
    try {
        const response = await fetch(`${CONFIG.API_BASE}/privacy/pools`);
        const data = await response.json();
        state.privacy.pools = data.pools || [];

        // Update pool dropdowns
        updatePrivacyPoolOptions();
    } catch (error) {
        console.error('Failed to load privacy pools:', error);
    }
}

/**
 * Update privacy pool dropdown options
 */
function updatePrivacyPoolOptions() {
    const tokenSelect = $('#privacyToken');
    const amountSelect = $('#privacyAmount');

    if (!tokenSelect || !amountSelect) return;

    // Get unique tokens
    const tokens = [...new Set(state.privacy.pools.map(p => p.token || p.tokenSymbol))];

    tokenSelect.innerHTML = tokens.map(token =>
        `<option value="${token}">${token}</option>`
    ).join('');

    // Update amounts based on selected token
    const updateAmounts = () => {
        const selectedToken = tokenSelect.value;
        const pools = state.privacy.pools.filter(p =>
            (p.token || p.tokenSymbol) === selectedToken
        );

        amountSelect.innerHTML = pools.map(p =>
            `<option value="${p.denomination || p.amount}">${p.denomination || p.amount}</option>`
        ).join('');
    };

    tokenSelect.addEventListener('change', updateAmounts);
    updateAmounts();
}

/**
 * Toggle privacy mode
 */
function togglePrivacyMode() {
    state.privacy.enabled = !state.privacy.enabled;
    $('#privacyToggle')?.classList.toggle('active', state.privacy.enabled);
    $('#privacyControls')?.classList.toggle('hidden', !state.privacy.enabled);

    if (state.privacy.enabled) {
        showToast('Privacy mode enabled - your transactions will be mixed', 'info');
        trackActivity('privacy_enabled', {});
    } else {
        showToast('Privacy mode disabled - transactions will be transparent', 'info');
        trackActivity('privacy_disabled', {});
    }
}

/**
 * Generate a privacy deposit note
 */
async function generatePrivacyNote() {
    const token = $('#privacyToken')?.value;
    const amount = $('#privacyAmount')?.value;

    if (!token || !amount) {
        showToast('Please select token and amount', 'warning');
        return;
    }

    try {
        showToast('Generating privacy note...', 'info');

        const response = await fetch(`${CONFIG.API_BASE}/privacy/note`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ token, amount })
        });

        const data = await response.json();

        if (data.success) {
            state.privacy.notes.push(data.note);

            const noteDisplay = $('#privacyNoteDisplay');
            if (noteDisplay) {
                noteDisplay.value = data.note.note;
            }

            showToast('Privacy note generated - save this securely!', 'success');
            trackActivity('privacy_note_generated', { token, amount });

            // Update fee estimate
            await updatePrivacyFeeEstimate(token, amount);
        }
    } catch (error) {
        console.error('Failed to generate note:', error);
        showToast('Failed to generate note', 'error');
    }
}

/**
 * Update fee estimate for privacy transaction
 */
async function updatePrivacyFeeEstimate(token, amount) {
    try {
        const response = await fetch(`${CONFIG.API_BASE}/privacy/fees?token=${token}&amount=${amount}`);
        const data = await response.json();

        if (data.success) {
            const feeDisplay = $('#privacyFeeEstimate');
            if (feeDisplay) {
                feeDisplay.textContent = `Estimated fee: ${data.totalFee} ${token}`;
            }
        }
    } catch (error) {
        console.error('Failed to fetch fee estimate:', error);
    }
}

/**
 * Execute private deposit
 */
async function executePrivateDeposit() {
    const noteDisplay = $('#privacyNoteDisplay');
    const note = noteDisplay?.value;

    if (!note) {
        showToast('Generate a note first', 'warning');
        return;
    }

    if (!state.wallet) {
        showToast('Please connect wallet first', 'warning');
        return;
    }

    try {
        showToast('Executing private deposit...', 'info');

        // In production, get private key from wallet
        // For demo mode, use placeholder
        const response = await fetch(`${CONFIG.API_BASE}/privacy/deposit`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
                note,
                privateKey: state.account, // In production, use actual signing
                useRouter: true
            })
        });

        const data = await response.json();

        if (data.success) {
            showToast(`Private deposit complete: ${formatAddress(data.result.txHash)}`, 'success');
            trackActivity('private_deposit', { txHash: data.result.txHash });

            // Clear note display for security
            if (noteDisplay) {
                noteDisplay.value = '';
            }
        }
    } catch (error) {
        console.error('Deposit failed:', error);
        showToast('Deposit failed', 'error');
    }
}

/**
 * Validate a privacy note
 */
async function validatePrivacyNote() {
    const noteInput = $('#validateNoteInput');
    const note = noteInput?.value;

    if (!note) {
        showToast('Enter a note to validate', 'warning');
        return;
    }

    try {
        const response = await fetch(`${CONFIG.API_BASE}/privacy/note/validate`, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ note })
        });

        const data = await response.json();

        const validationResult = $('#noteValidationResult');
        if (validationResult) {
            if (data.valid) {
                validationResult.innerHTML = `
                    <span class="validation-valid"> Valid Note</span>
                    <span>Token: ${data.token} | Amount: ${data.amount}</span>
                `;
            } else {
                validationResult.innerHTML = `
                    <span class="validation-invalid"> Invalid Note</span>
                `;
            }
        }
    } catch (error) {
        console.error('Validation failed:', error);
        showToast('Validation failed', 'error');
    }
}

/**
 * Copy privacy note to clipboard
 */
function copyPrivacyNote() {
    const noteDisplay = $('#privacyNoteDisplay');
    if (!noteDisplay?.value) {
        showToast('No note to copy', 'warning');
        return;
    }

    navigator.clipboard.writeText(noteDisplay.value)
        .then(() => showToast('Note copied to clipboard', 'success'))
        .catch(() => showToast('Failed to copy note', 'error'));
}

/**
 * Save note to local storage (encrypted in production)
 */
function saveNoteLocally() {
    const noteDisplay = $('#privacyNoteDisplay');
    const note = noteDisplay?.value;

    if (!note) {
        showToast('No note to save', 'warning');
        return;
    }

    try {
        const savedNotes = JSON.parse(localStorage.getItem('finallica_privacy_notes') || '[]');
        savedNotes.push({
            note,
            savedAt: Date.now(),
            used: false
        });
        localStorage.setItem('finallica_privacy_notes', JSON.stringify(savedNotes));
        showToast('Note saved locally (encrypted)', 'success');
    } catch (error) {
        showToast('Failed to save note', 'error');
    }
}

/**
 * Load saved notes
 */
function loadSavedNotes() {
    try {
        const savedNotes = JSON.parse(localStorage.getItem('finallica_privacy_notes') || '[]');
        const notesList = $('#savedNotesList');

        if (!notesList) return;

        if (savedNotes.length === 0) {
            notesList.innerHTML = '<p class="text-muted">No saved notes</p>';
            return;
        }

        notesList.innerHTML = savedNotes.map((item, index) => `
            <div class="saved-note-item">
                <span class="note-date">${new Date(item.savedAt).toLocaleDateString()}</span>
                <span class="note-preview">${item.note.substring(0, 30)}...</span>
                <span class="note-status ${item.used ? 'used' : 'unused'}">${item.used ? 'Used' : 'Unused'}</span>
                <button class="btn btn-sm btn-secondary" onclick="loadNoteIntoForm(${index})">Load</button>
            </div>
        `).join('');
    } catch (error) {
        console.error('Failed to load saved notes:', error);
    }
}

/**
 * Get privacy disclaimer for UI
 */
function getPrivacyDisclaimer() {
    return `
        <div class="privacy-disclaimer">
            <strong>Privacy Disclaimer:</strong>
            <ul>
                <li>Tornado Cash sanctions were lifted in March 2025, but regulations vary by jurisdiction</li>
                <li>Some exchanges may flag addresses that interact with mixers</li>
                <li>You are responsible for compliance with your local laws</li>
                <li>Always save your note securely - it cannot be recovered</li>
            </ul>
        </div>
    `;
}

// ============================================
// INITIALIZATION
// ============================================

function init() {
    // Tab navigation
    $$('.tab-btn').forEach(btn => {
        btn.addEventListener('click', () => {
            const tab = btn.dataset.tab;

            $$('.tab-btn').forEach(b => b.classList.remove('active'));
            $$('.tab-pane').forEach(p => p.classList.remove('active'));

            btn.classList.add('active');
            $(`#${tab}`)?.classList.add('active');
        });
    });

    // Button event listeners
    $('#connectWallet').addEventListener('click', connectWallet);
    $('#refreshDocs').addEventListener('click', loadDocuments);
    $('#editDoc').addEventListener('click', editDocument);
    $('#previewChanges').addEventListener('click', previewChanges);
    $('#saveEdit').addEventListener('click', saveEdit);
    $('#cancelEdit').addEventListener('click', cancelEdit);
    $('#proposeChange').addEventListener('click', () => showProposalModal());
    $('#viewHistory').addEventListener('click', () => {
        $('.tab-btn[data-tab="activity"]').click();
    });
    $('#closeModal').addEventListener('click', closeModal);
    $('#cancelProposal').addEventListener('click', closeModal);
    $('#submitProposal').addEventListener('click', submitProposal);
    $('#closeVotingModal').addEventListener('click', closeVotingModal);
    $('#voteFor').addEventListener('click', () => vote('for'));
    $('#voteAgainst').addEventListener('click', () => vote('against'));
    $('#voteAbstain').addEventListener('click', () => vote('abstain'));
    $('#sendChat').addEventListener('click', sendChatMessage);
    $('#clearChat').addEventListener('click', clearChat);

    // Chat input enter key
    $('#chatInput').addEventListener('keydown', (e) => {
        if (e.key === 'Enter' && !e.shiftKey) {
            e.preventDefault();
            sendChatMessage();
        }
    });

    // Slider value update
    $('#stakeWeight').addEventListener('input', (e) => {
        $('#stakeWeightValue').textContent = e.target.value;
    });

    // Load initial data
    loadDocuments();
    loadProposals();
    loadConsensus();
    loadAIModels();
    loadPrivacyStatus();
    renderActivity();
    connectWebSocket();

    // Privacy button listeners
    $('#privacyToggle')?.addEventListener('click', togglePrivacyMode);
    $('#generatePrivacyNote')?.addEventListener('click', generatePrivacyNote);
    $('#executePrivateDeposit')?.addEventListener('click', executePrivateDeposit);
    $('#validatePrivacyNote')?.addEventListener('click', validatePrivacyNote);
    $('#copyPrivacyNote')?.addEventListener('click', copyPrivacyNote);
    $('#saveNoteLocally')?.addEventListener('click', saveNoteLocally);
}

// Start application when DOM is ready
document.addEventListener('DOMContentLoaded', init);
</file>

<file path="frontend/ARCHITECTURE_OVERVIEW.md">
# Finallica Architecture Overview

This document describes the macro network architecture and end-to-end payment flow of the Finallica global financial privacy network.

---

## Section 1: Macro Network Architecture

### 1.1 Global Topology

The Finallica network operates as a **trust-minimized settlement overlay** consisting of:

- **127 jurisdictional shards** for regulatory compliance and latency optimization
- **~12,000 Validator-Routers (VRs)** distributed globally
- **8 Consensus Notaries** providing BFT state root signatures
- **15,240 cross-shard bridge links** connecting shards

### 1.2 Consensus Notaries (8 Authorities)

Eight geo-distributed notaries maintain the global state root:

| Notary | Location | BLS Pubkey | Stake |
|--------|----------|------------|-------|
| Notary1 | Switzerland | 0x1a2b... | 50M BLF |
| Notary2 | Singapore | 0x3c4d... | 48M BLF |
| Notary3 | Iceland | 0x5e6f... | 52M BLF |
| Notary4 | Canada | 0x7a8b... | 45M BLF |
| Notary5 | New Zealand | 0x9c0d... | 51M BLF |
| Notary6 | Germany | 0xae1f... | 47M BLF |
| Notary7 | Japan | 0xbf2a... | 49M BLF |
| Notary8 | USA | 0xd03c... | 46M BLF |

**Notary Responsibilities**:
- Publish global state root every 10 seconds
- Sign state root with BLS12-381 aggregated signatures (5 of 8 threshold)
- Validate shard state proofs via STARKs

### 1.3 Shard Topology (127 Shards)

Each shard is a **Crandall clique** of Validator-Routers:

```
Shard N topology:

 N = floor(  stake_weight) where  = 2.5                   
 Full-mesh TLS connections between all VRs in shard          
 Deterministic bipartite graph for cross-shard bridges       
 Bridge selection: top 5% stake in each shard                

```

#### Example: Shard 0 (North America)

| VR ID | IP Address | Role | Stake | Fee | Flags |
|-------|------------|------|-------|-----|-------|
| VR-0-001 | 203.0.113.9 | Guard | 8.2M BLF | 3 bps | Guard, Bridge, Stable |
| VR-0-015 | 203.0.113.42 | Guard | 15.7M BLF | 2 bps | Guard, Bridge, Fast |
| VR-0-084 | 203.0.113.128 | Guard | 4.1M BLF | 5 bps | Guard |
| VR-0-341 | 203.0.114.55 | Middle | 2.8M BLF | 4 bps | - |
| VR-0-552 | 203.0.115.72 | Middle | 6.3M BLF | 3 bps | - |
| VR-0-891 | 203.0.116.18 | Middle | 1.9M BLF | 6 bps | - |
| SE-0-12 | 203.0.117.5 | Exit | 12.3M BLF | 25 bps | SWIFT, ACH, BTC |
| SE-0-45 | 203.0.117.89 | Exit | 8.7M BLF | 10 bps | ACH only |

**Shard 0 Statistics**:
- Total VRs: 2,407 (as of epoch 18492)
- Guard VRs: ~722 (top 30% by stake)
- Middle VRs: ~1,485
- Settlement Executors: ~200
- Total Stake: 4.82B BLF ($21.7B)
- Avg Stake per VR: 2.01M BLF

### 1.4 Cross-Shard Bridges

**Bridge Selection**: VRs with stake in top 5% of shard become bridges.

```
Bridges per shard: 120
Total cross-shard links: 15,240
Bridge protocol: TLS 1.3 + BLS authentication
Bridge bandwidth: 10 Gbps per link
Bridge latency: 85-92ms (inter-continental)
```

**Example Bridge**:
```
Bridge-0-1: 203.0.113.9 (Shard 0)  198.51.100.14 (Shard 1)
  Protocol: TLS 1.3
  Bandwidth: 10 Gbps
  Latency: 85ms
  Role: Shard 0  Shard 1 payment routing
```

### 1.5 Network Visualization

```mermaid
graph TB
    subgraph "Global Consensus Layer (8 Notaries)"
        N1["Notary1<br/>203.0.113.1<br/>BLS: 0x1a2b...<br/>Stake: 50M BLF<br/>Location: Switzerland"]
        N2["Notary2<br/>203.0.113.2<br/>BLS: 0x3c4d...<br/>Stake: 48M BLF<br/>Location: Singapore"]
        N3["Notary3<br/>203.0.113.3<br/>BLS: 0x5e6f...<br/>Stake: 52M BLF<br/>Location: Iceland"]
        N4["Notary4<br/>203.0.113.4<br/>BLS: 0x7a8b...<br/>Stake: 45M BLF<br/>Location: Canada"]
        N5["Notary5<br/>203.0.113.5<br/>BLS: 0x9c0d...<br/>Stake: 51M BLF<br/>Location: New Zealand"]
        N6["Notary6<br/>203.0.113.6<br/>BLS: 0xae1f...<br/>Stake: 47M BLF<br/>Location: Germany"]
        N7["Notary7<br/>203.0.113.7<br/>BLS: 0xbf2a...<br/>Stake: 49M BLF<br/>Location: Japan"]
        N8["Notary8<br/>203.0.113.8<br/>BLS: 0xd03c...<br/>Stake: 46M BLF<br/>Location: USA"]
    end

    subgraph "Shard 0 (North America) - 2,407 VRs"
        subgraph "Guard VRs (Entry) - Top 30% by stake"
            G0["VR-0-001<br/>203.0.113.9<br/>Stake: 8.2M BLF<br/>Fee: 3 bps<br/>Flags: Guard, Bridge, Stable"]
            G1["VR-0-015<br/>203.0.113.42<br/>Stake: 15.7M BLF<br/>Fee: 2 bps<br/>Flags: Guard, Bridge, Fast"]
            G2["VR-0-084<br/>203.0.113.128<br/>Stake: 4.1M BLF<br/>Fee: 5 bps<br/>Flags: Guard"]
        end

        subgraph "Middle VRs - 1,200 nodes"
            M0["VR-0-341<br/>203.0.114.55<br/>Stake: 2.8M BLF<br/>Fee: 4 bps"]
            M1["VR-0-552<br/>203.0.115.72<br/>Stake: 6.3M BLF<br/>Fee: 3 bps"]
            M2["VR-0-891<br/>203.0.116.18<br/>Stake: 1.9M BLF<br/>Fee: 6 bps"]
        end

        subgraph "Settlement Executors (Exits) - 200 nodes"
            E0["SE-0-12<br/>203.0.117.5<br/>Stake: 12.3M BLF<br/>Fee: 25 bps<br/>Rails: SWIFT, ACH, BTC"]
            E1["SE-0-45<br/>203.0.117.89<br/>Stake: 8.7M BLF<br/>Fee: 10 bps<br/>Rails: ACH only"]
        end
    end

    subgraph "Shard 1 (Europe) - 2,800 VRs"
        G10["VR-1-007<br/>198.51.100.14<br/>Stake: 11.2M BLF<br/>Fee: 2 bps<br/>Flags: Guard, Bridge"]
        E10["SE-1-33<br/>198.51.101.67<br/>Stake: 9.8M BLF<br/>Fee: 15 bps<br/>Rails: SEPA, BTC"]
    end

    subgraph "Cross-Shard Bridge Links (15,240 total)"
        B0["Bridge-0-1<br/>203.0.113.9  198.51.100.14<br/>TLS 1.3<br/>Bandwidth: 10 Gbps<br/>Latency: 85ms"]
        B1["Bridge-0-1<br/>203.0.113.42  198.51.100.203<br/>TLS 1.3<br/>Bandwidth: 10 Gbps<br/>Latency: 92ms"]
    end

    subgraph "Client Infrastructure"
        FP["Finallica Proxy<br/>127.0.0.1:31337<br/>Wallet daemon<br/>Pathfinding engine<br/>Channel manager"]
        WALLET["User Wallet UI<br/>Mobile app<br/>BOLT-11 invoice scanner"]
        API["Merchant API<br/>RFC-5546 payment pointers<br/>Webhook callbacks"]
    end

    subgraph "Legacy Settlement Rails"
        SWIFT["SWIFT Network<br/>MT103 messages<br/>Settlement time: 1-3 days"]
        ACH["ACH Network<br/>NACHA files<br/>Settlement time: 1-2 days"]
        BTC["Bitcoin L1<br/>On-chain tx<br/>Settlement time: 10 min"]
        LN["Bitcoin Lightning<br/>HTLC routing<br/>Settlement time: 3 sec"]
    end

    N1 ---|BLS sign| CONS["Global State Root<br/>SHA256 of all shard roots<br/>8 BLS signatures<br/>Valid: 10 sec"]
    N2 ---|BLS sign| CONS
    N3 ---|BLS sign| CONS
    N4 ---|BLS sign| CONS
    CONS -->|pushed| G0
    CONS -->|pushed| G1
    CONS -->|pushed| M0
    CONS -->|pushed| E0

    G0 <-->|Noise_XX + DPDK<br/>Port 31337| M0
    G0 <-->|Noise_XX + DPDK| M1
    G0 <-->|Noise_XX + DPDK| G1
    M0 <-->|Noise_XX + DPDK| M1
    M0 <-->|Noise_XX + DPDK| E0
    M1 <-->|Noise_XX + DPDK| E1
    G1 <-->|Noise_XX + DPDK| E0

    G0 ---|TLS 1.3 + BLS auth| B0
    G1 ---|TLS 1.3 + BLS auth| B1
    B0 ---|shard 1| G10
    B1 ---|shard 1| G10

    WALLET -->|Noise_XK + TCP| FP
    API -->|Noise_XK + TCP| FP
    FP -->|OPEN cell<br/>Noise handshake| G0
    FP -->|OPEN cell| G1

    E0 -->|MT103| SWIFT
    E1 -->|NACHA| ACH
    E0 -->|Bitcoin RPC| BTC
    E0 -->|gRPC| LN
```

---

## Section 2: End-to-End Payment Flow

### 2.1 Overview: $100 Invoice to Settlement

Total time: **1-3 days** (dominated by SWIFT settlement)
Internal processing: **~260ms** (channel build + HTLC attachment)

```
Phase 1: Invoice Parsing & Route Selection     (12ms)
Phase 2: Channel Construction                  (247ms p50)
Phase 3: HTLC Attachment                       (5ms)
Phase 4: Settlement Execution                  (1-3 days SWIFT)
Phase 5: Channel Rebalance                     (optional, 30s)
```

### 2.2 Phase 1: Invoice Parsing & Route Selection (12ms)

```mermaid
sequenceDiagram
    participant User as User<br/>Payer
    participant Wallet as Wallet UI<br/>Mobile app
    participant FP as Finallica Proxy<br/>127.0.0.1:31337
    participant Dir as Directory Cache<br/>/var/lib/finallica/consensus.dat

    Note over User,Dir: Phase 1: Invoice Parsing & Route Selection (12ms)
    User->>Wallet: Scan BOLT-11 invoice<br/>lnbc10u1p3y...xyz
    Wallet->>Wallet: decode_bolt11()<br/>amount=$100<br/>payment_hash=0x1a2b...<br/>expiry=3600s
    Wallet->>FP: pay_invoice(invoice, amount=10,000,000 microcents)
    FP->>Dir: get_vr_path(amount=10M, dest_shard=0, currency=USD)
    Dir-->>FP: Path: G0(3bps)  M1(4bps)  E0(25bps)<br/>Total fee: 32bps ($0.32)
    FP->>FP: select_entry_guard()<br/>Chosen: VR-0-015 (stake=15.7M, fee=2bps)<br/>Recalc fee: 31bps ($0.31)
```

**Route Selection Algorithm**:

```c
struct vr_path *select_path(
  uint64_t amount_microcents,
  uint16_t dest_shard_id,
  uint8_t required_flags) {

  // Step 1: Guard selection (persistent)
  struct entry_guard *guard = get_guard_by_shard(0);

  // Formula: weight = stake^0.7 * uptime_factor / fee_bps^2
  double weight = pow(guard->stake, 0.7) *
                  (guard->uptime_days / 30.0) /
                  (guard->fee_bps * guard->fee_bps);

  // Step 2: Middle VR selection (probabilistic)
  // Top 50 by stake, reservoir sampling

  // Step 3: Exit VR selection
  // Filter by currency support, fee < 50 bps, latency < 500ms

  return path;
}
```

### 2.3 Phase 2: Channel Construction (247ms p50)

```mermaid
sequenceDiagram
    participant FP as Finallica Proxy
    participant G as Guard VR<br/>VR-0-015
    participant M as Middle VR<br/>VR-0-552
    participant E as Settlement Executor<br/>SE-0-12

    Note over FP,E: Phase 2: Channel Construction (247ms p50)
    FP->>G: OPEN2 cell (Noise_XX)<br/>channel_id=0x4f3e2d1c<br/>ephemeral=0x9f8e..., amount=10M<br/>BLS sign: _payer
    G->>G: noise_handshake_process()<br/>X25519 DH: 90s<br/>BLAKE2s KDF: 25s<br/>BLS verify: 105s (batch)
    G->>FP: OPENED2 cell<br/>channel_id=0x4f3e2d1c<br/>K_entry derived<br/>g^y, BLS sig: _guard
    FP->>FP: KDF_Noise(g^xy)  K_pay || K_settle || K_pad

    FP->>G: EXTEND cell (encrypted w/ K_pay)<br/>Target: VR-0-552 pubkey<br/>ephemeral_mid=0x7d6c...
    G->>M: OPEN2 cell (new channel_id=0x8a7b6c5d)<br/>Noise handshake
    M->>G: OPENED2 cell
    G->>FP: EXTENDED cell<br/>K_mid derived

    FP->>G: EXTEND2 cell (encrypted K_mid)<br/>Target: SE-0-12 pubkey<br/>ephemeral_exit=0x5b4a...
    M->>E: OPEN2 cell (channel_id=0x9c8d7e6f)
    E->>M: OPENED2 cell
    M->>G: EXTENDED2
    G->>FP: EXTENDED2<br/>K_exit derived<br/>Total: 3 hops built
```

**Noise_XX Handshake Transcript**:

```
// Prologue (client  VR)
-> e  (ephemeral pubkey: 32-byte X25519)

// VR response with stake proof
<- e, ee, s, es
   e = VR ephemeral pubkey
   ee = DH(e_client, e_vr)  shared secret
   s = VR BLS12-381 pubkey (48 bytes, compressed G1)
   es = DH(e_client, s_vr)  stake binding

// Client authentication
-> s, se, psk
   s = client BLS pubkey (48 bytes)
   se = DH(e_vr, s_client)
   psk = pre-shared key from stake delegation certificate
```

### 2.4 Phase 3: HTLC Attachment (5ms)

```mermaid
sequenceDiagram
    participant FP as Finallica Proxy
    participant G as Guard VR
    participant M as Middle VR
    participant E as Settlement Executor

    Note over FP,E: Phase 3: HTLC Attachment (5ms)
    FP->>FP: attach_payment_stream()<br/>stream_id=0x0042<br/>assign_htlc_id=0x123456789abc
    FP->>G: PAY cell (stream_id=0x0042)<br/>Encrypted w/ K_pay:<br/>{amount=10M, expiry=1706035200<br/>payment_hash=0x1a2b...<br/>next_hop=VR-0-552}<br/>Pedersen commitment: C = v*G + b*H
    G->>M: PAY cell (stream_id=0x0042)<br/>Encrypted w/ K_mid<br/>Deduct from channel balance: -10M microcents
    M->>E: PAY cell (stream_id=0x0042)<br/>Encrypted w/ K_exit<br/>Deduct: -10M microcents
    E->>E: Record HTLC: id=0x123456789abc<br/>amount=10M, hash=0x1a2b...<br/>timeout=1706035200
```

### 2.5 Phase 4: Settlement Execution (1-3 days SWIFT)

```mermaid
sequenceDiagram
    participant E as Settlement Executor
    participant Bank as Beneficiary Bank<br/>SWIFT: CHASUS33XXX
    participant M as Middle VR
    participant G as Guard VR
    participant FP as Finallica Proxy
    participant Wallet as Wallet UI

    Note over E,Wallet: Phase 4: Settlement Execution (1-3 days SWIFT)
    E->>Bank: SWIFT MT103 message<br/>Beneficiary: CHASUS33XXX<br/>Amount: $99.69 (after fees)<br/>Reference: SHA256(payment_preimage)
    Bank->>Bank: Process incoming SWIFT<br/>Credit beneficiary account
    Bank->>E: MT900 confirmation (1-3 days)

    E->>M: SETTLE cell (stream_id=0x0042)<br/>preimage=0xfedcba...<br/>BLS settle sig: _exit
    M->>G: SETTLE cell
    G->>FP: SETTLE cell<br/>Verify: SHA256(preimage) == payment_hash 
    FP->>Wallet: Payment settled<br/>Txid: 0xdeadbeef...<br/>Fee: $0.31<br/>Net: $99.69
```

### 2.6 Phase 5: Channel Rebalance (optional, 30s)

```mermaid
sequenceDiagram
    participant FP as Finallica Proxy
    participant E as Settlement Executor

    Note over FP,E: Phase 5: Channel Rebalance (optional, 30s)
    FP->>E: REBALANCE cell<br/>Atomic swap: 5M microcents to refill channel
    E->>FP: REBALANCE_ACK<br/>Channel: 0x4f3e2d1c<br/>New balance: 15M microcents
```

---

## Key Takeaways

1. **Network Scale**: 127 shards, 12,000 VRs, 8 notaries
2. **Path Selection**: Stake-weighted, 3 hops (Guard  Middle  Exit)
3. **Channel Build**: 247ms p50 via Noise_XX handshakes
4. **Settlement**: 200ms internal finality, 1-3 days external (SWIFT)
5. **Privacy**: Layered encryption, Pedersen commitments, 1-in-1,200 anonymity

---

*Next: [PROTOCOL_SPECIFICATION.md](./PROTOCOL_SPECIFICATION.md) - State Machines & Cell Processing*
</file>

<file path="frontend/CONSENSUS_MECHANISM.md">
# Finallica Consensus Mechanism

This document describes the HotStuff BFT consensus protocol used in Finallica for global state finalization.

---

## HotStuff BFT Protocol Overview

### 8.1 4-Phase Consensus Process

Finality achieved in **200ms** (4 network RTTs  50ms each)

```mermaid
sequenceDiagram
    participant VR as Validator Router<br/>Shard 0, Replica #42
    participant Leader as Leader VR<br/>Shard 0, View #18492
    participant Notary as Consensus Notary<br/>8 of 8 BFT
    participant Mempool as Mempool<br/>Pending HTLCs

    Note over VR,Notary: View 18492, Block Height 1,234,567
    Mempool->>Leader: 2,847 pending HTLCs<br/>Total value: $1.2M
    Leader->>Leader: Propose block<br/>hash = BLAKE2s(txs)<br/>state_root = MerkleRoot(accounts)

    Note over VR,Leader: Phase 1: PREPARE (50ms RTT)
    Leader->>VR: PREPARE(hash=0xbeef..., view=18492, justify=QC_18491)
    VR->>VR: Verify QC_18491 (8 BLS sigs)<br/>0.8ms
    VR->>Leader: PREPARE-VOTE<br/>BLS partial sig: _42
    Note over Leader: Collect 67% votes (1,605 of 2,400 VRs)

    Note over Leader: Phase 2: PRE-COMMIT (50ms RTT)
    Leader->>VR: PRE-COMMIT(hash=0xbeef..., QC_prepare)
    VR->>VR: Lock block 0xbeef...<br/>persist to disk<br/>fsync() = 2ms
    VR->>Leader: PRE-COMMIT-VOTE<br/>_42_locked

    Note over Leader: Phase 3: COMMIT (50ms RTT)
    Leader->>VR: COMMIT(hash=0xbeef..., QC_precommit)
    VR->>VR: Commit to ledger<br/>Update state root<br/>Apply HTLC settlements
    VR->>Leader: COMMIT-VOTE<br/>_42_committed

    Note over Leader,Notary: Phase 4: DECIDE (50ms RTT)
    Leader->>Notary: DECIDE(hash=0xbeef..., QC_commit, state_proof)
    Notary->>Notary: Verify QC_commit (1,605 BLS sigs)<br/>Aggregate: 125ms
    Notary->>Notary: Sign global state root<br/>8 notaries, 5ms each
    Notary->>VR: SIGNED_STATE_ROOT<br/>state_root=0xdead...<br/>8 BLS sigs aggregated

    VR->>VR: Apply finality<br/>Release settled funds<br/>channel->available_to_send += settled_amount
    Note over VR: Finality achieved: 200ms
```

---

## HotStuff Message Structures

### 8.2 Vote Message

```c
struct hotstuff_vote {
  uint64_t view_number;
  uint64_t block_height;
  uint8_t  block_hash[32];
  uint8_t  partial_signature[96];  // BLS G2 share
  uint8_t  signer_pubkey[48];      // BLS G1
  uint8_t  justification[192];     // QC from previous view
} __attribute__((packed));
```

### 8.3 Quorum Certificate (QC)

```c
struct quorum_certificate {
  uint64_t view_number;
  uint8_t  block_hash[32];
  uint8_t  aggregated_signature[96];  // BLS signature aggregation
  uint8_t  signers_bitfield[SHARD_SIZE / 8];  // 300 bytes for 2400 bits
} __attribute__((packed));
```

### 8.4 Block Proposal

```c
struct hotstuff_block {
  uint64_t view_number;
  uint64_t block_height;
  uint8_t  parent_hash[32];
  uint8_t  block_hash[32];
  uint8_t  state_root[32];
  uint16_t tx_count;
  struct hotstuff_tx *transactions;  // Array of txs
  struct quorum_certificate *justify;  // QC from previous view
} __attribute__((packed));
```

---

## BLS Signature Aggregation

### 8.5 Aggregating Partial Signatures

```c
// Aggregate 1,605 partial signatures into one QC signature
bls_signature aggregate_signatures(
  bls_signature *partial_sigs[],
  uint16_t *signer_indices,
  uint16_t count) {

  bls_signature aggregated;
  bls_signature_init(&aggregated);

  // Lagrange coefficients for threshold signature
  for (int i = 0; i < count; i++) {
    // Compute Lagrange coefficient: _i = _{ji} (j / (j - i))
    mpz_t lambda;
    compute_lagrange_coefficient(lambda, signer_indices[i], signer_indices, count);

    // Multiply signature by coefficient
    bls_signature scaled;
    bls_signature_mul(&scaled, &partial_sigs[i], lambda);

    // Add to aggregate
    bls_signature_add(&aggregated, &aggregated, &scaled);
  }

  return aggregated;
}
```

### 8.6 Verifying Aggregated Signature

```c
bool verify_qc_signature(
  struct quorum_certificate *qc,
  bls_public_key *validator_pubs[],
  uint16_t validator_count) {

  bls_signature agg_sig;
  bls_signatureDeserialize(&agg_sig, qc->aggregated_signature, 96);

  // Fast aggregate verification: e(agg_sig, G1) ==  e(H(block), pk_i)
  return bls_fast_aggregate_verify(
    &agg_sig,
    validator_pubs,
    validator_count,
    &qc->block_hash,
    32
  );
}
```

---

## State Root Commitment

### 8.7 Merkle Trie Construction

```c
struct merkle_node {
  uint8_t hash[32];
  struct merkle_node *left;
  struct merkle_node *right;
  struct account_state *value;  // NULL for internal nodes
};

// Compute state root from account states
uint8_t *compute_state_root(struct account_state accounts[], uint32_t count) {
  // Build Merkle trie from account states
  struct merkle_node *root = build_merkle_trie(accounts, count);

  // Hash root node
  uint8_t *root_hash = malloc(32);
  SHA256(root->hash, 32, root_hash);

  return root_hash;
}

// Verify Merkle proof for specific account
bool verify_merkle_proof(
  uint8_t *root_hash,
  uint8_t account_key[32],
  uint8_t account_value[32],
  uint8_t proof[][32],
  uint32_t proof_length) {

  uint8_t current_hash[32];
  SHA256(account_key, 32, current_hash);
  SHA256(current_hash, 32, current_hash);
  memcpy(current_hash, account_value, 32);

  // Climb up Merkle tree using proof
  for (uint32_t i = 0; i < proof_length; i++) {
    uint8_t combined[64];
    if (account_key[i % 32] % 2 == 0) {
      memcpy(combined, current_hash, 32);
      memcpy(combined + 32, proof[i], 32);
    } else {
      memcpy(combined, proof[i], 32);
      memcpy(combined + 32, current_hash, 32);
    }
    SHA256(combined, 64, current_hash);
  }

  return memcmp(current_hash, root_hash, 32) == 0;
}
```

---

## Leader Rotation

### 8.8 Round-Robin Leader Selection

```c
struct hotstuff_view {
  uint64_t view_number;
  bls_pubkey_t leader_pubkey;
  uint64_t start_time;
  uint64_t timeout_ms;
};

// Select leader for view N
bls_pubkey_t select_leader(uint64_t view_number, bls_pubkey_t validators[], uint32_t count) {
  // Round-robin: leader = validators[view_number % count]
  uint32_t leader_index = view_number % count;
  return validators[leader_index];
}

// Check if view timeout, trigger new view
bool check_view_timeout(struct hotstuff_view *view) {
  uint64_t elapsed = get_time_ms() - view->start_time;

  if (elapsed > view->timeout_ms) {
    // Trigger view change
    view->view_number++;
    view->leader_pubkey = select_leader(view->view_number, validators, validator_count);
    view->start_time = get_time_ms();
    view->timeout_ms *= 2;  // Exponential backoff
    return true;
  }

  return false;
}
```

---

## View Change Protocol

### 8.9 New View Message

```c
struct new_view_msg {
  uint64_t new_view_number;
  bls_pubkey_t new_leader_pubkey;
  struct quorum_certificate *justify;  // QC from previous view
  uint8_t signature[96];  // Leader's signature on new view
} __attribute__((packed));
```

### 8.10 Handling View Changes

```c
void handle_new_view(struct new_view_msg *nv) {
  // Verify leader's signature
  if (!bls_verify(&nv->signature, &nv->new_leader_pubkey, nv, sizeof(*nv))) {
    return;  // Invalid signature
  }

  // Verify justification QC
  if (!verify_qc_signature(nv->justify, validator_pubs, validator_count)) {
    return;  // Invalid QC
  }

  // Accept new view
  current_view->view_number = nv->new_view_number;
  current_view->leader_pubkey = nv->new_leader_pubkey;
  current_view->start_time = get_time_ms();

  // Broadcast NEW-VOTE to new leader
  struct hotstuff_vote vote = {
    .view_number = nv->new_view_number,
    .block_height = current_block_height,
    .block_hash = {0},  // Empty for new view
    .signer_pubkey = my_pubkey
  };

  bls_sign(&vote.partial_signature, my_secret_key, &vote, sizeof(vote) - 96);
  send_to_leader(&vote);
}
```

---

## Consensus Performance

### 8.11 Latency Breakdown

| Phase | RTT | Time |
|-------|-----|------|
| PREPARE | 50ms | 50ms |
| PRE-COMMIT | 50ms | 100ms |
| COMMIT | 50ms | 150ms |
| DECIDE | 50ms | 200ms |
| **Total** | **4 RTTs** | **200ms** |

### 8.12 Throughput Analysis

| Metric | Value | Notes |
|--------|-------|-------|
| Block interval | 10 sec | State root published |
| TPS per shard | ~10,000 | Theoretical max |
| Block size | ~100K payments | 10,000 TPS  10 sec |
| State propagation | 50ms | Within shard |
| Cross-shard sync | 200ms | Via bridges |

---

## Notary BFT Parameters

### 8.13 Consensus Notary Configuration

| Parameter | Value | Description |
|-----------|-------|-------------|
| Total Notaries | 8 | Geo-distributed |
| BFT Threshold | 5 of 8 | Byzantine fault tolerance |
| Stake per Notary | 45-52M BLF | ~$200M USD |
| State Root Interval | 10 sec | Finality frequency |
| Signature Aggregation | BLS | 96 bytes (8  48) |

### 8.14 Notary Voting Process

```c
// Every 10 seconds, notaries vote on state root
void notary_vote_on_state_root() {
  // Gather state roots from all 127 shards
  uint8_t shard_roots[127][32];
  collect_shard_state_roots(shard_roots);

  // Compute global state root: SHA256 of all shard roots
  uint8_t global_root[32];
  SHA256(global_root, 32, shard_roots, 127 * 32);

  // Sign with BLS private key
  bls_signature sig;
  bls_sign(&sig, notary_secret_key, global_root, 32);

  // Broadcast signature to all notaries
  broadcast_signature(notary_id, &sig);

  // Wait for 5 more signatures
  bls_signature sigs[8];
  collect_signatures(sigs);

  // Aggregate signatures
  bls_signature agg_sig;
  bls_signature_aggregate(&agg_sig, sigs, 8);

  // Publish to network
  publish_state_root(global_root, &agg_sig);
}
```

---

## Key Takeaways

1. **4-Phase Protocol**: PREPARE  PRE-COMMIT  COMMIT  DECIDE
2. **Finality**: 200ms (4 RTTs  50ms)
3. **Quorum**: 67% threshold (1,605 of 2,400 VRs)
4. **BLS Aggregation**: 96 bytes for 1,605 signatures
5. **State Root**: Published every 10 seconds by 8 notaries

---

*Next: [SECURITY_ANALYSIS.md](./SECURITY_ANALYSIS.md) - Attack Vectors & Defenses*
</file>

<file path="frontend/CONSTANTS_REFERENCE.md">
# Finallica Constants Reference

This document contains all hardcoded constants, limits, and configuration values used throughout the Finallica system.

---

## Cell Protocol Constants

```c
// Cell sizes
#define CELL_SIZE_FINALLICA      1024     // 1 KB per cell
#define PAYLOAD_SIZE_FINALLICA   1008     // Max payload size
#define RELAY_HEADER_SIZE        11       // Payment relay header
#define MAX_STREAM_DATA_SIZE     498      // Max data per PAY cell

// Command types
#define CMD_PADDING              0x00
#define CMD_OPEN                 0x01
#define CMD_PAY                  0x02
#define CMD_SETTLE               0x03
#define CMD_EXTEND               0x04
#define CMD_REKEY                0x05
#define CMD_DESTROY              0x06

// Channel IDs
#define CHANNEL_ID_MIN           1
#define CHANNEL_ID_MAX_INTRA     0x7FFFFFFF  // 2^31 - 1
#define CHANNEL_ID_MAX_INTER     0xFFFFFFFF
#define CHANNEL_ID_ZERO          0  // Reserved

// Stream IDs
#define STREAM_ID_MIN            0x0001
#define STREAM_ID_MAX            0xFFFE
#define STREAM_ID_CIRCUIT        0x0000  // Reserved
#define STREAM_ID_FOR_DIR        0x0001  // Reserved for directory fetch
#define STREAM_ID_MAX_VAL        0xFFFF
```

---

## Channel Management Constants

```c
// Channel lifecycle
#define MAX_ROUTE_LEN            8        // Maximum hops
#define DEFAULT_ROUTE_LEN        3        // Standard path length
#define MIN_CPUS_FOR_EXTEND      1        // Min CPUs for extend
#define CHANNEL_LIFETIME_MAX     21600    // 6 hours (in seconds)
#define CHANNEL_TIMEOUT_INIT     30       // Initial timeout (seconds)

// Guard selection
#define GUARD_LIFETIME           7776000  // 90 days (in seconds)
#define MAX_GUARD_FAILURES       20       // Max failures before rotation
#define GUARD_USAGE_FAILURES     4        // Failures before circuit close

// Channel limits per VR
#define MAX_CHANNELS_PER_PEER    5000
#define CHANNEL_MIN_CAPACITY     50000000 // $500 in microcents
#define CHANNEL_REKEY_INTERVAL   3600     // 1 hour (seconds)
```

---

## HTLC Constants

```c
// HTLC limits
#define HTLC_MIN_VALUE_MICROCENT 1       // $0.00001
#define HTLC_MAX_VALUE_MICROCENT 100000000000  // $1M
#define HTLC_MIN_TIMEOUT         40       // 10 blocks (~5 minutes)
#define HTLC_MAX_TIMEOUT         86400    // 1 day (in seconds)
#define MAX_HTLCS_PER_CHANNEL    483      // BOLT-03 limit

// HTLC timing (in blocks)
#define HTLC_TIMEOUT_MIN_BLOCKS  10
#define HTLC_TIMEOUT_MAX_BLOCKS  1440     // ~1 day
#define HTLC_DEFAULT_TIMEOUT     100      // Default expiry

// HTLC state
#define HTLC_STATE_OFFERED       0
#define HTLC_STATE_LOCKED        1
#define HTLC_STATE_SETTLED       2
#define HTLC_STATE_REFUNDED      3
#define HTLC_STATE_FAILED        4
```

---

## Cryptographic Constants

```c
// BLS12-381
#define BLS12_381_G1_COMPRESSED_SIZE   48   // Pubkey size
#define BLS12_381_G2_COMPRESSED_SIZE   96   // Signature size
#define BLS12_381_FP_SIZE             48   // Field element size
#define BLS_AGGREGATION_BATCH         64   // Optimal batch size

// X25519 / Noise
#define X25519_PUBLIC_KEY_SIZE        32
#define X25519_PRIVATE_KEY_SIZE       32
#define X25519_SHARED_SECRET_SIZE     32
#define NOISE_HANDSHAKE_HASH_SIZE     32

// ChaCha20-Poly1305
#define CHACHA20_KEY_SIZE             32
#define CHACHA20_NONCE_SIZE           12
#define POLY1305_TAG_SIZE             16

// Pedersen Commitment
#define PEDERSEN_COMMITMENT_SIZE      33   // Compressed
#define PEDERSEN_BLINDING_SIZE        32   // Scalar size
#define PEDERSEN_VALUE_BITS           64   // Range: [0, 2^64)

// SHA256 / BLAKE2s
#define SHA256_DIGEST_SIZE            32
#define BLAKE2S_DIGEST_SIZE           32
#define BLAKE2S_KEY_SIZE              32

// Ed25519 (rekey signatures)
#define ED25519_PUBLIC_KEY_SIZE       32
#define ED25519_PRIVATE_KEY_SIZE      64
#define ED25519_SIGNATURE_SIZE        64
```

---

## Network Protocol Constants

```c
// Ports
#define DATAPLANE_PORT           31337    // UDP (DPDK)
#define CONTROLPLANE_PORT        31338    // TCP (TLS)
#define ABUSE_REPORT_PORT        31339    // TCP

// Shard configuration
#define SHARD_COUNT              127      // Total shards
#define SHARD_ID_MIN             0
#define SHARD_ID_MAX             126
#define SHARD_ID_GLOBAL          127      // Reserved

// VR counts
#define VR_PER_SHARD_MIN         1000
#define VR_PER_SHARD_AVG         2400
#define VR_PER_SHARD_MAX         5000
#define BRIDGE_VR_PERCENT        5        // Top 5% become bridges

// Consensus
#define NOTARY_COUNT             8
#define NOTARY_SIG_THRESHOLD     5        // 5 of 8 BFT
#define CONSENSUS_INTERVAL_SEC   10       // State root every 10 sec
#define HOTSTUFF_VIEW_TIMEOUT    50000    // 50ms initial (s)
#define HOTSTUFF_QC_THRESHOLD    0.67     // 67% voting power
```

---

## Performance Tuning Constants

```c
// DPDK configuration
#define DPDK_MEMPOOL_SIZE        2097152  // 2M packets
#define DPDK_CACHE_SIZE          512      // Per-core cache
#define DPDK_RING_SIZE           4096     // RX/TX ring
#define DPDK_BURST_SIZE          32       // Packets per burst

// Cell queuing
#define CELL_QUEUE_HIGHWATER     512000   // 1000 cells  512B
#define CELL_QUEUE_LOWWATER      51200    // 100 cells  512B
#define MAX_REFILLED_CELLS       10       // Per tick

// Scheduling
#define SCHEDULING_INTERVAL_MSEC 10       // KIST interval
#define KIST_MAX_SCHED_BURST     32       // Max cells per schedule
#define KIST_SOCK_OUTQ_MIN       514      // Min socket queue

// CPU affinity
#define CPU_PIN_CONTROL          true
#define CPU_PIN_DATAPLANE        false
```

---

## Fee Structure Constants

```c
// Basis points (1 bp = 0.01%)
#define FEE_BPS_GUARD_MIN        2
#define FEE_BPS_GUARD_MAX        10
#define FEE_BPS_MIDDLE_MIN       3
#define FEE_BPS_MIDDLE_MAX       15
#define FEE_BPS_EXIT_MIN         10
#define FEE_BPS_EXIT_MAX         100

// Settlement rail fees
#define FEE_BPS_SWIFT            25       // 0.25%
#define FEE_BPS_ACH              10       // 0.10%
#define FEE_BPS_SEPA             15       // 0.15%
#define FEE_BPS_BTC              50       // 0.50%
#define FEE_BPS_LN               5        // 0.05%

// Liquidity fees
#define LIQUIDITY_FEE_BASE_BPS   2        // 0.02%
#define LIQUIDITY_UTIL_HIGH      0.85     // 85% threshold
#define LIQUIDITY_UTIL_EXP       4        // Exponential factor

// Padding cost (per user)
#define PADDING_RATE_CELLS_PER_SEC 1     // 1 cell/sec
#define DUST_PAYMENT_AMOUNT      1        // $0.01 (microcents)
```

---

## Staking & Economics Constants

```c
// Token supply
#define TOTAL_SUPPLY_BLF         21000000 // 21M BLF total
#define STAKED_SUPPLY_TARGET     0.878    // 87.8% target
#define INFLATION_RATE_ANNUAL    0.04     // 4% per year

// Minimum stake requirements
#define MIN_STAKE_VR             500000   // 500K BLF (~$2.25M)
#define MIN_STAKE_SE             2000000  // 2M BLF (~$9M)
#define MIN_STAKE_NOTARY         10000000 // 10M BLF (~$45M)

// Unbonding
#define UNBONDING_PERIOD_SEC     2592000  // 30 days

// Slashing penalties (basis points)
#define SLASH_DOUBLE_SIGN        10000    // 100%
#define SLASH_CENSORSHIP         1000     // 10%
#define SLASH_INVALID_SETTLEMENT 500      // 5%
#define SLASH_DOWNTIME           100      // 1% per day

// Liquidity mining
#define LIQUIDITY_APY_MIN        800      // 8% APY minimum
#define LIQUIDITY_TARGET_UTIL    0.60     // 60% utilization optimal
#define CHANNEL_REBALANCE_THRESHOLD_HIGH 0.85  // 85%
#define CHANNEL_REBALANCE_THRESHOLD_LOW  0.15  // 15%
```

---

## Memory Management Constants

```c
// Per-channel memory (40,736 bytes total)
#define CHANNEL_STATE_SIZE       224      // struct channel_t
#define CRYPTO_KEYS_SIZE         1536     // 6 cipher states
#define HTLC_TABLE_SIZE          30912    // 483 entries  64B
#define QUEUE_BUFFERS_SIZE       4096     // Input + output rings
#define REPLAY_PROTECTION_SIZE   8192     // Bloom filter
#define PATH_STATE_SIZE          640      // Guard + middle info

// Memory limits
#define MAX_MEM_IN_QUEUES_MB     1024     // 1 GB default
#define OOM_KILL_THRESHOLD       0.90     // 90% memory usage

// Channel capacity by memory
#define CHANNELS_PER_4GB         98000    // Theoretical
#define CHANNELS_PER_8GB         150000   // Practical
#define CHANNELS_PER_16GB        250000   // High-end
#define CHANNELS_PER_64GB        1000000  // Max
```

---

## Flow Control Constants

```c
// SENDME windows
#define PACKAGE_WINDOW_DEFAULT   1000     // Cells
#define DELIVER_WINDOW_DEFAULT   1000     // Cells
#define SENDME_CELL_THRESHOLD   100      // Send SENDME every 100 cells

// Token bucket rate limits
#define RATE_LIMIT_NORMAL        1000     // cells/sec
#define RATE_LIMIT_HIGH_PRIORITY 5000    // cells/sec
#define RATE_LIMIT_SETTLEMENT    10000    // cells/sec
#define RATE_LIMIT_PADDING       1        // cell/sec

// Burst sizes
#define BURST_NORMAL             100      // cells
#define BURST_HIGH_PRIORITY      500      // cells
#define BURST_SETTLEMENT         1000     // cells
#define BURST_PADDING            10       // cells

// Congestion control
#define CWND_MIN                 100
#define CWND_MAX                 10000
#define CWND_INITIAL             1000
#define SSTHRESH_INITIAL         10000
```

---

## Timing Constants

```c
// Adaptive timeout parameters
#define TIMEOUT_INITIAL_MS       200      // Initial circuit timeout
#define TIMEOUT_MIN_MS           50       // Minimum timeout
#define TIMEOUT_MAX_MS           5000     // Maximum timeout

// Timeout calculation weights
#define TIMEOUT_EWMA_ALPHA       0.8      // Exponential moving average
#define_TIMEOUT_SAMPLE_WEIGHT    0.2

// Keepalive
#define KEEPALIVE_INTERVAL_SEC   60       // PING every 60 sec
#define KEEPALIVE_TIMEOUT_SEC    300      // 5 minutes without response

// Circuit build timing
#define CIRCUIT_BUILD_TIMEOUT_MIN 50     // ms
#define CIRCUIT_BUILD_TIMEOUT_MAX 10000   // ms

// Payment expiry
#define PAYMENT_EXPIRY_MIN_SEC   60       // 1 minute
#define PAYMENT_EXPIRY_MAX_SEC   86400    // 1 day
#define PAYMENT_EXPIRY_DEFAULT   3600     // 1 hour
```

---

## Directory & Consensus Constants

```c
// Consensus document
#define CONSENSUS_PERIOD_SEC     3600     // Vote every hour
#define CONSENSUS_VALID_AFTER_SEC 7200     // Valid 2 hours
#define CONSENSUS_FRESH_UNTIL_SEC 10800   // Fresh for 3 hours
#define CONSENSUS_VALID_UNTIL_SEC 18000   // Valid for 5 hours

// Voting
#define VOTE_DELAY_SEC           300      // 5 minutes
#define CONSENSUS_METHOD_MIN     27       // Minimum supported method
#define CONSENSUS_METHOD_MAX     30       // Maximum supported method

// Descriptor sizes
#define MICRODESC_DIGEST_SIZE    32       // SHA256
#define ROUTER_DESC_MAX_SIZE     8192     // 8 KB max
```

---

## Padding Constants

```c
// Link padding
#define PADDING_SCHEDULE_SINE_WAVE 1      // Sine wave pattern
#define PADDING_CYCLE_SECONDS    86400    // 24-hour cycle
#define PADDING_MIN_RATE_BPS     1250000  // 1.25 MB/s min
#define PADDING_MAX_RATE_BPS     10000000 // 10 MB/s max

// Cell padding
#define PADDING_CELL_BURST_LAMBDA 5.0    // Poisson 
#define PADDING_CELL_MIN_SIZE    0        // Can be zero
#define PADDING_CELL_MAX_SIZE    255      // Bytes

// Payment padding (dust)
#define DUST_PAYMENTS_PER_DAY    1000     // Target dust payments
#define DUST_PAYMENT_AMOUNT      1        // $0.01 (microcents)
```

---

## Path Selection Weights

```c
// Weight calculation
#define WEIGHT_STAKE_EXPONENT   0.7      // stake^0.7
#define WEIGHT_FEE_EXPONENT     2.0      // fee^2 (penalty)
#define WEIGHT_UPTIME_DAYS     30       // Uptime normalization

// Bandwidth weights
#define BW_WEIGHT_FLOOR         5120     // 5 KB/s minimum
#define BW_WEIGHT_CAP           10485760 // 10 MB/s cap

// Guard fraction
#define GUARD_FRACTION_MIN      0.20     // 20% of nodes
#define GUARD_FRACTION_MAX      0.40     // 40% of nodes
```

---

## Debug & Logging Constants

```c
// Log levels
#define LOG_DEBUG               0
#define LOG_INFO                1
#define LOG_NOTICE              2
#define LOG_WARN                3
#define LOG_ERROR               4

// Logging domains
#define LD_GENERAL              "GENERAL"
#define LD_NET                  "NET"
#define LD_CONFIG               "CONFIG"
#define LD_CRYPTO               "CRYPTO"
#define LD_HTLC                 "HTLC"
#define LD_CONSENSUS            "CONSENSUS"

// Tracing
#define TRACE                   1        // Enable trace logging
#define DEBUG_CELL              0        // Log all cells
```

---

## Compatibility Versions

```c
// Protocol versions
#define PROTO_VERSION_MIN       4
#define PROTO_VERSION_MAX       4
#define PROTO_VERSION_CURRENT   4

// Consensus methods
#define CONSENSUS_METHOD_MIN    27
#define CONSENSUS_METHOD_MAX    30
#define CONSENSUS_METHOD_CURRENT 28

// Supported link protocols
#define LINK_PROTO_MIN          2
#define LINK_PROTO_MAX          3        // 1=TLS 1.2, 2=TLS 1.3, 3=Noise_XX
```

---

## Security Thresholds

```c
// Path bias detection
#define PATH_BIAS_PERCENTAGE_WARN   25    // Warning at 25%
#define PATH_BIAS_PERCENTAGE_ABORT  10    // Abort at 10%
#define PATH_BISECT_THRESHOLD       5     // Extends b/w this

// DoS limits
#define DOS_CONN_PER_ADDRESS     4        // Max conns per IP
#define DOS_CONCURRENT_CONN_BONUS 32     // Allow bonus for good behavior
#define DOS_MAX_CIRCUITS_PER_SEC 10     // Max circuits per second

// Abuse detection
#define ABUSE_PORT_SCAN_THRESHOLD 3      // Flag after 3 port scans
#define ABUSE_DMCA_PER_DAY        1       // DMCA notice limit
#define ABUSE_SSH_BRUTE_PER_HOUR  12     // SSH brute force limit
```

---

## Unit Conversion Macros

```c
// Time conversions
#define MS_TO_US(ms)             ((ms) * 1000)
#define SEC_TO_MS(sec)           ((sec) * 1000)
#define SEC_TO_US(sec)           ((sec) * 1000000)
#define MIN_TO_SEC(min)          ((min) * 60)
#define HOURS_TO_SEC(hr)         ((hr) * 3600)
#define DAYS_TO_SEC(day)         ((day) * 86400)

// Microcent conversions (1 microcent = $0.00001)
#define USD_TO_MICROCENTS(usd)   ((uint64_t)((usd) * 100000))
#define MICROCENTS_TO_USD(uc)    (((uc) / 100.0) / 1000.0)
#define CENTS_TO_MICROCENTS(c)   ((c) * 10000)

// Basis points (1 bp = 0.01%)
#define BPS_TO_RATIO(bps)        ((bps) / 10000.0)
#define RATIO_TO_BPS(ratio)      ((int)((ratio) * 10000))

// Token conversions (1 BLF = $4.50)
#define BLF_TO_USD(blf)          ((blf) * 4.50)
#define USD_TO_BLF(usd)          ((usd) / 4.50)
```

---

## Summary Table: Critical Constants

| Category | Constant | Value | Notes |
|----------|----------|-------|-------|
| **Cell** | CELL_SIZE | 1,024 bytes | Fixed packet size |
| **Cell** | MAX_HTLCS_PER_CHANNEL | 483 | BOLT-03 limit |
| **Channel** | CHANNEL_LIFETIME_MAX | 21,600 sec | 6 hours |
| **Channel** | CHANNEL_MIN_CAPACITY | $500 | In microcents |
| **Guard** | GUARD_LIFETIME | 7,776,000 sec | 90 days |
| **Fees** | FEE_BPS_EXIT_MIN | 10 bp | 0.10% |
| **Fees** | FEE_BPS_SWIFT | 25 bp | 0.25% |
| **Stake** | MIN_STAKE_VR | 500K BLF | ~$2.25M |
| **Stake** | MIN_STAKE_SE | 2M BLF | ~$9M |
| **Crypto** | BLS12_381_G1_SIZE | 48 bytes | Pubkey |
| **Crypto** | BLS12_381_G2_SIZE | 96 bytes | Signature |
| **Network** | SHARD_COUNT | 127 | Total shards |
| **Network** | NOTARY_COUNT | 8 | Consensus authorities |
| **Timing** | CONSENSUS_INTERVAL | 10 sec | State root period |
| **Window** | PACKAGE_WINDOW_DEFAULT | 1,000 cells | Flow control |

---

*Back to [README.md](./README.md)*
</file>

<file path="frontend/CRYPTOGRAPHIC_DETAILS.md">
# Finallica Cryptographic Details

This document describes the payment cell flow, nested commitment unwrapping, and cryptographic primitives used in Finallica.

---

## Payment Cell Flow: Nested Commitment Unwrapping

### 6.1 Cell Structure & Encryption Layers

All Finallica payments use **3 layers of nested encryption** (one per hop):

```
Ciphertext = Encrypt_Guard(
  Encrypt_Middle(
    Encrypt_Exit(
      PaymentPayload + NextHopAddress + Amount
    )
  )
)
```

Each layer uses **ChaCha20-Poly1305** with independent keys derived via Noise_XX handshake.

### 6.2 Per-Hop Processing Diagram

```mermaid
graph LR
    subgraph "Finallica Proxy (Origin)"
        APP["User Payment<br/>$100.00 = 10,000,000 microcents<br/>BOLT-11 invoice"]
        COMMIT["Pedersen Commitment<br/>C = v*G + b*H<br/>v = 10,000,000<br/>b = random scalar<br/>33 bytes compressed"]
        RELAY_HDR["Payment Relay Header<br/>stream_id: 0x0042<br/>amount_commit: C<br/>expiry: 1706035200<br/>payment_hash: 0x1a2b...<br/>next_hop: 0x7d6c... (BLS)"]
        PLAINTEXT["Plaintext Payload: 867 bytes<br/>relay_hdr + invoice_data + padding"]

        ENCRYPT_EXIT["Encrypt with Exit Key K_exit<br/>ChaCha20-Poly1305<br/>nonce = 0..11<br/>auth_tag = 0..15"]
        ENCRYPT_MID["Encrypt with Middle Key K_mid<br/>ChaCha20-Poly1305"]
        ENCRYPT_GUARD["Encrypt with Guard Key K_guard<br/>ChaCha20-Poly1305"]

        CELL_FINAL["Final Cell<br/>channel_id=0x4f3e2d1c<br/>cmd=PAY (0x02)<br/>payload: 867 bytes onion-encrypted<br/>BLS sig: _payer (96 bytes)"]
    end

    subgraph "Guard VR (Hop 1)"
        G_RECV["DPDK RX<br/>mbuf ptr: 0x7f3a...<br/>Direct cell access"]
        G_PARSE["Parse: channel_id=0x4f3e2d1c, cmd=PAY"]
        G_DEC_GUARD["Decrypt layer 1<br/>ChaCha20-Poly1305 with K_guard<br/>Verify auth_tag<br/>0.002ms"]
        G_BLS["Verify BLS _payer<br/>Batch verify: 0.15ms<br/>Pedersen verify: 45ms"]
        G_RELAY["Parse relay_hdr<br/>amount_commit = C<br/>next_hop = 0x7d6c..."]
        G_BALANCE["Homomorphic subtract<br/>C_new = C_channel - C<br/>Verify C_new > 0"]
        G_FORWARD["Forward to Middle<br/>New channel_id=0x8a7b6c5d<br/>DPDK TX queue"]
    end

    subgraph "Middle VR (Hop 2)"
        M_RECV["DPDK RX<br/>channel_id=0x8a7b6c5d"]
        M_DEC_MID["Decrypt layer 2<br/>ChaCha20 with K_mid<br/>0.002ms"]
        M_RELAY["Parse: still encrypted<br/>next_hop = 0x9c8d..."]
        M_BALANCE["Update balance: -C<br/>Check expiry > block"]
        M_FORWARD["Forward to Exit<br/>channel_id=0x9c8d7e6f"]
    end

    subgraph "Settlement Executor (Hop 3)"
        E_RECV["DPDK RX<br/>channel_id=0x9c8d7e6f"]
        E_DEC_EXIT["Decrypt layer 3<br/>ChaCha20 with K_exit<br/>0.002ms"]
        E_RELAY_CLEAR["Relay header plaintext<br/>stream_id: 0x0042<br/>amount: 10M microcents<br/>payment_hash: 0x1a2b..."]
        E_LOOKUP["Lookup HTLC<br/>htlc_table_find(payment_hash)"]
        E_SETTLE["Initiate settlement<br/>SWIFT API call<br/>15,000ms"]
        E_PREIMAGE["Receive preimage from bank<br/>Reveal: preimage=0xfedcba..."]
        E_BLS_AGG["BLS aggregate settle sig<br/>_exit =  _i<br/>125ms for 64 payments"]
    end

    APP --> COMMIT
    COMMIT --> RELAY_HDR
    RELAY_HDR --> PLAINTEXT
    PLAINTEXT --> ENCRYPT_EXIT
    ENCRYPT_EXIT --> ENCRYPT_MID
    ENCRYPT_MID --> ENCRYPT_GUARD
    ENCRYPT_GUARD --> CELL_FINAL

    CELL_FINAL --> G_RECV
    G_DEC_GUARD --> G_BLS
    G_BLS --> G_RELAY
    G_RELAY --> G_BALANCE
    G_BALANCE --> G_FORWARD

    G_FORWARD --> M_RECV
    M_DEC_MID --> M_RELAY
    M_RELAY --> M_BALANCE
    M_BALANCE --> M_FORWARD

    M_FORWARD --> E_RECV
    E_DEC_EXIT --> E_RELAY_CLEAR
    E_RELAY_CLEAR --> E_LOOKUP
    E_LOOKUP --> E_SETTLE
    E_SETTLE --> E_PREIMAGE
    E_PREIMAGE --> E_BLS_AGG
```

---

## Pedersen Commitments

### 7.1 Commitment Scheme

**Pedersen commitments** hide payment amounts while allowing homomorphic operations:

```
C = v*G + b*H

where:
  C = commitment (33 bytes compressed)
  v = value (amount in microcents)
  G = secp256k1 generator point
  b = blinding factor (random scalar)
  H = second generator point (H = hash(G))
```

### 7.2 Commitment Creation

```c
secp256k1_pedersen_commitment commitment;
secp256k1_scalar blinding_factor;
secp256k1_scalar value;

// Set value
secp256k1_scalar_set_u64(&value, amount_microcents);

// Generate random blinding factor
randombytes_buf(&blinding_factor, 32);

// Create commitment
secp256k1_pedersen_commit(
  secp256k1_ctx,
  &commitment,
  &blinding_factor,
  amount_microcents,
  &secp256k1_generator_h
);

// Serialize to 33 bytes (compressed)
secp256k1_pedersen_commitment_serialize(
  &cell->commitment[0],
  &commitment
);
```

### 7.3 Homomorphic Operations

```c
// Subtract payment from channel balance
secp256k1_pedersen_commitment new_balance;
secp256k1_pedersen_commitment_negate(&payment_commit, &payment_commit);
secp256k1_pedersen_commitment_sum(
  &new_balance,
  (const secp256k1_pedersen_commitment *[]){
    &channel_balance,
    &payment_commit
  },
  2
);

// Verify balance is positive
bool is_positive = secp256k1_pedersen_commitment_verify_positive(&new_balance);
```

### 7.4 Range Proofs (Bulletproofs+)

To prevent negative amounts while keeping value hidden:

```c
// Generate range proof: 0  value < 2^64
secp256k1_bulletproofs_plus_proof bp_proof;
secp256k1_bulletproofs_plus_prove(
  secp256k1_ctx,
  &bp_proof,
  &commitment,
  &value,
  &blinding_factor,
  NULL,  // no additional commits
  0,     // n_additional_commits
  64,    // bit_range
  NULL   // custom_nonce
);

// Verification: 5-10ms (single), 0.5ms (batch 64)
bool valid = secp256k1_bulletproofs_plus_verify(
  secp256k1_ctx,
  &bp_proof,
  &commitment,
  NULL,
  0,
  64
);
```

---

## BLS12-381 Signatures

### 8.1 Key Generation

```c
bls_secret_key secret_key;
bls_public_key public_key;

// Generate
bls_bls_keygen(&secret_key, entropy, 32);

// Derive public key
bls_get_public_key(&public_key, &secret_key);

// Serialize (48 bytes compressed G1)
bls_public_key_serialize(&cell->bls_pubkey[0], &public_key);
```

### 8.2 Signing

```c
bls_signature signature;

// Sign commitment (33 bytes)
bls_sign(
  &signature,
  &secret_key,
  &cell->commitment[0],
  33,
  NULL  // no proof of possession
);

// Serialize (96 bytes G2)
bls_signature_serialize(&cell->bls_signature[0], &signature);
```

### 8.3 Verification (Single)

```c
bls_signature sig;
bls_public_key pk;
bls_signatureDeserialize(&sig, &cell->bls_signature[0], 96);
bls_public_keyDeserialize(&pk, &cell->bls_pubkey[0], 48);

bool valid = bls_verify(
  &sig,
  &pk,
  &cell->commitment[0],
  33
);
// Time: ~2-3ms (single)
```

### 8.4 Batch Verification

```c
// Aggregate 64 signatures for verification
bls_signature agg_sig;
bls_signature_aggregate(&agg_sig, signatures, 64);

// Verify all at once
bool valid = bls_fast_aggregate_verify(
  &agg_sig,
  public_keys,
  64,
  messages,
  message_lengths
);
// Time: ~0.15ms for 64 signatures (40x faster)
```

### 8.5 Signature Aggregation

Used by Exit VRs to aggregate settlement signatures:

```c
// Combine 64 payment signatures
bls_signature aggregated;
bls_signature_aggregate(&aggregated, settle_sigs, 64);

// Broadcast aggregated signature to notaries
bls_signature_serialize(&agg_sig_bytes[0], &aggregated);
```

---

## ChaCha20-Poly1305 Encryption

### 9.1 Key Derivation

```c
uint8_t chaining_key[32];
uint8_t pay_key[32];
uint8_t nonce[12];

// Extract phase
BLAKE2s(chaining_key, 32, NULL, 0,
        handshake_hash, BLAKE2S_OUTBYTES,
        "FinallicaExtract", 16);

// Expand phase (3 keys)
HKDF_BLAKE2s_Expand(pay_key, 32, chaining_key, 32,
                    "FinallicaPayKey", 15);
HKDF_BLAKE2s_Expand(settle_key, 32, chaining_key, 32,
                    "FinallicaSettleKey", 18);
HKDF_BLAKE2s_Expand(padding_key, 32, chaining_key, 32,
                    "FinallicaPaddingKey", 17);

// Initialize cipher
crypto_aead_chacha20poly1305_ietf_keygen(cipher_state, pay_key);
```

### 9.2 Encryption (Per Hop)

```c
// Nonce: 12-byte counter (incremented per cell)
uint64_t *nonce_counter = (uint64_t *)nonce;
*nonce_counter = cell_sequence;

// Encrypt payload
crypto_aead_chacha20poly1305_ietf_encrypt(
  cell->payload,        // ciphertext output
  &cell->payload_len,   // ciphertext length
  plaintext,            // plaintext input
  plaintext_len,        // plaintext length
  NULL,                 // additional data
  0,                    // AD length
  NULL,                 // nonce (set separately)
  cipher->key           // key
);

// Set nonce explicitly
memcpy(cell->nonce, nonce, 12);
```

### 9.3 Decryption (Per Hop)

```c
uint8_t plaintext[867];
size_t plaintext_len;

int result = crypto_aead_chacha20poly1305_ietf_decrypt(
  plaintext,              // plaintext output
  &plaintext_len,         // plaintext length
  NULL,                   // unused
  cell->payload,          // ciphertext
  cell->payload_len,      // ciphertext length
  cell->auth_tag,         // auth tag (16 bytes)
  cell->nonce,            // nonce (12 bytes)
  cipher->key             // key
);

if (result != 0) {
  // Authentication failed - reject cell
  channel_penalty(channel_id, 100);
  return;
}
```

---

## Key Rotation Schedule

| Key Type | Rotation Trigger | Max Lifetime |
|----------|-----------------|--------------|
| K_pay (Pay Cipher) | 2^20 cells OR 1 hour | ~1M cells |
| K_settle (Settle Cipher) | 2^20 cells OR 1 hour | ~1M cells |
| K_pad (Padding Cipher) | 1 hour (fixed) | 1 hour |
| Rekey Key | 6 hours | 6 hours |

**Rekeying Process** (in-band, zero-RTT):

```c
struct rekey_cell {
  uint8_t command: 0xFF;  // REKEY
  uint32_t channel_id;
  uint8_t new_ephemeral[32];  // X25519
  uint8_t signature[64];       // Ed25519(new_ephemeral || old_key || channel_id)
  uint8_t auth_tag[16];        // Poly1305
} __attribute__((packed));
```

---

## Cryptographic Performance

| Operation | Time (single) | Time (batch 64) |
|-----------|---------------|-----------------|
| ChaCha20-Poly1305 encrypt | 1.2 s | N/A |
| ChaCha20-Poly1305 decrypt | 1.2 s | N/A |
| BLS sign | 2-3 ms | N/A |
| BLS verify (single) | 2-3 ms | N/A |
| BLS verify (batch 64) | N/A | 0.15 ms |
| BLS aggregate (64) | 0.125 ms | N/A |
| Pedersen commit | 45 s | N/A |
| Bulletproofs+ prove | 780 s | N/A |
| Bulletproofs+ verify | 5-10 ms | 0.5 ms |
| X25519 scalar mult | 90 s | N/A |
| BLAKE2s hash | 25 s | N/A |

---

## Key Takeaways

1. **Nested Encryption**: 3 layers (Guard  Middle  Exit)
2. **Amount Hiding**: Pedersen commitments + Bulletproofs+ range proofs
3. **Stake Binding**: BLS12-381 signatures (batch verification 40x faster)
4. **Fast Symmetric**: ChaCha20-Poly1305 (1.2 s per hop)
5. **Key Rotation**: Every 1M cells or 1 hour (whichever first)

---

*Next: [LIQUIDITY_MANAGEMENT.md](./LIQUIDITY_MANAGEMENT.md) - Flow Control & Channel Windows*
</file>

<file path="frontend/index.html">
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Finallica Documentation System</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <div id="app">
        <!-- Header -->
        <header class="header">
            <div class="header-content">
                <h1 class="logo">
                    <span class="logo-icon"></span>
                    Finallica
                    <span class="logo-subtitle">Documentation System</span>
                </h1>
                <div class="header-actions">
                    <!-- Privacy Toggle -->
                    <div id="privacyToggleContainer" class="hidden">
                        <button id="privacyToggle" class="btn-privacy">
                            <span class="privacy-icon"></span>
                            <span class="privacy-label">Privacy Mode</span>
                        </button>
                    </div>
                    <button id="connectWallet" class="btn btn-primary">
                        <span class="btn-icon"></span>
                        Connect Wallet
                    </button>
                    <div id="walletInfo" class="wallet-info hidden">
                        <span class="wallet-address"></span>
                        <span class="wallet-balance"></span>
                    </div>
                </div>
            </div>
        </header>

        <!-- Main Layout -->
        <div class="main-container">
            <!-- Sidebar - Document Tree -->
            <aside class="sidebar">
                <div class="sidebar-header">
                    <h3>Documentation</h3>
                    <button id="refreshDocs" class="btn-icon" title="Refresh"></button>
                </div>
                <nav id="docTree" class="doc-tree">
                    <!-- Dynamically populated -->
                </nav>
            </aside>

            <!-- Main Content Area -->
            <main class="main-content">
                <!-- Document Viewer -->
                <div id="documentViewer" class="document-viewer">
                    <div class="doc-toolbar">
                        <div class="doc-breadcrumbs">
                            <span class="breadcrumb-item">docs</span>
                            <span class="breadcrumb-separator">/</span>
                            <span class="breadcrumb-item">finallica</span>
                            <span class="breadcrumb-separator">/</span>
                            <span id="currentDoc" class="breadcrumb-item active">README.md</span>
                        </div>
                        <div class="doc-actions">
                            <button id="editDoc" class="btn btn-secondary">
                                <span class="btn-icon"></span>
                                Edit
                            </button>
                            <button id="proposeChange" class="btn btn-primary">
                                <span class="btn-icon"></span>
                                Propose Change
                            </button>
                            <button id="viewHistory" class="btn btn-secondary">
                                <span class="btn-icon"></span>
                                History
                            </button>
                        </div>
                    </div>
                    <div id="docContent" class="doc-content">
                        <!-- Document content rendered here -->
                    </div>
                </div>

                <!-- Editor Panel (Hidden by default) -->
                <div id="editorPanel" class="editor-panel hidden">
                    <div class="editor-toolbar">
                        <h3 id="editorTitle">Edit Document</h3>
                        <div class="editor-actions">
                            <button id="previewChanges" class="btn btn-secondary">Preview</button>
                            <button id="saveEdit" class="btn btn-primary">Save</button>
                            <button id="cancelEdit" class="btn btn-secondary">Cancel</button>
                        </div>
                    </div>
                    <textarea id="docEditor" class="doc-editor" spellcheck="false"></textarea>
                    <div id="editPreview" class="edit-preview hidden"></div>
                </div>

                <!-- Proposals Panel -->
                <div id="proposalsPanel" class="proposals-panel hidden">
                    <div class="panel-header">
                        <h3>Active Proposals</h3>
                        <button id="newProposal" class="btn btn-primary">+ New Proposal</button>
                    </div>
                    <div id="proposalsList" class="proposals-list">
                        <!-- Dynamically populated -->
                    </div>
                </div>

                <!-- Consensus View -->
                <div id="consensusPanel" class="consensus-panel hidden">
                    <div class="panel-header">
                        <h3>Consensus State</h3>
                        <div class="consensus-stats">
                            <span class="stat">Block: <span id="currentBlock">0</span></span>
                            <span class="stat">Epoch: <span id="currentEpoch">0</span></span>
                            <span class="stat">Votes: <span id="totalVotes">0</span></span>
                        </div>
                    </div>
                    <div id="consensusContent" class="consensus-content">
                        <!-- Consensus data rendered here -->
                    </div>
                </div>
            </main>

            <!-- Right Panel - AI Chat & Voting -->
            <aside class="right-panel">
                <!-- Tab Navigation -->
                <div class="tab-navigation">
                    <button class="tab-btn active" data-tab="ai-chat">
                        <span class="tab-icon"></span>
                        AI Chat
                    </button>
                    <button class="tab-btn" data-tab="proposals">
                        <span class="tab-icon"></span>
                        Proposals
                        <span id="pendingCount" class="badge">0</span>
                    </button>
                    <button class="tab-btn" data-tab="consensus">
                        <span class="tab-icon"></span>
                        Consensus
                    </button>
                    <button class="tab-btn" data-tab="activity">
                        <span class="tab-icon"></span>
                        Activity
                    </button>
                    <button class="tab-btn" data-tab="privacy">
                        <span class="tab-icon"></span>
                        Privacy
                    </button>
                </div>

                <!-- Tab Contents -->
                <div class="tab-content">
                    <!-- AI Chat Tab -->
                    <div id="ai-chat" class="tab-pane active">
                        <div class="chat-header">
                            <h3>AI Assistant</h3>
                            <div id="aiModelSelector" class="ai-model-selector">
                                <!-- Provider and model selectors will be rendered here -->
                            </div>
                        </div>
                        <div id="chatMessages" class="chat-messages">
                            <div class="chat-message system">
                                <div class="message-content">
                                    Welcome to Finallica AI Assistant. Ask questions about the architecture, protocol, or any aspect of the system.
                                </div>
                            </div>
                        </div>
                        <div class="chat-input-container">
                            <textarea id="chatInput" class="chat-input" placeholder="Ask about Finallica..." rows="3"></textarea>
                            <div class="chat-actions">
                                <button id="sendChat" class="btn btn-primary">Send</button>
                                <button id="clearChat" class="btn btn-secondary">Clear</button>
                            </div>
                        </div>
                    </div>

                    <!-- Proposals Tab -->
                    <div id="proposals" class="tab-pane">
                        <div id="proposalsSummary" class="proposals-summary">
                            <!-- Summary cards -->
                        </div>
                        <div id="proposalsDetail" class="proposals-detail">
                            <!-- Detailed list -->
                        </div>
                    </div>

                    <!-- Consensus Tab -->
                    <div id="consensus" class="tab-pane">
                        <div class="consensus-overview">
                            <div class="consensus-metric">
                                <span class="metric-label">Total Stake</span>
                                <span class="metric-value" id="totalStake">0 BLF</span>
                            </div>
                            <div class="consensus-metric">
                                <span class="metric-label">Quorum</span>
                                <span class="metric-value" id="quorumStatus">Not Reached</span>
                            </div>
                            <div class="consensus-metric">
                                <span class="metric-label">Approval Rate</span>
                                <span class="metric-value" id="approvalRate">0%</span>
                            </div>
                        </div>
                        <div id="consensusList" class="consensus-list">
                            <!-- Voting items -->
                        </div>
                    </div>

                    <!-- Activity Tab -->
                    <div id="activity" class="tab-pane">
                        <div id="activityFeed" class="activity-feed">
                            <!-- Activity timeline -->
                        </div>
                    </div>

                    <!-- Privacy Tab -->
                    <div id="privacy" class="tab-pane">
                        <!-- Privacy Status -->
                        <div class="privacy-status-bar">
                            <div class="privacy-status">
                                <span class="privacy-status-dot"></span>
                                <span id="privacyStatusText">Privacy Service: Checking...</span>
                            </div>
                        </div>

                        <!-- Privacy Controls Panel -->
                        <div id="privacyControls" class="privacy-panel hidden">
                            <h3> Privacy Controls</h3>

                            <!-- Private Deposit Section -->
                            <div class="privacy-section">
                                <h4>Private Deposit</h4>
                                <p class="privacy-warning">
                                    Deposit funds into the privacy mixer. Your deposit will be mixed with others
                                    to break the on-chain link between sender and recipient.
                                </p>

                                <div class="form-group">
                                    <label>Token</label>
                                    <select id="privacyToken">
                                        <option value="ETH">ETH</option>
                                        <option value="BLF">BLF</option>
                                        <option value="USDC">USDC</option>
                                    </select>
                                </div>

                                <div class="form-group">
                                    <label>Amount</label>
                                    <select id="privacyAmount">
                                        <option value="0.1">0.1 ETH</option>
                                        <option value="1">1 ETH</option>
                                        <option value="10">10 ETH</option>
                                        <option value="100">100 BLF</option>
                                        <option value="1000">1000 BLF</option>
                                        <option value="10000">10000 BLF</option>
                                    </select>
                                </div>

                                <div class="privacy-actions">
                                    <button id="generatePrivacyNote" class="btn btn-secondary">
                                        <span class="btn-icon"></span>
                                        Generate Note
                                    </button>
                                </div>

                                <div class="form-group" style="margin-top: 1rem;">
                                    <label>Your Note (save this securely!)</label>
                                    <textarea id="privacyNoteDisplay" readonly rows="3" placeholder="Click 'Generate Note' to create a privacy deposit note..."></textarea>
                                    <div id="privacyFeeEstimate" style="margin-top: 0.5rem;"></div>
                                </div>

                                <div class="privacy-actions">
                                    <button id="executePrivateDeposit" class="btn btn-primary">
                                        <span class="btn-icon"></span>
                                        Deposit to Privacy Pool
                                    </button>
                                    <button id="copyPrivacyNote" class="btn btn-secondary">
                                        <span class="btn-icon"></span>
                                        Copy Note
                                    </button>
                                    <button id="saveNoteLocally" class="btn btn-secondary">
                                        <span class="btn-icon"></span>
                                        Save Note
                                    </button>
                                </div>
                            </div>

                            <div class="privacy-divider"></div>

                            <!-- Note Validation Section -->
                            <div class="privacy-section">
                                <h4>Validate Note</h4>
                                <p class="privacy-warning">
                                    Validate an existing privacy note to check if it's valid and view its details.
                                </p>

                                <div class="form-group">
                                    <label>Paste your note here</label>
                                    <input type="text" id="validateNoteInput" placeholder="tornado-ETH-0.1-..." />
                                </div>

                                <div id="noteValidationResult" style="display: none;"></div>

                                <div class="privacy-actions">
                                    <button id="validatePrivacyNote" class="btn btn-secondary">Validate Note</button>
                                </div>
                            </div>

                            <div class="privacy-divider"></div>

                            <!-- Saved Notes Section -->
                            <div class="privacy-section">
                                <h4>Saved Notes</h4>
                                <div id="savedNotesList" style="margin-top: 0.5rem;">
                                    <p class="text-muted">No saved notes</p>
                                </div>
                            </div>

                            <!-- Privacy Best Practices -->
                            <div class="privacy-info">
                                <h5>Privacy Best Practices:</h5>
                                <ul>
                                    <li>Wait at least a few hours between deposit and withdrawal</li>
                                    <li>Use a fresh address for withdrawals</li>
                                    <li>Don't deposit and withdraw predictable amounts</li>
                                    <li>Save your note securely - it's required to withdraw</li>
                                    <li>Never share your note with anyone</li>
                                </ul>
                            </div>

                            <!-- Privacy Disclaimer -->
                            <div class="privacy-disclaimer">
                                <strong>Privacy Disclaimer:</strong>
                                <ul>
                                    <li>Tornado Cash sanctions were lifted in March 2025, but regulations vary by jurisdiction</li>
                                    <li>Some exchanges may flag addresses that interact with mixers</li>
                                    <li>You are responsible for compliance with your local laws</li>
                                    <li>This is an optional privacy feature - nothing is mandatory</li>
                                </ul>
                            </div>
                        </div>
                    </div>
                </div>
            </aside>
        </div>
    </div>

    <!-- Proposal Modal -->
    <div id="proposalModal" class="modal hidden">
        <div class="modal-content">
            <div class="modal-header">
                <h2>Create Proposal</h2>
                <button id="closeModal" class="btn-close"></button>
            </div>
            <div class="modal-body">
                <form id="proposalForm">
                    <div class="form-group">
                        <label for="proposalTitle">Title</label>
                        <input type="text" id="proposalTitle" class="form-control" required>
                    </div>
                    <div class="form-group">
                        <label for="proposalType">Type</label>
                        <select id="proposalType" class="form-control">
                            <option value="document_edit">Document Edit</option>
                            <option value="new_section">New Section</option>
                            <option value="protocol_change">Protocol Change</option>
                            <option value="parameter_update">Parameter Update</option>
                        </select>
                    </div>
                    <div class="form-group">
                        <label for="proposalDoc">Document</label>
                        <select id="proposalDoc" class="form-control">
                            <!-- Populated dynamically -->
                        </select>
                    </div>
                    <div class="form-group">
                        <label for="proposalDiff">Changes (Diff Format)</label>
                        <textarea id="proposalDiff" class="form-control" rows="10" placeholder="--- a/file.md&#10;+++ b/file.md&#10;@@ -1,1 +1,2 @@&#10;- old line&#10;+ new line"></textarea>
                    </div>
                    <div class="form-group">
                        <label for="proposalRationale">Rationale</label>
                        <textarea id="proposalRationale" class="form-control" rows="4" placeholder="Explain why this change should be made..."></textarea>
                    </div>
                    <div class="form-group">
                        <label for="proposalStake">Stake Amount (BLF)</label>
                        <input type="number" id="proposalStake" class="form-control" min="1000" value="1000" required>
                        <small class="form-text">Minimum 1000 BLF stake required. This stake is locked until proposal is resolved.</small>
                    </div>
                </form>
            </div>
            <div class="modal-footer">
                <button id="submitProposal" class="btn btn-primary">Submit Proposal</button>
                <button id="cancelProposal" class="btn btn-secondary">Cancel</button>
            </div>
        </div>
    </div>

    <!-- Voting Modal -->
    <div id="votingModal" class="modal hidden">
        <div class="modal-content">
            <div class="modal-header">
                <h2>Vote on Proposal</h2>
                <button id="closeVotingModal" class="btn-close"></button>
            </div>
            <div class="modal-body">
                <div id="votingProposalDetails" class="voting-details">
                    <!-- Proposal details -->
                </div>
                <div class="voting-options">
                    <button id="voteFor" class="btn btn-success btn-large">
                        <span class="btn-icon"></span>
                        Vote For
                    </button>
                    <button id="voteAgainst" class="btn btn-danger btn-large">
                        <span class="btn-icon"></span>
                        Vote Against
                    </button>
                    <button id="voteAbstain" class="btn btn-secondary btn-large">
                        <span class="btn-icon"></span>
                        Abstain
                    </button>
                </div>
                <div class="voting-sliders">
                    <div class="slider-group">
                        <label>Stake Weight: <span id="stakeWeightValue">100</span>%</label>
                        <input type="range" id="stakeWeight" min="1" max="100" value="100">
                    </div>
                </div>
            </div>
        </div>
    </div>

    <!-- Toast Notifications -->
    <div id="toastContainer" class="toast-container"></div>

    <!-- Scripts -->
    <script src="app.js"></script>
</body>
</html>
</file>

<file path="frontend/LIQUIDITY_MANAGEMENT.md">
# Finallica Liquidity Management

This document describes the flow control mechanisms, channel windows, and liquidity rebalancing in Finallica.

---

## Channel Capacity Windows

### 7.1 Sender-Side Flow Control

```mermaid
graph TB
    subgraph "Channel Capacity Window (Sender Side)"
        FP_SEND["FP sends PAY cell<br/>channel->available_to_send -= amount"]
        FP_WINDOW["Initial: $25,000<br/>After $100 payment: $24,900<br/>Window = $24,900"]
        FP_BLOCK["Block when window < min_payment<br/>min_payment = $1.00<br/>Return INSUFFICIENT_LIQUIDITY"]

        E_SETTLE["Exit settles HTLC<br/>Preimage revealed<br/>Settlement confirmed"]
        E_ACK["Exit sends SETTLE_ACK<br/>channel->available_to_send += amount<br/>Window = $24,900 + $100 = $25,000"]
    end

    FP_SEND --> FP_WINDOW
    FP_WINDOW --> FP_BLOCK
    E_SETTLE --> E_ACK
```

### Channel Window Structure

```c
struct channel_window {
  int64_t available_to_send;   // Payer's liquidity (microcents)
  int64_t available_to_recv;   // Payee's settlement capacity
  uint32_t max_inflight_htlcs; // Default: 483 (BOLT-03 limit)
  uint64_t min_payment;        // $1.00 = 100,000 microcents
};

// Default initialization
struct channel_window default_window = {
  .available_to_send = 25000000,    // $25,000
  .available_to_recv = 25000000,
  .max_inflight_htlcs = 483,
  .min_payment = 100000
};
```

### Window Update Logic

```c
// When sending payment
bool can_send_payment(struct channel *chan, uint64_t amount) {
  if (chan->window.available_to_send < amount + chan->window.min_payment) {
    return false;  // Would drop below minimum
  }
  if (chan->htlc_count >= chan->window.max_inflight_htlcs) {
    return false;  // Too many inflight HTLCs
  }
  return true;
}

// Deduct from window
void deduct_from_window(struct channel *chan, uint64_t amount) {
  chan->window.available_to_send -= amount;
  chan->htlc_count++;
}

// Refund on settlement
void refund_window(struct channel *chan, uint64_t amount) {
  chan->window.available_to_send += amount;
  chan->htlc_count--;
}
```

---

## HTLC Slot Windows

### 7.2 Per-Channel HTLC Limits

```mermaid
graph TB
    subgraph "HTLC Slot Window (Per-Channel)"
        M_RECV["VR receives PAY<br/>Check htlc_table->count"]
        M_SLOTS["HTLC slots: 483 max<br/>Used: 482<br/>Free: 1"]
        M_BLOCK["Reject when slots = 0<br/>Return MAX_HTLCS_EXCEEDED"]

        M_SETTLE["HTLC settles<br/>htlc_table_free(entry)<br/>count--: 482"]
    end

    M_RECV --> M_SLOTS
    M_SLOTS --> M_BLOCK
    M_SETTLE --> M_SLOTS
```

### HTLC Table Management

```c
#define HTLC_MAX_PER_CHANNEL 483

struct htlc_table {
  htlc_entry_t *entries[HTLC_MAX_PER_CHANNEL];
  uint16_t count;
  bitarray_t *used_slots;  // 483 bits
};

// Allocate HTLC slot
htlc_entry_t *htlc_allocate(struct htlc_table *table) {
  if (table->count >= HTLC_MAX_PER_CHANNEL) {
    return NULL;  // Table full
  }

  // Find free slot
  for (int i = 0; i < HTLC_MAX_PER_CHANNEL; i++) {
    if (!bitarray_test(table->used_slots, i)) {
      bitarray_set(table->used_slots, i);
      table->entries[i] = calloc(1, sizeof(htlc_entry_t));
      table->count++;
      return table->entries[i];
    }
  }

  return NULL;
}

// Free HTLC slot
void htlc_free(struct htlc_table *table, htlc_entry_t *entry) {
  int index = entry->index;
  bitarray_clear(table->used_slots, index);
  free(table->entries[index]);
  table->entries[index] = NULL;
  table->count--;
}
```

---

## Rate Limiting (Per-Stream)

### 7.3 Token Bucket Rate Limiter

```mermaid
graph TB
    subgraph "Rate Limiting (Per-Stream)"
        P_STREAM["Payment stream<br/>stream_id=0x0042"]
        R_BUCKET["Token bucket<br/>rate = 1000 cells/sec<br/>burst = 100 cells"]
        R_DROP["Drop when tokens = 0<br/>Send NACK upstream"]

        R_TOKENS["Ack received<br/>tokens += 100<br/>Max: 1000"]
    end

    P_STREAM --> R_BUCKET
    R_BUCKET --> R_DROP
    R_TOKENS --> R_BUCKET
```

### Token Bucket Implementation

```c
struct token_bucket {
  uint64_t rate;         // tokens per second
  uint64_t burst;        // max tokens
  uint64_t tokens;       // current tokens
  uint64_t last_update;  // timestamp (s)
};

// Check if tokens available
bool token_bucket_consume(struct token_bucket *bucket, uint64_t tokens) {
  uint64_t now = get_time_us();
  uint64_t elapsed = now - bucket->last_update;

  // Refill based on elapsed time
  bucket->tokens += (elapsed * bucket->rate) / 1000000;
  if (bucket->tokens > bucket->burst) {
    bucket->tokens = bucket->burst;
  }
  bucket->last_update = now;

  // Check if enough tokens
  if (bucket->tokens < tokens) {
    return false;  // Rate limited
  }

  bucket->tokens -= tokens;
  return true;
}

// Add tokens on ACK
void token_bucket_add(struct token_bucket *bucket, uint64_t tokens) {
  bucket->tokens += tokens;
  if (bucket->tokens > bucket->burst) {
    bucket->tokens = bucket->burst;
  }
}
```

### Rate Limits by Stream Type

| Stream Type | Rate | Burst |
|-------------|------|-------|
| Normal payments | 1,000 cells/sec | 100 cells |
| High-priority | 5,000 cells/sec | 500 cells |
| Settlement | 10,000 cells/sec | 1,000 cells |
| Padding | 1 cell/sec | 10 cells |

---

## Cross-Shard Liquidity Rebalancing

### 7.4 Atomic Swap Protocol

```mermaid
graph TB
    subgraph "Cross-Shard Liquidity Rebalancing"
        SHARD_0["Shard 0<br/>Channel: $500 capacity<br/>Used: $425 (85%)"]
        SHARD_1["Shard 1<br/>Channel: $500 capacity<br/>Used: $75 (15%)"]
        BRIDGE["Atomic Swap<br/>HTLAS protocol<br/>3-second lock time"]

        SHARD_0 -->|Swap $200| BRIDGE
        BRIDGE -->|Swap $200| SHARD_1
        SHARD_0 -->|New balance: $225| SHARD_0
        SHARD_1 -->|New balance: $275| SHARD_1
    end
```

### HTLAS (Hashed Timelock Atomic Swap) Protocol

```c
struct htlas_swap {
  uint64_t amount;
  uint8_t payment_hash[32];
  uint32_t timeout_block;  // 3 seconds = ~15 blocks
  bls_pubkey_t shard_a_pubkey;
  bls_pubkey_t shard_b_pubkey;
};

// Step 1: Shard A creates HTLC
bool shard_a_create_htlc(struct htlas_swap *swap) {
  // Lock funds on Shard A
  htlc_entry_t *htlc = htlc_allocate(&shard_a->htlc_table);
  htlc->amount = swap->amount;
  htlc->payment_hash = swap->payment_hash;
  htlc->expiry = current_block + swap->timeout_block;

  // Broadcast to Shard B via bridge
  bridge_send_htlc(swap);
  return true;
}

// Step 2: Shard B creates mirrored HTLC
bool shard_b_create_htlc(struct htlas_swap *swap) {
  // Lock funds on Shard B (refundable if timeout)
  htlc_entry_t *htlc = htlc_allocate(&shard_b->htlc_table);
  htlc->amount = swap->amount;
  htlc->payment_hash = swap->payment_hash;
  htlc->expiry = current_block + swap->timeout_block;
  return true;
}

// Step 3: Reveal preimage, claim both HTLCs
bool claim_htlc(struct htlas_swap *swap, uint8_t *preimage) {
  // Verify preimage matches hash
  if (SHA256(preimage) != swap->payment_hash) {
    return false;
  }

  // Claim on Shard A
  shard_a_claim_htlc(swap, preimage);

  // Claim on Shard B
  shard_b_claim_htlc(swap, preimage);

  return true;
}

// Step 4: Refund if timeout
bool refund_htlc(struct htlas_swap *swap) {
  if (current_block < swap->timeout_block) {
    return false;  // Not yet expired
  }

  // Refund both HTLCs
  shard_a_refund_htlc(swap);
  shard_b_refund_htlc(swap);
  return true;
}
```

### Rebalancing Trigger Conditions

| Condition | Threshold | Action |
|-----------|-----------|--------|
| High utilization | >85% capacity | Rebalance OUT |
| Low utilization | <15% capacity | Rebalance IN |
| Rebalance amount | Min $50, Max $500 | Atomic swap |
| Lock time | 3 seconds (15 blocks) | HTLAS timeout |

---

## Liquidity Fee Structure

### 7.5 Dynamic Fee Calculation

Fees increase with channel utilization:

```c
uint64_t calculate_liquidity_fee(
  uint64_t amount,
  struct channel *chan) {

  double utilization = (double)chan->used / chan->capacity;

  // Fee multiplier: 1.0x at 0%, 1.5x at 85%, 2.5x at 95%
  double multiplier = 1.0 + pow(utilization / 0.9, 4);

  // Base rate: 2 bps
  uint64_t fee = amount * 0.0002 * multiplier;

  return fee;
}
```

### Fee Examples

| Utilization | Multiplier | Fee on $100 |
|-------------|------------|-------------|
| 0% | 1.0x | $0.02 |
| 50% | 1.1x | $0.022 |
| 85% | 1.5x | $0.03 |
| 90% | 1.8x | $0.036 |
| 95% | 2.7x | $0.054 |

---

## Channel Rebalance Threshold

```c
#define REBALANCE_THRESHOLD_HIGH 0.85  // 85%
#define REBALANCE_THRESHOLD_LOW  0.15  // 15%
#define REBALANCE_MIN_AMOUNT    50000000  // $50
#define REBALANCE_MAX_AMOUNT    500000000 // $500

void check_rebalance_needed(struct channel *chan) {
  double utilization = (double)chan->used / chan->capacity;

  if (utilization > REBALANCE_THRESHOLD_HIGH) {
    // Need to rebalance OUT
    uint64_t amount = (chan->used - (chan->capacity * 0.6));
    amount = MAX(amount, REBALANCE_MIN_AMOUNT);
    amount = MIN(amount, REBALANCE_MAX_AMOUNT);

    initiate_rebalance(chan, amount, REBALANCE_OUT);
  }
  else if (utilization < REBALANCE_THRESHOLD_LOW) {
    // Need to rebalance IN
    uint64_t amount = ((chan->capacity * 0.4) - chan->used);
    amount = MAX(amount, REBALANCE_MIN_AMOUNT);
    amount = MIN(amount, REBALANCE_MAX_AMOUNT);

    initiate_rebalance(chan, amount, REBALANCE_IN);
  }
}
```

---

## Key Takeaways

1. **Channel Windows**: $25,000 default capacity, 483 HTLC slots max
2. **Rate Limiting**: Token bucket, 1,000 cells/sec per stream
3. **Rebalancing**: Atomic swaps at 85%/15% thresholds
4. **Dynamic Fees**: Increase with utilization (1x  2.7x)
5. **HTLAS Protocol**: 3-second lock time for cross-shard swaps

---

*Next: [CONSENSUS_MECHANISM.md](./CONSENSUS_MECHANISM.md) - HotStuff BFT Protocol*
</file>

<file path="frontend/OPERATIONAL_METRICS.md">
# Finallica Operational Metrics

This document provides the live production metrics and operational dashboards for the Finallica network.

---

## Client FP Metrics

### Finallica Proxy (Wallet Side)

```mermaid
graph TB
    subgraph "Client FP Metrics"
        C_CIRC["Active Channels: 12<br/>Building: 1<br/>Closed (24h): 8<br/>Reuse rate: 94%"]
        C_STREAM["Payment Streams: Active: 34<br/>Inflight HTLCs: 127<br/>Avg per channel: 2.8"]
        C_BW["Bandwidth: TX: 2.8 MB/s<br/>RX: 1.9 MB/s<br/>Padding overhead: 22%<br/>Dust payments: 1,200/day"]
        C_LATENCY["Latency: Channel build: 340ms p95<br/>Payment RTT: 580ms<br/>Guard RTT: 42ms<br/>Settlement: 1.8 days SWIFT"]
        C_FEES["Fees (24h): Total paid: $18.42<br/>Avg per payment: $0.31<br/>Routing: $0.12<br/>Settlement: $0.18<br/>Liquidity: $0.01"]
    end
```

### FP Statistics Breakdown

| Metric | Value | Notes |
|--------|-------|-------|
| **Channels** | | |
| Active | 12 | Currently usable |
| Building | 1 | In handshake phase |
| Closed (24h) | 8 | Natural expiration |
| Reuse Rate | 94% | High efficiency |
| **Streams** | | |
| Active Streams | 34 | Concurrent payments |
| Inflight HTLCs | 127 | Pending settlement |
| Avg/Channel | 2.8 | Stream multiplexing |
| **Bandwidth** | | |
| TX Rate | 2.8 MB/s | Outbound traffic |
| RX Rate | 1.9 MB/s | Inbound traffic |
| Padding Overhead | 22% | Privacy cost |
| Dust Payments | 1,200/day | $0.01 each |
| **Latency** | | |
| Channel Build (p50) | 127ms | Median |
| Channel Build (p95) | 340ms | 95th percentile |
| Payment RTT | 580ms | Round-trip time |
| Guard RTT | 42ms | Entry hop latency |
| Settlement Time | 1.8 days | SWIFT average |
| **Fees (24h)** | | |
| Total Paid | $18.42 | All payments |
| Avg Per Payment | $0.31 | 0.31% of $100 |
| Routing Fee | $0.12 | 3 hops  2-5 bps |
| Settlement Fee | $0.18 | SWIFT rail |
| Liquidity Fee | $0.01 | Dynamic |

---

## Guard VR Metrics

### VR-0-015 (Example Guard Node)

```mermaid
graph TB
    subgraph "Guard VR-0-015 Metrics"
        G_CIRC["Active Channels: 5,823<br/>Client conns: 5,823<br/>VR-to-VR: 2,406<br/>Total: 8,229"]
        G_CONN["DPDK Flows: 8,229 / 1,048,576<br/>UDP port 31337<br/>TCP port 31338: 2,406"]
        G_CPU["CPU: 16 cores @ 98%<br/>ChaCha20: 18,200 ops/sec<br/>BLS verify: 4,800 sigs/sec<br/>Load avg: 15.8"]
        G_NET["Network: RX: 45.2 Gbps<br/>TX: 46.1 Gbps<br/>Drops: 0.0008%<br/>Retrans: 0% UDP"]
        G_PAY["Payments: 12,847 last epoch<br/>Success: 99.91%<br/>Avg fee revenue: 2.1 bps = $2,697/epoch"]
    end
```

### Guard VR Statistics

| Metric | Value | Capacity |
|--------|-------|----------|
| **Connections** | | |
| Active Channels | 5,823 | Max: 15,000 |
| Client Connections | 5,823 | |
| VR-to-VR Peers | 2,406 | Shard size |
| Total Flows | 8,229 | DPDK max: 1,048,576 |
| **CPU** | | |
| Core Utilization | 98% | 16 cores @ 3.5 GHz |
| ChaCha20 Ops/sec | 18,200 | Max: 25,000 |
| BLS Verify/sec | 4,800 | Max: 64,000 |
| Load Average | 15.8 | |
| **Network** | | |
| RX Throughput | 45.2 Gbps | NIC: 100 Gbps |
| TX Throughput | 46.1 Gbps | |
| Packet Drops | 0.0008% | |
| Retransmissions | 0% | UDP (no retrans) |
| **Payments** | | |
| Per Epoch | 12,847 | |
| Success Rate | 99.91% | |
| Fee Revenue | $2,697/epoch | 2.1 bps avg |

---

## Settlement Executor Metrics

### SE-0-12 (Example Exit Node)

```mermaid
graph TB
    subgraph "Settlement SE-0-12 Metrics"
        E_STREAM["Active Settlements: 1,247<br/>SWIFT: 892<br/>ACH: 324<br/>BTC: 31<br/>LN: 0"]
        E_API["API Rate: SWIFT: 8.9 req/sec<br/>ACH: 32.4 req/sec<br/>Quota: 10/100 req/sec<br/>429 errors: 0.02%"]
        E_MEM["Memory: Used: 4.2 GB<br/>Per-settlement: 3.4 MB<br/>Buffers: 2.1 GB<br/>OOM risk: Low"]
        E_ABUSE["Abuse: Failed settlements: 3<br/>AML flags: 12<br/>Fraud score: 0.8%<br/>Frozen: $12,400"]
    end
```

### Settlement Executor Statistics

| Metric | Value | Capacity |
|--------|-------|----------|
| **Active Settlements** | | |
| SWIFT | 892 | 60% of total |
| ACH | 324 | 26% of total |
| Bitcoin | 31 | 2.5% of total |
| Lightning | 0 | 0% |
| Total | 1,247 | Max: 2,000 |
| **API Rates** | | |
| SWIFT (req/sec) | 8.9 | Quota: 10 |
| ACH (req/sec) | 32.4 | Quota: 100 |
| 429 Errors | 0.02% | Rate limit rejects |
| **Memory** | | |
| Used | 4.2 GB | Max: 8 GB |
| Per Settlement | 3.4 MB | |
| Buffers | 2.1 GB | TX/RX queues |
| OOM Risk | Low | < 50% |
| **Abuse** | | |
| Failed Settlements | 3 | Per day |
| AML Flags | 12 | Suspicious activity |
| Fraud Score | 0.8% | Flagged rate |
| Frozen Amount | $12,400 | Pending review |

---

## Network Health Dashboard

### Global Statistics (Epoch 18492)

```mermaid
graph TB
    subgraph "Network Health"
        N_CONS["Consensus: Age: 7 sec<br/>Signatures: 8/8<br/>Next in: 3 sec<br/>HotStuff QCs: 1,605/2,400 votes"]
        N_EPOCH["Epoch 18492<br/>Payments: 38.4M<br/>Value: $4.27B<br/>Avg payment: $111.20"]
        N_STAKE["Staked: 18.43M BLF $82.9B<br/>Slashed: 45,000 BLF $202K<br/>Inflation: 2,301 BLF/epoch $10K"]
        N_USERS["Estimated Users: 4.2M daily<br/>Active wallets: 1.8M<br/>Channels opened: 52K/day"]
    end
```

### Network Health Statistics

| Category | Metric | Value |
|----------|--------|-------|
| **Consensus** | | |
| State Root Age | 7 sec | Refresh interval: 10 sec |
| Notary Signatures | 8/8 | All notaries signed |
| Next State Root | 3 sec | Countdown |
| HotStuff Quorum | 1,605/2,400 | 67% threshold met |
| **Epoch** | | |
| Epoch Number | 18492 | |
| Total Payments | 38.4M | Per epoch (10 sec) |
| Total Value | $4.27B | Settlement value |
| Avg Payment | $111.20 | |
| **Staking** | | |
| Total Staked | 18.43M BLF | $82.9B USD |
| Staked Supply | 87.8% | Of total 21M BLF |
| Slashed (24h) | 45,000 BLF | $202K USD |
| Inflation Reward | 2,301 BLF | Per epoch (~$10K) |
| **Users** | | |
| Daily Users | 4.2M | Estimated |
| Active Wallets | 1.8M | With balance |
| Channels Opened | 52K/day | New channels |

---

## Fee Structure Breakdown

### $100 Payment Example

```

                      $100.00 Payment                    

 Routing Fees (Guard + Middle + Exit VR)               
   Guard VR (15.7M stake, 2 bps):     $0.020           
   Middle VR (6.3M stake, 3 bps):     $0.030           
   Exit SE (12.3M stake, 25 bps):     $0.250           
   Subtotal:                          $0.300           
                                                        
 Settlement Rail Fee (SWIFT MT103)                     
   Intermediary bank:                 $0.150           
   Correspondent fee:                 $0.100           
   Subtotal:                          $0.250           
                                                        
 Liquidity Fee (85% utilization penalty)               
   Base rate (2 bps)  1.5:          $0.030           
                                                        
 Payment Padding (Privacy overhead)                    
   1,200 dust cells/day  34 payments  $0.352          
                                                        
 Total Fees:                          $0.932           
                                                        
 Beneficiary Receives:                $99.068          
                                                        
 Settlement Time: 1.8 days (SWIFT)                     
 Privacy: 1-in-1,200 anonymity set                     

```

### Fee Distribution by Component

| Component | Fee | Percentage |
|-----------|-----|------------|
| Guard VR | $0.020 | 2.1% |
| Middle VR | $0.030 | 3.2% |
| Exit SE | $0.250 | 26.8% |
| SWIFT Bank | $0.250 | 26.8% |
| Liquidity | $0.030 | 3.2% |
| Padding | $0.352 | 37.8% |
| **Total** | **$0.932** | **100%** |

---

## Performance Baselines

### Target vs Actual Performance

| Metric | Target | Actual (p50) | Status |
|--------|--------|--------------|--------|
| Channel Build | 200-500ms | 127ms |  Better |
| Payment RTT | 600ms | 580ms |  On target |
| Consensus Finality | 200ms | 200ms |  On target |
| Cell Processing | 0.8 s | 0.76 s |  On target |
| TPS per Shard | 10,000 | 8,423 |  Below target |
| SWIFT Settlement | 2 days | 1.8 days |  Better |
| Success Rate | 99.5% | 99.91% |  Better |

---

## Key Takeaways

1. **FP Metrics**: 12 channels, 34 active streams, $0.31 avg fee
2. **Guard VR**: 5,823 channels, 98% CPU, 45 Gbps throughput
3. **Settlement SE**: 1,247 active settlements, SWIFT 8.9 req/sec
4. **Network Health**: 4.2M daily users, $4.27B/epoch volume
5. **Fees**: $0.932 on $100 payment (0.93% total)

---

*Next: [TOR_FINALLIKA_MAPPING.md](./TOR_FINALLIKA_MAPPING.md) - Complete Analogy Reference*
</file>

<file path="frontend/PERFORMANCE_ANALYSIS.md">
# Finallica Performance Analysis

This document provides a detailed breakdown of CPU, memory, and network bottlenecks in the Finallica system.

---

## CPU Flame Graph: $100 Payment Processing Cost

### Total CPU Time: 1,847 s per payment

```mermaid
graph TD
    subgraph "Total CPU Time: 1,847 s per payment"
        subgraph "Entry VR (Client  Guard): 1,198 s"
            E_TLS["TLS 1.3 handshake: 850 s<br/>ECDSA P-256 verify: 320 s<br/>X25519 key schedule: 180 s<br/>Kernel copy_user: 350 s"]
            E_NOISE["Noise_XX handshake: 230 s<br/>X25519 scalar mult: 90 s<br/>BLAKE2s Hash: 25 s<br/>BLS verify (batch): 105 s<br/>HKDF Expand: 10 s"]
            E_PAY["BLS sign payment: 110 s<br/>Pedersen commitment: 45 s<br/>Range proof (Bulletproofs+): 780 s<br/>SHA256(payment_hash): 0.5 s"]
            E_ROUTE["Path selection: 12 s<br/>Routerlist lookup: 4 s<br/>Stake weight calc: 8 s"]
            E_CELL["Cell crypto: 2 s<br/>ChaCha20 (AVX2): 1.2 s<br/>Poly1305: 0.8 s"]
        end

        subgraph "Middle VR (Hop 2): 4 s"
            M_DEC["Decrypt/verify: 3 s<br/>ChaCha20: 1.2 s<br/>Poly1305: 0.8 s<br/>BLS batch: 0.15 s<br/>Digest update: 0.85 s"]
            M_FWD["Forward cell: 1 s<br/>rte_ring_enqueue: 0.5 s<br/>KIST schedule: 0.5 s"]
        end

        subgraph "Exit VR (Settlement): 15,231 s"
            X_SETTLE["SWIFT MT103: 15,000 s<br/>API call: 14,800 s<br/>Response parse: 200 s"]
            X_BLS["BLS aggregate: 125 s<br/>Combine 64 settlement sigs"]
            X_STATE["State root update: 106 s<br/>Merkle trie: 80 s<br/>HotStuff propose: 26 s"]
        end
    end

    E_TLS --> E_NOISE
    E_NOISE --> E_PAY
    E_PAY --> E_ROUTE
    E_ROUTE --> E_CELL

    M_DEC --> M_FWD

    style X_SETTLE fill:#f66
    style E_PAY fill:#fb0
```

### CPU Breakdown by Component

| Component | Time (s) | Percentage | Bottleneck |
|-----------|-----------|------------|------------|
| **Entry VR** | 1,198 | 65% | TLS + BLS + Pedersen |
| TLS 1.3 | 850 | 46% | ECDSA verify |
| Noise_XX | 230 | 12% | X25519 |
| BLS operations | 110 | 6% | Pairing operations |
| Pedersen + Range Proof | 825 | 45% | Bulletproofs+ |
| **Middle VR** | 4 | 0.2% | Minimal overhead |
| **Exit VR** | 15,231 | 82% | SWIFT API dominates |
| SWIFT API | 15,000 | 81% | External call |
| BLS aggregate | 125 | 0.7% | Batch operations |
| State update | 106 | 0.6% | Merkle trie |

### Optimization Opportunities

| Bottleneck | Current | Optimized | Improvement |
|------------|---------|-----------|-------------|
| TLS 1.3 handshake | 850 s | 0-RTT resumption | 85% |
| Bulletproofs+ verify | 780 s | Batch verify (64) | 70% |
| BLS verify | 105 s | Pre-computed pairings | 40% |
| SWIFT API | 15,000 s | Async + caching | N/A (external) |

---

## Memory Allocation: Per-Channel Resource Consumption

### Total: 40,736 bytes per channel

```mermaid
graph LR
    subgraph "Heap Memory per Channel (40,736 bytes)"
        C_STATE["Channel State<br/>struct channel_t<br/>224 bytes<br/>{channel_id, state, peer_pubkey, stake}"]

        subgraph "Cryptographic Keys (1,536 bytes)"
            K_PAY["Pay Cipher<br/>crypto_aead_state<br/>ChaCha20-Poly1305<br/>32-byte key + 12-byte nonce<br/>256 bytes"]
            K_SETTLE["Settle Cipher<br/>crypto_aead_state<br/>256 bytes"]
            K_PAD["Pad Cipher<br/>crypto_aead_state<br/>256 bytes"]
            K_REKEY["Rekey Key<br/>uint8_t[32]<br/>32 bytes"]
            K_HANDSHAKE["Noise Handshake State<br/>handshake_state_t<br/>384 bytes"]
            K_BLS["BLS Keypair<br/>bls_secret_key<br/>32 bytes + 48 bytes pubkey<br/>80 bytes"]
            K_PED["Pedersen Blinding<br/>secp256k1_scalar<br/>32 bytes"]
        end

        subgraph "HTLC Table (30,912 bytes)"
            HTLC["HTLC Entry Array<br/>struct htlc[HTLC_MAX_PER_CHANNEL]<br/>483 entries  64 bytes<br/>{payment_hash, amount, expiry, status}"]
        end

        subgraph "Queue Buffers (4,096 bytes)"
            Q_IN["Input Ring<br/>rte_ring<br/>1024 entries  4 bytes<br/>Lockless producer-consumer"]
            Q_OUT["Output Ring<br/>rte_ring<br/>1024 entries  4 bytes"]
        end

        subgraph "Replay Protection (8,192 bytes)"
            REPLAY["Bloom Filter<br/>cell_sequence cache<br/>10,000 bits<br/>FP rate: 0.1%"]
        end

        subgraph "Path State (640 bytes)"
            P_GUARD["Guard Info<br/>entry_guard_t pointer<br/>128 bytes"]
            P_MIDDLE["Middle VR List<br/>smartlist_t *vrs<br/>64 bytes + 3 pointers"]
        end
    end

    C_STATE --> K_PAY
    C_STATE --> K_SETTLE
    C_STATE --> HTLC
    K_PAY --> K_REKEY
    HTLC --> Q_IN
    Q_OUT --> REPLAY
```

### Memory Breakdown

| Component | Size (bytes) | Percentage |
|-----------|--------------|------------|
| Channel State | 224 | 0.5% |
| Cryptographic Keys | 1,536 | 3.8% |
| HTLC Table | 30,912 | 75.9% |
| Queue Buffers | 4,096 | 10.1% |
| Replay Protection | 8,192 | 2.0% |
| Path State | 640 | 1.6% |
| Overhead | 224 | 0.5% |
| **Total** | **40,736** | **100%** |

### Channel Capacity by Memory

| Memory | Max Channels | Notes |
|--------|--------------|-------|
| 4 GB | ~98,000 | Theoretical (no overhead) |
| 8 GB | ~150,000 | Practical max |
| 16 GB | ~250,000 | High-end VR |
| 64 GB | ~1,000,000 | With kernel + stack |

**OOM Killer**: Activates at 90% memory usage, closes lowest-capacity channels first.

---

## Network Saturation: Shard Capacity Limits

### Guard VR Capacity (100 Gbps NIC)

```mermaid
graph TB
    subgraph "Shard 0 Capacity (Guard VR: 100 Gbps NIC)"
        G_BW_TOTAL["Total Bandwidth: 100 Gbps<br/>12.5 GB/s theoretical"]

        subgraph "Traffic Breakdown"
            G_BW_CLIENT["Client Uplinks: 25%<br/>3.125 GB/s<br/>50,000 concurrent FP connections<br/>Avg: 62.5 Mbps per FP"]
            G_BW_VR["VR-to-VR (Data Plane): 55%<br/>6.875 GB/s<br/>2,406 VR peers  2.86 Gbps each"]
            G_BW_BRIDGE["Cross-Shard Bridges: 10%<br/>1.25 GB/s<br/>120 bridges  10.4 Gbps each"]
            G_BW_CONTROL["Consensus/Control: 5%<br/>0.625 GB/s<br/>TLS 1.3, port 31338"]
            G_BW_PADDING["Payment Padding: 5%<br/>0.625 GB/s<br/>Constant 1 cell/sec per channel"]
        end

        G_CONN_LIMIT["Connection Limits<br/>DPDK max flows: 1,048,576<br/>Actual: 50,000 client + 2,406 VR = 52,406<br/>Per-flow memory: 128 bytes"]
        G_CPU_LIMIT["CPU Saturation<br/>16 cores @ 3.5 GHz<br/>Max ChaCha20: 25M cells/sec (AVX2)<br/>Max BLS verify: 64K sigs/sec (batch)<br/>Limiting factor: BLS @ 6,000 payments/sec"]
    end

    G_BW_CLIENT --> G_CONN_LIMIT
    G_BW_VR --> G_CPU_LIMIT
```

### Middle VR Capacity (200 Gbps NIC)

| Metric | Value | Notes |
|--------|-------|-------|
| Total Bandwidth | 200 Gbps | 25 GB/s theoretical |
| Pure Relay | 92% | 23 GB/s |
| Consensus Gossip | 3% | 0.75 GB/s |
| Padding | 5% | 1.25 GB/s |
| Max Channels | 15,000 | 64 GB RAM limit |
| OOM Threshold | 48 GB | Activates killer |

**Per-Channel Bandwidth**: 1.92 Gbps (23 GB/s  12,000 channels)

### Settlement Executor (Exit VR) Capacity

| Metric | Value | Limiting Factor |
|--------|-------|-----------------|
| Total Uplink | 40 Gbps | 5 GB/s |
| SWIFT/ACH API | 60% | 3 GB/s |
| VR Mesh | 25% | 1.25 GB/s |
| Consensus | 10% | 0.5 GB/s |
| API Rate (SWIFT) | 10 req/sec | Per SE |
| API Rate (ACH) | 100 req/sec | Per SE |
| Max Settlements | 1,000 | Concurrent |

**File Descriptors**: 2 per settlement stream (in + out)
**Max**: 2,000 FDs
**TCP keepalive**: 300 seconds

---

## Performance Benchmarks

### Latency Distribution (Channel Build)

| Percentile | Latency | Notes |
|------------|---------|-------|
| p50 | 127 ms | Median |
| p95 | 340 ms | Typical SLA |
| p99 | 1,250 ms | Timeout failures |
| p99.9 | 5,000 ms | Adaptive timeout limit |

### Payment Processing Rate

| Node Type | Payments/sec | Limiting Factor |
|-----------|--------------|-----------------|
| Guard VR | 6,000 | BLS verification |
| Middle VR | 25,000 | ChaCha20 (AVX2) |
| Exit VR | 50 | SWIFT API rate |

### Network-Wide Throughput

| Metric | Value |
|--------|-------|
| Total TPS (all shards) | ~10,000 |
| Total Value/sec | ~$1.1M |
| Avg Payment | $111.20 |
| Peak (observed) | 12,847 TPS |

---

## Key Takeaways

1. **CPU Bottleneck**: Entry VR (TLS 850s + Pedersen 780s)
2. **Memory Bottleneck**: HTLC table (76% per-channel)
3. **Network Bottleneck**: Guard VR CPU (BLS verification @ 6K TPS)
4. **External Bottleneck**: SWIFT API (15ms, dominates Exit VR)
5. **Scaling Limit**: 15K channels per VR (64 GB RAM)

---

*Next: [CRYPTOGRAPHIC_DETAILS.md](./CRYPTOGRAPHIC_DETAILS.md) - Commitment Unwrapping & Encryption*
</file>

<file path="frontend/PROTOCOL_SPECIFICATION.md">
# Finallica Protocol Specification

This document describes the state machines and cell processing pipeline of the Finallica network.

---

## Section 3: State Machines

### 3.1 Channel Lifecycle State Machine

```mermaid
graph TB
    subgraph "Channel Lifecycle"
        C_INIT["INIT<br/>channel->state = CHANNEL_BUILDING<br/>channel->n_hops = 0<br/>local_balance = capacity<br/>remote_balance = 0"]
        C_G_WAIT["GUARD_WAIT<br/>awaiting OPENED<br/>channel->n_hop_build = 1<br/>noise_hs_state = 'e, ee, s, es'"]
        C_M_WAIT["MID_WAIT<br/>awaiting EXTENDED<br/>channel->n_hop_build = 2<br/>K_pay derived"]
        C_OPEN["OPEN<br/>channel->state = CHANNEL_OPEN<br/>n_hops = 3<br/>valid_for = 21600 sec (6h)<br/>cells_sent = 0<br/>last_rekey = now()"]
        C_ACTIVE["ACTIVE<br/>channel->package_window = 1000<br/>htlc_table[483] active<br/>rebalance_threshold = 0.85"]
        C_SETTLING["SETTLING<br/>settle_timer = 60 sec<br/>pending_htlcs = 0<br/>finalize_state_root()"]
        C_CLOSED["CLOSED<br/>channel->state = CLOSED<br/>reason: TIMEOUT|SLASH|USER_CLOSE<br/>balances settled on-chain"]
    end

    C_INIT -->|OPEN cell sent| C_G_WAIT
    C_G_WAIT -->|OPENED received| C_M_WAIT
    C_M_WAIT -->|EXTENDED received| C_OPEN
    C_OPEN -->|First PAY cell| C_ACTIVE
    C_ACTIVE -->|Channel timeout| C_SETTLING
    C_ACTIVE -->|User close| C_SETTLING
    C_ACTIVE -->|Slashing event| C_CLOSED
    C_SETTLING -->|Settlement confirmed| C_CLOSED
```

#### Channel State Transitions

| From State | To State | Trigger | Conditions |
|------------|----------|---------|------------|
| INIT | GUARD_WAIT | OPEN cell sent | Client initiates channel |
| GUARD_WAIT | MID_WAIT | OPENED received | Guard VR responds |
| MID_WAIT | OPEN | EXTENDED received | All hops built |
| OPEN | ACTIVE | First PAY cell | Channel ready for payments |
| ACTIVE | SETTLING | Timeout / User close | 6h elapsed or manual close |
| ACTIVE | CLOSED | Slashing event | 100% stake slash |
| SETTLING | CLOSED | Settlement confirmed | All HTLCs resolved |
| Any | CLOSED | DESTROY cell | Immediate teardown |

#### Channel State Structure

```c
enum channel_state_t {
  CHANNEL_BUILDING,
  CHANNEL_GUARD_WAIT,
  CHANNEL_MID_WAIT,
  CHANNEL_OPEN,
  CHANNEL_ACTIVE,
  CHANNEL_SETTLING,
  CHANNEL_CLOSED
};

struct channel_t {
  uint32_t channel_id;
  channel_state_t state;
  uint8_t n_hops;
  uint8_t n_hop_build;

  // Balances (in microcents)
  uint64_t local_balance;
  uint64_t remote_balance;
  uint64_t capacity;

  // Cryptographic keys
  crypto_aead_state *k_pay;
  crypto_aead_state *k_settle;
  crypto_aead_state *k_pad;

  // HTLC table
  htlc_entry_t *htlc_table[HTLC_MAX_PER_CHANNEL]; // 483 entries
  uint16_t htlc_count;

  // Timing
  uint64_t created_at;
  uint64_t last_rekey;
  uint64_t valid_until; // 6 hours

  // Flow control
  int package_window;   // 1000 cells
  int deliver_window;   // 1000 cells
};
```

### 3.2 HTLC State Machine

```mermaid
graph TB
    subgraph "Payment HTLC State"
        H_INIT["HTLC_INIT<br/>htlc->payment_hash = SHA256(preimage)<br/>htlc->amount = 10M microcents<br/>htlc->expiry = block+100<br/>status = OFFERED"]
        H_LOCKED["HTLC_LOCKED<br/>Sent PAY cell<br/>All hops acked<br/>status = LOCKED<br/>locked_at = now()"]
        H_SETTLED["HTLC_SETTLED<br/>Preimage revealed<br/>settled_on_chain = true<br/>status = SETTLED<br/>finality_time = 200ms"]
        H_REFUNDED["HTLC_REFUNDED<br/>expiry < block_height<br/>preimage NOT revealed<br/>status = REFUNDED<br/>refund_tx_broadcast = true"]
        H_FAILED["HTLC_FAILED<br/>Channel closed mid-route<br/>reason: INSUFFICIENT_LIQUIDITY|TIMEOUT<br/>status = FAILED"]
    end

    H_INIT -->|PAY cell forwarded| H_LOCKED
    H_LOCKED -->|SETTLE cell + preimage| H_SETTLED
    H_LOCKED -->|expiry passed| H_REFUNDED
    H_LOCKED -->|channel_destroyed| H_FAILED
```

#### HTLC State Transitions

| From State | To State | Trigger | Timeout |
|------------|----------|---------|----------|
| OFFERED | LOCKED | All hops ACK | 30 seconds |
| LOCKED | SETTLED | Preimage revealed | Block expiry |
| LOCKED | REFUNDED | Expiry passed | Block+100 |
| Any | FAILED | Channel closed / Insufficient liquidity | Immediate |

#### HTLC Entry Structure

```c
enum htlc_state_t {
  HTLC_OFFERED,
  HTLC_LOCKED,
  HTLC_SETTLED,
  HTLC_REFUNDED,
  HTLC_FAILED
};

struct htlc_entry_t {
  uint64_t htlc_id;
  uint8_t payment_hash[32]; // SHA256 of preimage
  uint64_t amount;          // In microcents
  uint32_t expiry;          // Block height
  htlc_state_t state;
  uint64_t created_at;
  uint64_t locked_at;

  // Routing
  bls_pubkey_t next_hop;
  uint16_t stream_id;
};
```

---

## Section 4: Cell Processing Pipeline

### 4.1 Per-Hop Processing Pipeline

Target latency: **0.8 s** per cell (fast path)

```mermaid
graph LR
    subgraph "Per-Hop Cell Processing (0.8 s target)"
        DPDK_RECV["DPDK RX Queue<br/>rte_eth_rx_burst()<br/>Poll mode, no IRQ<br/>32 mbufs per batch"]
        PREFETCH["Prefetch: __builtin_prefetch()<br/>L2 cache load<br/>64-byte alignment check"]
        PARSE_CELL["Parse Header<br/>Extract: channel_id, cmd, shard_id<br/>CRC32C verification: 0.02 s"]

        subgraph "Cryptographic Operations"
            CMD_SWITCH["Switch Command"]

            PADDING["Command: PADDING<br/>Dummy cell<br/>Update padding stats<br/>Free mbuf"]

            OPEN["Command: OPEN<br/>Noise_XX handshake<br/>X25519: 90s (slow path)<br/>BLS verify: 105s<br/>Derive K_pay, K_settle"]

            PAY["Command: PAY<br/>Decrypt: ChaCha20-Poly1305<br/>pedersen_verify: 45s<br/>BLS batch verify: 0.15s<br/>Update running digest"]

            SETTLE["Command: SETTLE<br/>Verify preimage: SHA256<br/>Check expiry > block<br/>BLS aggregate: 125s<br/>Commit to state root"]

            REKEY["Command: REKEY<br/>Verify sig: Ed25519<br/>Rotate ChaCha20 keys<br/>Reset nonce counter"]

            DESTROY["Command: DESTROY<br/>channel_mark_for_close()<br/>Settle remaining HTLCs<br/>Emit Close event"]
        end

        BALANCE_UPDATE["Update Channel Balance<br/>Homomorphic subtract:<br/>C_new = C_old - payment_commit<br/>Check C_new > 0"]

        FORWARD["Forward Cell<br/>rte_ring_enqueue()<br/>KIST scheduler<br/>Next hop: lookup_route(channel_id)"]

        DPDK_SEND["DPDK TX Queue<br/>rte_eth_tx_burst()<br/>Batch 32 cells<br/>Zero-copy"]
    end

    DPDK_RECV --> PREFETCH
    PREFETCH --> PARSE_CELL
    PARSE_CELL --> CMD_SWITCH
    CMD_SWITCH -->|cmd=0x00| PADDING
    CMD_SWITCH -->|cmd=0x01| OPEN
    CMD_SWITCH -->|cmd=0x02| PAY
    CMD_SWITCH -->|cmd=0x03| SETTLE
    CMD_SWITCH -->|cmd=0x04| REKEY
    CMD_SWITCH -->|cmd=0x05| DESTROY

    PAY --> BALANCE_UPDATE
    SETTLE --> BALANCE_UPDATE

    BALANCE_UPDATE --> FORWARD
    FORWARD --> DPDK_SEND
```

### 4.2 Cell Structure

All Finallica traffic flows in **1,024-byte transaction cells**:

```c
struct finallica_cell {
  // Byte offset 0: Channel identification
  uint32_t channel_id;      // Big-endian, connection-scoped
  uint8_t  shard_id;        // 0-126, shard topology
  uint8_t  command;         // PAY=0x01, SETTLE=0x02, OPEN=0x03, etc.
  uint16_t stream_id;       // Big-endian, 0x0000 = circuit-level
  uint64_t cell_seq;        // Big-endian, monotonic counter

  // Byte offset 16: Cryptographic metadata
  uint8_t  commitment[33];  // Compressed Pedersen commitment
  uint8_t  bls_signature[96]; // BLS12-381 G2 signature

  // Byte offset 145: Payment payload (encrypted)
  uint8_t  nonce[12];       // ChaCha20 nonce (counter mode)
  uint8_t  payload[867];    // Encrypted payment data
  uint16_t payload_len;     // Big-endian, 0-867 bytes
  uint8_t  auth_tag[16];    // Poly1305 MAC
} __attribute__((packed, aligned(64)));
```

**Total size: 1,042 bytes  Padded to 1,024 bytes**

### 4.3 Command Types

| Command | Value | Description | Processing Time |
|---------|-------|-------------|-----------------|
| PADDING | 0x00 | Dummy cell for traffic shaping | 0.01 s |
| OPEN | 0x01 | Channel initiation (Noise_XX) | 230 s (slow path) |
| PAY | 0x02 | Payment data with HTLC | 45 s |
| SETTLE | 0x03 | Settlement with preimage | 125 s |
| EXTEND | 0x04 | Extend channel to next hop | 230 s |
| REKEY | 0x05 | Rotate encryption keys | 5 s |
| DESTROY | 0x06 | Channel teardown | 10 s |

### 4.4 Payment Payload Structure (PAY cell)

```c
struct payment_relay_t {
  uint16_t stream_id;          // Payment stream identifier
  uint64_t amount_microcents;  // 8-byte fixed-point: 1 = $0.00001
  uint32_t timeout_unix;       // Settlement deadline
  uint8_t  next_hop[32];       // BLS pubkey hash of next VR
  uint8_t  payment_hash[32];   // SHA256 of preimage
  uint8_t  command;            // FORWARD=0x01, SETTLE=0x02, REFUND=0x03
  uint8_t  data[];             // Variable-length invoice metadata
} __attribute__((packed));
```

### 4.5 Processing Code Example

```c
void process_payment_cell(struct finallica_cell *cell,
                          crypto_aead_state *cipher) {
  // Prefetch for cache efficiency
  __builtin_prefetch(cell, 0, 3);

  // Verify BLS signature (fast-fail)
  if (!bls_verify_fast(&cell->bls_signature,
                       cell->commitment, 33,
                       vr_bls_pubkey)) {
    channel_mark_for_close(cell->channel_id, REASON_INVALID_SIG);
    return;
  }

  // Decrypt payload (ChaCha20-Poly1305)
  uint8_t plaintext[867];
  if (crypto_aead_chacha20poly1305_decrypt(
        plaintext, NULL, NULL,
        cell->payload, cell->payload_len,
        cell->auth_tag, 16,
        cell->nonce, cipher->key) != 0) {
    channel_penalty(cell->channel_id, 100);
    return;
  }

  // Parse payment relay header
  struct payment_relay_t *relay = (struct payment_relay_t *)plaintext;

  // Update channel balance (homomorphic subtraction)
  secp256k1_pedersen_commitment new_commit;
  secp256k1_pedersen_commitment_subtract(
    &new_commit, &cell->commitment, &relay->amount_commit);

  // Verify balance > 0
  if (!secp256k1_pedersen_commitment_verify_positive(&new_commit)) {
    channel_mark_for_close(cell->channel_id, REASON_INSUFFICIENT_FUNDS);
    return;
  }

  // Re-encrypt for next hop and forward
  crypto_aead_chacha20poly1305_encrypt(
    cell->payload, NULL,
    plaintext, relay->data_len,
    NULL, 0,
    cell->nonce, next_hop_cipher->key,
    cell->auth_tag);

  forward_cell(cell);
}
```

### 4.6 DPDK Integration

**Kernel bypass for maximum throughput**:

```c
// DPDK initialization
int finallica_dpdk_init(int argc, char **argv) {
  ret = rte_eal_init(argc, argv);

  // Memory pool per NUMA node
  pkt_pool = rte_pktmbuf_pool_create(
    "finallica_pkt_pool",
    FINALLICA_PKT_POOL_SIZE,  // 2,097,152 packets
    FINALLICA_CACHE_SIZE,      // 512 per core
    0,
    FINALLICA_CELL_SIZE,       // 1024 + headroom
    rte_socket_id()
  );

  // NIC setup: disable IRQ, enable RSS
  struct rte_eth_conf port_conf = {
    .rxmode = {
      .mq_mode = ETH_MQ_RX_RSS,
      .offloads = DEV_RX_OFFLOAD_CHECKSUM,
    },
    .rss_conf = {
      .rss_key = rss_key,
      .rss_key_len = 40,
      .rss_hf = ETH_RSS_NONFRAG_IPV4_UDP,
    }
  };

  rte_eth_dev_configure(port_id, rx_rings, tx_rings, &port_conf);

  return 0;
}

// Zero-copy cell processing
void finallica_cell_process(struct rte_mbuf *m) {
  struct finallica_cell *cell = rte_pktmbuf_mtod(m, struct finallica_cell *);

  // Prefetch next mbuf while processing current
  __builtin_prefetch(rte_pktmbuf_mtod(m->next, void *), 0, 1);

  // Process cell inline, no queueing
  vr_process_cell(cell);

  // Free mbuf back to pool
  rte_pktmbuf_free(m);
}
```

### 4.7 Performance Targets

| Operation | Target | Actual (p50) |
|-----------|--------|--------------|
| Cell receive (DPDK) | 0.1 s | 0.08 s |
| Parse header | 0.02 s | 0.015 s |
| ChaCha20 decrypt | 1.2 s | 1.1 s |
| Poly1305 verify | 0.8 s | 0.75 s |
| BLS batch verify | 0.15 s | 0.12 s |
| Balance update | 0.5 s | 0.45 s |
| Forward | 0.1 s | 0.08 s |
| **Total (fast path)** | **0.8 s** | **0.76 s** |

---

## Key Takeaways

1. **Channel States**: 7 states from INIT to CLOSED, 6-hour lifetime
2. **HTLC States**: 5 states (OFFERED  LOCKED  SETTLED/REFUNDED/FAILED)
3. **Cell Processing**: 0.8 s target via DPDK + lockless queues
4. **Commands**: 7 types (PADDING, OPEN, PAY, SETTLE, EXTEND, REKEY, DESTROY)
5. **Cryptography**: ChaCha20-Poly1305 (fast path), BLS12-381 (signatures)

---

*Next: [PERFORMANCE_ANALYSIS.md](./PERFORMANCE_ANALYSIS.md) - CPU/Memory/Network Bottlenecks*
</file>

<file path="frontend/README.md">
# Finallica: Global Financial Privacy Network

## Executive Summary

**Finallica** is a global, trust-minimized payment overlay network that adapts Tor's anonymity architecture for financial value transfer. It operates as a 127-shard network of ~12,000 Validator-Routers (VRs) processing payments through layered encryption, stake-weighted routing, and BFT consensus.

### Key Characteristics

| Attribute | Value |
|-----------|-------|
| **Network Size** | 12,000 Validator-Routers across 127 jurisdictional shards |
| **Consensus** | HotStuff BFT with 8 notaries, 200ms finality |
| **Cryptography** | BLS12-381 (staking), Noise_XX (handshakes), ChaCha20-Poly1305 (payments) |
| **Throughput** | ~10,000 payments/sec per shard (theoretical) |
| **Settlement** | SWIFT (1-3 days), ACH (1-2 days), Bitcoin (10 min), Lightning (3 sec) |
| **Anonymity Set** | ~1,200 users per payment |
| **Avg Fee** | 0.3% ($0.31 on $100 payment) |
| **Staking Required** | 500K BLF (~$2.25M) for VR, 2M BLF (~$9M) for Settlement Executor |

---

## Quick Concepts

### Core Components

1. **Finallica Proxy (FP)**: Local wallet daemon that handles pathfinding, channel construction, and payment stream multiplexing. Analogous to Tor's Onion Proxy.

2. **Validator-Router (VR)**: Network nodes that forward encrypted payment cells. Three types:
   - **Guard VR**: Entry point (persistent, high-stake)
   - **Middle VR**: Pure forwarding
   - **Settlement Executor (SE)**: Exit node connecting to legacy rails (SWIFT, ACH, BTC)

3. **Consensus Notary**: 8 geo-distributed authorities that sign global state roots every 10 seconds.

4. **Payment Channel**: 3-hop encrypted path (Guard  Middle  Exit) with HTLC-locked funds, valid for 6 hours.

### How a Payment Flows

```
User Scan Invoice  FP Selects Path  Channel Built (Noise_XX)  HTLC Attached  Settlement  Beneficiary Paid
        (12ms)              (247ms p50)              (5ms)          (1-3 days SWIFT)
```

---

## Tor vs Finallica Comparison

| **Tor Concept** | **Finallica Analogue** | **Key Differences** |
|----------------|------------------------|---------------------|
| Onion Router (OR) | Validator-Router (VR) | VRs stake BLF tokens; ORs volunteer |
| Guard Node | Entry VR (persistent) | 90-day persistence vs Tor's variable |
| Middle Node | Middle VR (ephemeral) | Identical forwarding role |
| Exit Node | Settlement Executor (SE) | SE connects to fiat rails; Tor exits to Internet |
| Directory Authority (9) | Consensus Notary (8) | Notaries sign state roots; Dir authorities vote on consensus |
| Circuit (3 hops) | Payment Channel (3 hops) | Channels have HTLC balances; circuits are stateless |
| RELAY cell | PAY cell | Payments include Pedersen commitments |
| AES-128-CTR | ChaCha20-Poly1305 | Different cipher, same layered encryption |
| NTor (X25519) | Noise_XX (X25519) | Similar handshake, Finallica adds BLS stake binding |
| No financial state | HTLC balance table | Channels track locked funds |
| Free to use | 0.3% avg fee | Economic incentives for operators |
| No finality | HotStuff BFT (200ms) | Finallica has settlement finality |

---

## Key Metrics at a Glance

### Network Health (Epoch 18492)
- **Total Payments**: 38.4M per epoch
- **Transaction Value**: $4.27B per epoch
- **Average Payment**: $111.20
- **Estimated Users**: 4.2M daily, 1.8M active wallets
- **Staked Supply**: 18.43M BLF ($82.9B) = 87.8% of total supply

### Performance
- **Channel Build Time**: 127ms (p50), 340ms (p95)
- **Payment RTT**: 580ms average
- **Consensus Finality**: 200ms (4-phase HotStuff)
- **Cell Processing**: 0.8 s per hop (target)

### Security
- **Guard Compromise Probability**: 0.31% per payment
- **Timing Correlation Success**: 12% (global passive adversary)
- **Anonymity Set**: 1-in-1,200 users
- **Slashing (24h)**: 45,000 BLF ($202K)

---

## Documentation Index

| Document | Description | Points Covered |
|----------|-------------|----------------|
| [ARCHITECTURE_OVERVIEW.md](./ARCHITECTURE_OVERVIEW.md) | 127-shard topology, E2E payment flow | 1-2 |
| [PROTOCOL_SPECIFICATION.md](./PROTOCOL_SPECIFICATION.md) | State machines, cell processing pipeline | 3-4 |
| [PERFORMANCE_ANALYSIS.md](./PERFORMANCE_ANALYSIS.md) | CPU/memory/network bottlenecks | 5 |
| [CRYPTOGRAPHIC_DETAILS.md](./CRYPTOGRAPHIC_DETAILS.md) | Commitment unwrapping, encryption layers | 6 |
| [LIQUIDITY_MANAGEMENT.md](./LIQUIDITY_MANAGEMENT.md) | Flow control, channel windows | 7 |
| [CONSENSUS_MECHANISM.md](./CONSENSUS_MECHANISM.md) | HotStuff BFT, state roots | 8 |
| [SECURITY_ANALYSIS.md](./SECURITY_ANALYSIS.md) | Attack vectors, defenses | 9 |
| [OPERATIONAL_METRICS.md](./OPERATIONAL_METRICS.md) | Live production dashboards | 10 |
| [TOR_FINALLIKA_MAPPING.md](./TOR_FINALLIKA_MAPPING.md) | Complete analogy reference | All |
| [RESEARCH_PROPOSALS.md](./RESEARCH_PROPOSALS.md) | v5.0 roadmap (Fin-340, Fin-N23, Fin-PQ) | Future |
| [CONSTANTS_REFERENCE.md](./CONSTANTS_REFERENCE.md) | All hardcoded values | Reference |

---

## System Architecture Overview

```mermaid
graph TB
    subgraph "Global Consensus Layer (8 Notaries)"
        N1[Notary1: 50M BLF]
        N2[Notary2: 48M BLF]
        N3[Notary3: 52M BLF]
        N4[Notary4: 45M BLF]
    end

    subgraph "Shard 0 (North America) - 2,407 VRs"
        G1[Guard: 15.7M BLF]
        M1[Middle: 6.3M BLF]
        E1[Exit SE: 12.3M BLF]
    end

    subgraph "Client Infrastructure"
        FP[Finallica Proxy]
        WALLET[Wallet UI]
    end

    subgraph "Legacy Rails"
        SWIFT[SWIFT: 1-3 days]
        ACH[ACH: 1-2 days]
        BTC[Bitcoin: 10 min]
    end

    N1 -->|BLS sign| CONS[Global State Root<br/>Every 10 sec]
    N2 -->|BLS sign| CONS
    N3 -->|BLS sign| CONS
    N4 -->|BLS sign| CONS

    CONS --> G1
    G1 <-->|Noise_XX + DPDK| M1
    M1 <-->|Noise_XX + DPDK| E1

    WALLET -->|Noise_XK| FP
    FP -->|OPEN cell| G1
    E1 -->|MT103| SWIFT
    E1 -->|NACHA| ACH
    E1 -->|RPC| BTC
```

---

## Payment Flow Sequence

```mermaid
sequenceDiagram
    participant User as User
    participant FP as Finallica Proxy
    participant G as Guard VR
    participant M as Middle VR
    participant E as Settlement Executor
    participant Bank as Bank

    User->>FP: Scan BOLT-11 invoice
    FP->>FP: Select path (12ms)
    FP->>G: OPEN2 cell (Noise_XX)
    G->>FP: OPENED2 cell
    FP->>G: EXTEND to Middle
    M->>G: OPENED
    FP->>M: EXTEND to Exit
    E->>M: OPENED
    FP->>G: PAY cell (HTLC)
    G->>M: PAY (decrypt/forward)
    M->>E: PAY (decrypt/forward)
    E->>Bank: SWIFT MT103
    Bank->>E: MT900 (1-3 days)
    E->>FP: SETTLE cell + preimage
    FP->>User: Payment settled
```

---

## Roadmap

### v4.2 (Current)
- BLS12-381 stake attestations
- Noise_XX handshakes
- HotStuff BFT consensus
- Bulletproofs+ range proofs

### v5.0 (2026 - Proposed)
- **Fin-340**: RingCT with MLSAG ring signatures (anonymity: 1,331)
- **Fin-N23**: eBPF flow control (0.3 s latency, per-stream windows)
- **Fin-PQ**: Post-quantum STARK proofs (quantum-resistant)
- **Fin-Sharding**: Dynamic shard splitting (unlimited TPS)

---

## License & Disclaimer

This is a theoretical architecture specification for educational purposes. Finallica is not a deployed network.

---

*Last Updated: 2024-12-22*
</file>

<file path="frontend/RESEARCH_PROPOSALS.md">
# Finallica Research Proposals

This document describes proposed enhancements to the Finallica system, targeting the v5.0 release in 2026.

---

## Overview: Roadmap to v5.0

```mermaid
graph LR
    subgraph "Current System (v4.2)"
        CURR["Current<br/>BLS signatures<br/>ChaCha20 encryption<br/>HotStuff consensus<br/>Bulletproofs+ range proofs"]
    end

    subgraph "Proposal Fin-340: RingCT"
        RINGCT["RingCT Integration<br/>MLSAG ring sig (size 11)<br/>Bulletproofs+ aggregated<br/>Anonymity: 11 = 1,331<br/>Overhead: +2KB/payment"]
    end

    subgraph "Proposal Fin-N23: eBPF Flow Control"
        EBPF["eBPF Rate Limiter<br/>Token bucket in kernel<br/>0.3 s latency<br/>Per-stream windows<br/>Head-of-line blocking eliminated"]
    end

    subgraph "Proposal Fin-PQ: Post-Quantum"
        PQ["STARK State Proofs<br/>192 KB proof size<br/>45 ms verification<br/>Quantum-resistant<br/>BLS  STARK migration"]
    end

    subgraph "Proposal Fin-Sharding: Dynamic Shards"
        DYN["Dynamic Sharding<br/>Split at 8K TPS<br/>Verifiable shuffle<br/>Stake redistribution<br/>Unlimited scalability"]
    end

    CURR --> RINGCT
    CURR --> EBPF
    CURR --> PQ
    CURR --> DYN

    RINGCT -->|"Impact: +15% CPU, +25% privacy"| FUTURE
    EBPF -->|"Impact: -65% latency, +40% throughput"| FUTURE
    PQ -->|"Impact: +24 proof size, -0% quantum risk"| FUTURE
    DYN -->|"Impact: Unlimited TPS, +complexity"| FUTURE

    FUTURE["Finallica v5.0 (2026)"]
```

---

## Proposal Fin-340: RingCT Integration

### 11.1 Confidential Transactions with Ring Signatures

**Goal**: Hide payment amounts and increase anonymity set using ring signatures.

**Current System**:
```
- Pedersen commitment: C = v*G + b*H (33 bytes)
- Bulletproofs+ range proof: ~700 bytes
- Total per payment: ~733 bytes overhead
- Anonymity: 1-in-1,200 (from path diversity)
```

**Fin-340 System**:
```
- Ring commitment: C_ring = (C_i) for i in ring (11 decoys)
- MLSAG ring signature: ~1,000 bytes
- Bulletproofs+ (aggregated): ~500 bytes
- Total overhead: ~1,500 bytes per payment
- Anonymity: 11 = 1,331 (from ring size 11)
```

### 11.2 RingCT Payment Structure

```c
struct ringct_payment {
  // Ring of 11 inputs (1 real + 10 decoys)
  secp256k1_pedersen_commitment ring_commitments[11];

  // MLSAG ring signature proving ownership of ONE input
  secp256k1_mlsag_sig mlsag;

  // Aggregated range proof for all commitments
  secp256k1_bulletproofs_proof bp_proof;

  // Actual payment (encrypted)
  uint64_t amount;
  uint8_t blinding_factor[32];
  uint8_t recipient_pubkey[32];
} __attribute__((packed));
```

### 11.3 Verification Process

```c
bool ringct_verify_payment(struct ringct_payment *payment) {
  // Step 1: Verify MLSAG ring signature
  secp256k1_pubkey *pubkeys[11];
  for (int i = 0; i < 11; i++) {
    pubkeys[i] = &payment->ring_commitments[i].pubkey;
  }

  if (!secp256k1_mlsag_verify(
        secp_ctx,
        &payment->mlsag,
        pubkeys,
        11,
        &payment->mlsag.ring_sig)) {
    return false;  // Invalid ring signature
  }

  // Step 2: Verify aggregated range proof
  if (!secp256k1_bulletproofs_rangeproof_verify(
        secp_ctx,
        &payment->bp_proof,
        payment->ring_commitments,
        11,
        NULL,
        0,
        64)) {  // bit_range
    return false;  // Invalid range proof
  }

  // Step 3: Verify ring commitment sum
  secp256k1_pedersen_commitment sum;
  secp256k1_pedersen_commitment_sum(&sum, payment->ring_commitments, 11);

  if (!secp256k1_pedersen_commitment_verify_positive(&sum)) {
    return false;  // Sum is negative
  }

  return true;
}
```

### 11.4 Performance Impact

| Metric | Current | Fin-340 | Change |
|--------|---------|---------|--------|
| Proof Size | 733 bytes | 1,500 bytes | +104% |
| Verification Time | 5ms (single) | 7ms (single) | +40% |
| Verification Time (batch) | 0.5ms (64) | 0.7ms (64) | +40% |
| Anonymity Set | 1,200 | 1,331 | +11% |
| CPU Usage | +45s/payment | +52s/payment | +15% |

### 11.5 Implementation Timeline

- **Q1 2025**: Research ring signature variants
- **Q2 2025**: Prototype MLSAG integration
- **Q3 2025**: Security audit
- **Q4 2025**: Testnet deployment
- **Q1 2026**: Mainnet rollout (Fin-340)

---

## Proposal Fin-N23: eBPF Flow Control

### 11.6 Kernel-Bypass Rate Limiting

**Goal**: Eliminate head-of-line blocking and reduce latency using eBPF.

**Current System**:
```
- Userspace token bucket
- Latency: 1.0 s per cell
- Per-channel windows only
- Head-of-line blocking: YES
```

**Fin-N23 System**:
```
- eBPF token bucket (in-kernel)
- Latency: 0.3 s per cell
- Per-stream windows
- Head-of-line blocking: NO
```

### 11.7 eBPF Program

```c
// In bpf/kern/finallica_n23_kern.c
SEC("xdp")
int xdp_n23_flow_control(struct xdp_md *ctx) {
  void *data = (void *)(long)ctx->data;
  void *data_end = (void *)(long)ctx->data_end;
  struct finallica_cell *cell = data;

  // Parse cell
  if ((void *)(cell + 1) > data_end) {
    return XDP_PASS;  // Not a full cell
  }

  // Lookup payment flow state in eBPF map
  struct payment_flow_key key = {
    .channel_id = cell->channel_id,
    .stream_id = cell->stream_id
  };

  struct payment_flow_val *val =
    bpf_map_lookup_elem(&payment_flows, &key);

  if (!val) {
    // New flow: initialize with initial window
    struct payment_flow_val new_val = {
      .window = 100,  // cells
      .last_ack = bpf_ktime_get_ns(),
      .rate_limit = 1000  // cells/sec
    };
    bpf_map_update_elem(&payment_flows, &key, &new_val, BPF_ANY);
    return XDP_PASS;
  }

  // Token bucket rate limiting
  uint64_t now = bpf_ktime_get_ns();
  uint64_t elapsed = now - val->last_ack;
  val->window += (elapsed / 1000000) * val->rate_limit;  // 1ms granularity
  val->window = min(val->window, 1000);  // Max burst

  if (val->window < 1) {
    // Drop and send NACK to upstream
    bpf_xdp_adjust_tail(ctx, -1024);  // Drop cell
    send_nack(cell->channel_id, cell->stream_id);
    return XDP_DROP;
  }

  val->window--;
  return XDP_PASS;
}
```

### 11.8 Performance Impact

| Metric | Current | Fin-N23 | Change |
|--------|---------|---------|--------|
| Rate Limit Latency | 1.0 s | 0.3 s | -70% |
| Throughput | 6,000 TPS | 8,500 TPS | +42% |
| Head-of-Line Blocking | YES | NO |  Eliminated |
| Granularity | Per-channel | Per-stream |  Improved |
| CPU Usage | 98% | 85% | -13% |

### 11.9 Implementation Timeline

- **Q2 2025**: eBPF prototype
- **Q3 2025**: Kernel module development
- **Q4 2025**: Testnet deployment
- **Q2 2026**: Mainnet rollout (Fin-N23)

---

## Proposal Fin-PQ: Post-Quantum STARK Proofs

### 11.10 Quantum-Resistant State Proofs

**Goal**: Replace BLS signatures with STARK proofs for quantum resistance.

**Current Vulnerability**:
```
BLS12-381: Vulnerable to quantum computers
- Shor's algorithm breaks discrete log
- Estimated quantum computer: 2028-2032
- Impact: 100% stake compromise
```

**Fin-PQ Solution**:
```
STARK (Scalable Transparent Argument of Knowledge)
- Quantum-resistant under conservative assumptions
- Proof size: 192 KB (vs 8 KB BLS aggregate)
- Verification: 45ms (vs 1ms BLS)
- Security: 128-bit post-quantum
```

### 11.11 STARK Proof Generation

```python
# In src/finallica/consensus/stark/settle.py
def prove_state_transition(
  prev_state_root: bytes32,
  transactions: List[Transaction],
  new_state_root: bytes32,
  validator_set: List[BlsPubkey]
) -> STARKProof:

  # Arithmetic circuit: verify 10,000 txs in parallel
  # Field: 256-bit prime field (same as Cairo)
  # Trace: 2^16 rows, 64 columns

  # Constraints:
  # 1. Payment signatures verify (switch to Crystals-Dilithium)
  # 2. Channel commitments balanced:  inputs =  outputs
  # 3. No HTLC expired unclaimed
  # 4. Validator stake unchanged except rewards/slashes

  # Proof generation: 12 seconds on 64-core AWS c6i.32xlarge
  # Proof size: 192 KB (vs 8 KB BLS aggregate)
  # Verification: 45 ms on single core
  # Quantum security: Provable under RAM model

  return stark_prove(
    program=state_transition_circuit,
    public_inputs=[prev_state_root, new_state_root],
    private_inputs=transactions,
    security_bits=128
  )
```

### 11.12 Hybrid Migration Path

```c
struct hybrid_signature {
  // BLS signature (classical)
  bls_signature bls_sig;

  // STARK proof (post-quantum)
  uint8_t stark_proof[192000];  // 192 KB
  uint8_t stark_pubkey[32];     // Prover identifier
};

// Verification: accept either
bool verify_hybrid(struct hybrid_signature *hybrid) {
  // Try BLS first (fast)
  if (bls_verify(&hybrid->bls_sig, ...)) {
    return true;
  }

  // Fall back to STARK (slow but quantum-safe)
  if (stark_verify(hybrid->stark_proof, ...)) {
    return true;
  }

  return false;
}
```

### 11.13 Performance Impact

| Metric | BLS | STARK | Change |
|--------|-----|-------|--------|
| Proof Size | 8 KB | 192 KB | +2400% |
| Verification Time | 1ms | 45ms | +4400% |
| Proof Generation | 10ms | 12,000ms | +120000% |
| Quantum Security |  |  | N/A |
| Bandwidth (per epoch) | 1 MB | 24 MB | +2400% |

### 11.14 Implementation Timeline

- **Q3 2025**: STARK circuit design
- **Q4 2025**: Proof system integration
- **Q1 2026**: Hybrid BLS+STARK deployment
- **Q2 2026**: STARK-only testnet
- **Q4 2026**: Mainnet rollout (Fin-PQ)

---

## Proposal Fin-Sharding: Dynamic Sharding

### 11.15 Unlimited Scalability via Shard Splitting

**Goal**: Enable unlimited TPS by dynamically splitting shards at high load.

**Current Limit**:
```
- 127 fixed shards
- 10,000 TPS per shard limit
- Total capacity: ~1.27M TPS (theoretical)
- Actual: ~350K TPS (observed)
```

**Fin-Sharding Solution**:
```
- Dynamic shard splitting at 8,000 TPS threshold
- Verifiable random shuffle of stake
- Automatic merge at low load
- Theoretical capacity: UNLIMITED
```

### 11.16 Shard Splitting Algorithm

```c
// Triggered when shard TPS > 8,000 for 10 consecutive epochs
bool should_split_shard(shard_id_t shard) {
  struct shard_stats *stats = get_shard_stats(shard);

  if (stats->avg_tps < 8000) {
    return false;
  }

  if (stats->high_load_epochs < 10) {
    return false;
  }

  return true;
}

// Split shard into two
struct shard_split_result split_shard(shard_id_t shard) {
  // Step 1: Verifiable shuffle of stake
  struct vr_assignment *assignments = verifiable_shuffle(
    shard->vrs,
    shard->vr_count,
    shard->random_beacon  // DRB from notaries
  );

  // Step 2: Partition into two new shards
  shard_id_t shard_a = shard * 2;      // Even
  shard_id_t shard_b = shard * 2 + 1;  // Odd

  for (int i = 0; i < shard->vr_count; i++) {
    if (i % 2 == 0) {
      assignments[i].new_shard = shard_a;
    } else {
      assignments[i].new_shard = shard_b;
    }
  }

  // Step 3: Sign new shard assignments
  struct shard_split_result result = {
    .shard_a = shard_a,
    .shard_b = shard_b,
    .assignment_sig = notaries_sign(assignments)
  };

  // Step 4: Broadcast to network
  broadcast_shard_split(&result);

  return result;
}
```

### 11.17 Performance Impact

| Metric | Current | Fin-Sharding | Change |
|--------|---------|--------------|--------|
| Max TPS per Shard | 10,000 | 10,000 | Same |
| Total Shards | 127 | Unlimited |  |
| Max Network TPS | 1.27M | Unlimited |  |
| Shard Split Time | N/A | 30 min | New |
| Shard Merge Time | N/A | 60 min | New |

### 11.18 Implementation Timeline

- **Q4 2025**: Verifiable shuffle design
- **Q1 2026**: Shard split/merge protocols
- **Q2 2026**: Testnet deployment (4 shards  8)
- **Q4 2026**: Mainnet rollout (Fin-Sharding)

---

## v5.0 Target Specifications

### Combined Impact

| Metric | v4.2 (Current) | v5.0 (Proposed) | Improvement |
|--------|----------------|-----------------|-------------|
| **Privacy** | | | |
| Anonymity Set | 1,200 | 1,331 | +11% |
| Amount Hiding | Pedersen | RingCT |  Stronger |
| **Performance** | | | |
| TPS per Shard | 10,000 | 14,000 | +40% |
| Latency | 580ms | 200ms | -65% |
| Throughput | 350K | 500K+ | +43% |
| **Security** | | | |
| Quantum Resistant |  |  | Critical |
| Slashable | 100% | 100% | Same |
| **Scalability** | | | |
| Max Shards | 127 | Unlimited |  |
| Max TPS | 1.27M | Unlimited |  |

---

## Key Takeaways

1. **Fin-340**: RingCT adds +25% privacy (1,331 anonymity set) at +15% CPU cost
2. **Fin-N23**: eBPF reduces latency by 65% (1.0s  0.3s) and eliminates HoL blocking
3. **Fin-PQ**: STARK proofs provide quantum resistance at 24 bandwidth cost
4. **Fin-Sharding**: Dynamic splitting enables unlimited TPS scalability
5. **v5.0 Target**: All four proposals deployed by 2026

---

*Next: [CONSTANTS_REFERENCE.md](./CONSTANTS_REFERENCE.md) - All Hardcoded Values*
</file>

<file path="frontend/SECURITY_ANALYSIS.md">
# Finallica Security Analysis

This document describes the attack surface, vulnerabilities, and defensive mechanisms of the Finallica network.

---

## Attack Surface Analysis

### 9.1 Timing Correlation Attacks

```mermaid
graph TB
    subgraph "Timing Correlation Attack"
        ADV["Global Adversary<br/>NSA/FVEY<br/>AS-level taps<br/>FinSpy at IXPs"]

        subgraph "Side A (Entry)"
            A_ENTRY["Observe FP  Guard<br/>Cell timing: burst of 3 cells @ t=0ms<br/>Payment amount: $100 quantized to $0.01  10,000 cells"]
        end

        subgraph "Side B (Exit)"
            B_EXIT["Observe Exit  Bank<br/>SWIFT MT103 @ t=150ms<br/>Amount: $99.69<br/>Unique payment ref: SHA256(preimage)"]
        end

        ADV -->|Correlate timing + amount| A_ENTRY
        ADV -->|Correlate timing + amount| B_EXIT
        A_ENTRY -->|Latency diff: =150ms  20ms| B_EXIT
        ADV -->|Success probability: 12% per payment<br/>Anonymity set reduces to 1,200| B_EXIT
    end
```

### Attack Probability Calculation

```
P[deanonymize] = (t / N)^(h-1) + 

where:
  t = timing resolution (100ms)
  N = network latency variance (800ms)
  h = hops (3)
   = statistical leakage from padding (0.08)

P = (100 / 800)^2 + 0.08 = 0.0156 + 0.08 = 0.0956  9.6%

With advanced packet sizing analysis: P  12%
```

### Defense: Payment Padding

```c
// Constant-rate padding: 1 cell/sec
void inject_padding_cells(struct channel *chan) {
  uint64_t now = get_time_sec();

  if (now - chan->last_padding_time >= 1) {
    struct finallica_cell pad_cell = {
      .channel_id = chan->id,
      .command = PADDING,
      .payload_len = 0,
      .nonce = {0},
    };

    // Send dummy cell with zero-value HTLC
    send_cell(chan, &pad_cell);
    chan->last_padding_time = now;
  }
}

// Burst padding: Poisson-distributed
void inject_burst_padding(struct channel *chan) {
  double lambda = 5.0;  // 5 cells/sec avg

  // Generate Poisson-distributed count
  unsigned int count = generate_poisson(lambda);

  for (unsigned int i = 0; i < count; i++) {
    inject_padding_cells(chan);
  }
}
```

---

## Guard Discovery + Stake Grinding

### 9.2 Compromising Entry Guards

```mermaid
graph TB
    subgraph "Guard Discovery + Stake Grinding"
        MAL_GUARD["Malicious Guard VR<br/>Run by adversary<br/>Stake: 15M BLF<br/>Probability: 15M / 4.85B = 0.31%<br/>Expected guards to corrupt: 7.4 VRs"]
        USER["User's FP<br/>Persistent guard: VR-0-015<br/>Prob(guard is malicious): 0.31%"]

        MAL_GUARD -->|Logs IP + payment_hash| ADV
        USER -->|Pays through malicious guard| MAL_GUARD
        ADV -->|Knows payer IP after 1 payment| MAL_GUARD

        subgraph "Defense: Guard Rotation"
            ROTATE["Guard rotation every 90 days<br/>If guard fails: immediate rotate<br/>After 30 days: forced rotate<br/>Probability attack succeeds: 1 - (1-0.0031)^3 = 0.9%"]
        end
    end
```

### Attack Cost Analysis

```
To deanonymize 1 payer:
  Guard discovery probability = stake_fraction_guard

  Average guard stake = 2.01M BLF
  Total shard stake = 4.82B BLF
  P(guard) = 2.01M / 4.82B = 0.000417

  Over 90 days: 1 - (1 - 0.000417)^720 = 26.1% chance

  Cost to operate 2 guards for 90 days:
    Stake: 2  2.01M BLF  $4.50 = $18.09M USD
    Infra: $50K/month  3 months = $150K
    Total: $18.24M
```

### Defense: Guard Selection Algorithm

```c
// Weighted guard selection reduces grinding effectiveness
struct entry_guard *select_guard() {
  // Exclude guards owned by same entity (family flag)
  smartlist_t *candidates = get_guards_without_conflicts(my_guards);

  // Bias toward higher-stake guards (harder to corrupt)
  double total_weight = 0;
  SMARTLIST_FOREACH(candidates, entry_guard_t *, guard) {
    guard->weight = pow(guard->stake, 0.7) * guard->uptime_factor;
    total_weight += guard->weight;
  }

  // Random weighted selection
  double rand = crypto_rand_double() * total_weight;
  SMARTLIST_FOREACH_BEGIN(candidates, entry_guard_t *, guard) {
    rand -= guard->weight;
    if (rand <= 0) return guard;
  SMARTLIST_FOREACH_END(guard);

  return NULL;
}
```

---

## Settlement Executor Compromise

### 9.3 Malicious Exit Nodes

```mermaid
graph TB
    subgraph "Settlement Executor Compromise"
        MAL_EXIT["Malicious Exit SE<br/>Runs settlement API<br/>Refuses to settle unless bribe: 50%<br/>Probability: 200 exits, corrupt 20 = 10%"]
        PAYMENT["Payment: $100<br/>Exit fee: $0.25<br/>Bribe demand: extra $50"]

        USER -->|Route through malicious exit| MAL_EXIT
        MAL_EXIT -->|Censor settlement| ADV
        MAL_EXIT -->|Extort payer| USER

        subgraph "Defense: Redundant Settlement"
            REDUNDANT["3 exit redundancy<br/>Payment splits: $33.33  3<br/>Require 2-of-3 settlement<br/>Prob(all 3 exits malicious): 0.1^3 = 0.001 = 0.1%<br/>Prob(2 malicious): 3.7%"]
        end
    end
```

### Attack: Exit Censorship

```c
// Malicious exit refuses to settle
bool malicious_settle_filter(struct htlc_entry *htlc) {
  // Check if beneficiary is on blacklist
  if (is_blacklisted(htlc->beneficiary_pubkey)) {
    return false;  // Refuse to settle
  }

  // Check if bribe paid
  if (htlc->bribe_amount < EXPECTED_BRIBE) {
    return false;  // Demand bribe
  }

  return true;
}
```

### Defense: Redundant Settlement

```c
// Split payment across 3 exits
struct split_payment {
  uint64_t total_amount;
  uint64_t split_amount;  // total / 3
  bls_pubkey_t exits[3];
  uint8_t payment_hashes[3][32];
};

// Require 2-of-3 settlements to release funds
bool verify_redundant_settlement(struct split_payment *split) {
  int settled_count = 0;

  for (int i = 0; i < 3; i++) {
    if (verify_settlement_signature(&split->exits[i], split->payment_hashes[i])) {
      settled_count++;
    }
  }

  return settled_count >= 2;  // 2-of-3 threshold
}
```

---

## Sybil Attacks

### 9.4 Fake Identity Creation

```
Attack: Adversary creates multiple fake VRs to increase influence

  Minimum stake per VR: 500K BLF ($2.25M USD)
  Cost to create 10 fake VRs: 10  $2.25M = $22.5M USD

Defense: Stake grinding resistance
  - Guards selected by stake^0.7 (reduces benefit of splitting)
  - Family flags prevent same operator from controlling multiple guards
  - Slash 100% for Sybil detection
```

### Sybil Detection Algorithm

```c
// Detect multiple VRs operated by same entity
bool detect_sybil_attack(vr_info_t *vr1, vr_info_t *vr2) {
  // Check for overlapping IP ranges
  if (ip_in_same_subnet(vr1->ip, vr2->ip, /24)) {
    return true;
  }

  // Check for identical BLS keys
  if (memcmp(vr1->bls_pubkey, vr2->bls_pubkey, 48) == 0) {
    return true;
  }

  // Check for temporal correlation (uptime patterns)
  if (uptime_correlation(vr1, vr2) > 0.95) {
    return true;
  }

  // Check for payment routing bias (prefer each other)
  if (routing_bias(vr1, vr2) > 0.3) {
    return true;
  }

  return false;
}
```

---

## Eclipse Attacks

### 9.5 Isolating a Target

```
Attack: Adversary eclipses a VR by controlling all its peers

  Target: VR-0-341 (Stake: 2.8M BLF)
  Adversary controls: 2,400 peers
  Cost: 2,400  500K BLF = 1.2B BLF ($5.4B USD) - infeasible

Defense: Peer diversity requirements
  - Minimum unique peers: 100
  - Max from same /16 subnet: 10
  - Periodic random peer sampling
```

---

## DDoS Mitigation

### 9.6 Connection Rate Limiting

```c
struct dos_client_stats {
  uint32_t conncount;           // Active connections
  uint32_t creation_count;      // CREATE cells in 1s window
  time_t   last_creation_time;
  token_bucket_t rate_limit;    // 3 cells/sec burst, 0.1 cell/sec sustained
};

// Token bucket filter per client IP
bool check_rate_limit(struct in_addr *client_ip) {
  struct dos_client_stats *stats = get_or_create_stats(client_ip);

  // Refill tokens
  uint64_t elapsed = now() - stats->last_creation_time;
  stats->rate_limit.tokens += elapsed * 0.1;
  if (stats->rate_limit.tokens > 3.0) {
    stats->rate_limit.tokens = 3.0;
  }

  // Check if allowed
  if (stats->rate_limit.tokens < 1.0) {
    return false;  // Rate limited
  }

  stats->rate_limit.tokens -= 1.0;
  return true;
}
```

---

## Anonymity Set Analysis

### 9.7 Effective Anonymity Set Size

```
|AS| = (N_shards  N_vrs_per_shard) / (c  f)

where:
  N_shards = 127
  N_vrs_per_shard = 2,400 (avg)
  c = concurrency factor = 8 (payments per second per VR)
  f = fee clustering factor = 10 (pools of similar fees)

|AS| = (127  2400) / (8  10) = 304,800 / 80 = 3,810

With padding + amount quantization:
  Effective |AS|  1,200 (12% deanonymization probability)
```

---

## Security Summary

| Attack Vector | Success Probability | Defense | Cost to Attack |
|---------------|---------------------|---------|----------------|
| Timing Correlation | 12% | Padding + quantization | AS-level tap (~$1M) |
| Guard Discovery | 26% (90 days) | Rotation + family flags | $18M (90 days) |
| Exit Compromise | 10% | 2-of-3 redundancy | Stake 200 exits |
| Sybil Attack | Low | Stake^0.7 weighting | $22.5M per 10 VRs |
| Eclipse Attack | Very Low | Peer diversity | $5.4B (infeasible) |
| DDoS | Low | Token bucket | Minimal |

---

## Key Takeaways

1. **Timing Attacks**: 12% success probability, mitigated by padding
2. **Guard Discovery**: 0.31% per guard, 90-day rotation limits exposure
3. **Exit Compromise**: 2-of-3 redundancy reduces success to 0.1%
4. **Anonymity Set**: ~1,200 users after defenses
5. **Sybil Resistance**: Stake-weighted selection + family flags

---

*Next: [OPERATIONAL_METRICS.md](./OPERATIONAL_METRICS.md) - Live Production Dashboards*
</file>

<file path="frontend/styles.css">
/* Finallica Documentation System Styles */

:root {
    --color-primary: #00d4ff;
    --color-primary-dark: #0099cc;
    --color-secondary: #6b46c1;
    --color-success: #10b981;
    --color-danger: #ef4444;
    --color-warning: #f59e0b;
    --color-bg: #0a0e1a;
    --color-bg-secondary: #111827;
    --color-bg-tertiary: #1f2937;
    --color-border: #374151;
    --color-text: #f3f4f6;
    --color-text-muted: #9ca3af;
    --shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.5);
    --shadow-lg: 0 10px 25px -5px rgba(0, 0, 0, 0.5);
    --radius: 8px;
    --font-mono: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
    --font-sans: system-ui, -apple-system, sans-serif;
}

* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
}

body {
    font-family: var(--font-sans);
    background: var(--color-bg);
    color: var(--color-text);
    line-height: 1.6;
    min-height: 100vh;
}

/* Header */
.header {
    background: var(--color-bg-secondary);
    border-bottom: 1px solid var(--color-border);
    padding: 0.75rem 1.5rem;
    position: sticky;
    top: 0;
    z-index: 100;
}

.header-content {
    max-width: 2000px;
    margin: 0 auto;
    display: flex;
    justify-content: space-between;
    align-items: center;
}

.logo {
    display: flex;
    align-items: center;
    gap: 0.75rem;
    font-size: 1.5rem;
    font-weight: 700;
}

.logo-icon {
    font-size: 2rem;
    color: var(--color-primary);
}

.logo-subtitle {
    font-size: 0.875rem;
    color: var(--color-text-muted);
    font-weight: 400;
}

.header-actions {
    display: flex;
    gap: 1rem;
    align-items: center;
}

.wallet-info {
    display: flex;
    gap: 1rem;
    align-items: center;
}

.wallet-address {
    font-family: var(--font-mono);
    font-size: 0.875rem;
    color: var(--color-primary);
}

.wallet-balance {
    font-weight: 600;
}

/* Buttons */
.btn {
    display: inline-flex;
    align-items: center;
    gap: 0.5rem;
    padding: 0.5rem 1rem;
    border: none;
    border-radius: var(--radius);
    font-size: 0.875rem;
    font-weight: 500;
    cursor: pointer;
    transition: all 0.2s;
}

.btn-primary {
    background: var(--color-primary);
    color: #000;
}

.btn-primary:hover {
    background: var(--color-primary-dark);
}

.btn-secondary {
    background: var(--color-bg-tertiary);
    color: var(--color-text);
}

.btn-secondary:hover {
    background: var(--color-border);
}

.btn-success {
    background: var(--color-success);
    color: #fff;
}

.btn-danger {
    background: var(--color-danger);
    color: #fff;
}

.btn-large {
    padding: 1rem 2rem;
    font-size: 1rem;
}

.btn-icon {
    font-size: 1rem;
}

.btn-icon {
    padding: 0.25rem;
    background: none;
    border: none;
    cursor: pointer;
    color: var(--color-text-muted);
}

.btn-close {
    background: none;
    border: none;
    font-size: 1.5rem;
    cursor: pointer;
    color: var(--color-text-muted);
}

.hidden {
    display: none !important;
}

/* Main Container */
.main-container {
    display: grid;
    grid-template-columns: 250px 1fr 350px;
    gap: 1px;
    background: var(--color-border);
    min-height: calc(100vh - 60px);
}

/* Sidebar */
.sidebar {
    background: var(--color-bg-secondary);
    padding: 1rem 0;
}

.sidebar-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 0 1rem 1rem;
    border-bottom: 1px solid var(--color-border);
}

.sidebar-header h3 {
    font-size: 0.875rem;
    text-transform: uppercase;
    letter-spacing: 0.05em;
    color: var(--color-text-muted);
}

.doc-tree {
    max-height: calc(100vh - 150px);
    overflow-y: auto;
}

.doc-tree-item {
    display: block;
    padding: 0.5rem 1rem;
    color: var(--color-text-muted);
    text-decoration: none;
    font-size: 0.875rem;
    cursor: pointer;
    transition: all 0.2s;
}

.doc-tree-item:hover {
    background: var(--color-bg-tertiary);
    color: var(--color-text);
}

.doc-tree-item.active {
    background: var(--color-bg-tertiary);
    color: var(--color-primary);
    border-left: 2px solid var(--color-primary);
}

.doc-tree-section {
    padding: 0.5rem 1rem;
    font-size: 0.75rem;
    text-transform: uppercase;
    letter-spacing: 0.05em;
    color: var(--color-text-muted);
}

/* Main Content */
.main-content {
    background: var(--color-bg);
    overflow-y: auto;
    max-height: calc(100vh - 60px);
}

.document-viewer {
    padding: 2rem;
    max-width: 900px;
    margin: 0 auto;
}

.doc-toolbar {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 2rem;
    padding-bottom: 1rem;
    border-bottom: 1px solid var(--color-border);
}

.doc-breadcrumbs {
    display: flex;
    gap: 0.5rem;
    font-size: 0.875rem;
}

.breadcrumb-item {
    color: var(--color-text-muted);
}

.breadcrumb-item.active {
    color: var(--color-primary);
}

.breadcrumb-separator {
    color: var(--color-border);
}

.doc-actions {
    display: flex;
    gap: 0.5rem;
}

/* Document Content */
.doc-content {
    font-size: 1rem;
    line-height: 1.8;
}

.doc-content h1 {
    font-size: 2rem;
    margin: 2rem 0 1rem;
    color: var(--color-primary);
}

.doc-content h2 {
    font-size: 1.5rem;
    margin: 1.5rem 0 0.75rem;
    color: var(--color-text);
}

.doc-content h3 {
    font-size: 1.25rem;
    margin: 1.25rem 0 0.5rem;
}

.doc-content h4 {
    font-size: 1rem;
    margin: 1rem 0 0.5rem;
}

.doc-content p {
    margin: 1rem 0;
}

.doc-content code {
    background: var(--color-bg-tertiary);
    padding: 0.2rem 0.4rem;
    border-radius: 4px;
    font-family: var(--font-mono);
    font-size: 0.875rem;
}

.doc-content pre {
    background: var(--color-bg-tertiary);
    padding: 1rem;
    border-radius: var(--radius);
    overflow-x: auto;
    margin: 1rem 0;
}

.doc-content pre code {
    background: none;
    padding: 0;
}

.doc-content ul, .doc-content ol {
    margin: 1rem 0;
    padding-left: 2rem;
}

.doc-content li {
    margin: 0.5rem 0;
}

.doc-content table {
    width: 100%;
    border-collapse: collapse;
    margin: 1rem 0;
}

.doc-content th,
.doc-content td {
    padding: 0.75rem;
    text-align: left;
    border-bottom: 1px solid var(--color-border);
}

.doc-content th {
    background: var(--color-bg-secondary);
    font-weight: 600;
}

.doc-content blockquote {
    border-left: 3px solid var(--color-primary);
    padding-left: 1rem;
    margin: 1rem 0;
    color: var(--color-text-muted);
}

/* Editor Panel */
.editor-panel {
    padding: 2rem;
    max-width: 1200px;
    margin: 0 auto;
}

.editor-toolbar {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 1rem;
}

.doc-editor {
    width: 100%;
    min-height: 500px;
    background: var(--color-bg-tertiary);
    border: 1px solid var(--color-border);
    border-radius: var(--radius);
    padding: 1rem;
    color: var(--color-text);
    font-family: var(--font-mono);
    font-size: 0.875rem;
    resize: vertical;
}

.edit-preview {
    margin-top: 1rem;
    padding: 1rem;
    background: var(--color-bg-secondary);
    border-radius: var(--radius);
    border: 1px solid var(--color-border);
}

/* Right Panel */
.right-panel {
    background: var(--color-bg-secondary);
    display: flex;
    flex-direction: column;
    border-left: 1px solid var(--color-border);
}

.tab-navigation {
    display: flex;
    border-bottom: 1px solid var(--color-border);
}

.tab-btn {
    flex: 1;
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 0.5rem;
    padding: 1rem;
    background: none;
    border: none;
    color: var(--color-text-muted);
    cursor: pointer;
    transition: all 0.2s;
    position: relative;
}

.tab-btn:hover {
    background: var(--color-bg-tertiary);
    color: var(--color-text);
}

.tab-btn.active {
    color: var(--color-primary);
    border-bottom: 2px solid var(--color-primary);
}

.tab-icon {
    font-size: 1.25rem;
}

.badge {
    background: var(--color-danger);
    color: #fff;
    font-size: 0.625rem;
    padding: 0.125rem 0.375rem;
    border-radius: 999px;
    font-weight: 600;
}

.tab-content {
    flex: 1;
    overflow-y: auto;
}

.tab-pane {
    display: none;
}

.tab-pane.active {
    display: block;
}

/* Chat */
.chat-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 0.75rem 1rem;
    border-bottom: 1px solid var(--color-border);
}

.chat-header h3 {
    margin: 0;
    font-size: 1rem;
    font-weight: 600;
}

.ai-model-selector {
    display: flex;
    gap: 0.5rem;
    align-items: center;
}

.ai-selector {
    display: flex;
    gap: 0.5rem;
}

.ai-select {
    background: var(--color-bg-tertiary);
    border: 1px solid var(--color-border);
    border-radius: var(--radius);
    padding: 0.375rem 0.75rem;
    color: var(--color-text);
    font-size: 0.75rem;
    cursor: pointer;
}

.ai-select:hover {
    border-color: var(--color-primary);
}

.ai-select:focus {
    outline: none;
    border-color: var(--color-primary);
}

.ai-status {
    font-size: 0.75rem;
    padding: 0.25rem 0.75rem;
    background: var(--color-bg-warning);
    border-radius: var(--radius);
    color: var(--color-warning);
}

.chat-messages {
    flex: 1;
    padding: 1rem;
    overflow-y: auto;
    max-height: calc(100vh - 250px);
}

.chat-message {
    margin-bottom: 1rem;
    display: flex;
    gap: 0.75rem;
}

.chat-message.user {
    flex-direction: row-reverse;
}

.chat-avatar {
    width: 32px;
    height: 32px;
    border-radius: 50%;
    background: var(--color-primary);
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 0.875rem;
    flex-shrink: 0;
}

.chat-message.ai .chat-avatar {
    background: var(--color-secondary);
}

.chat-message-content {
    flex: 1;
}

.message-bubble {
    background: var(--color-bg-tertiary);
    padding: 0.75rem 1rem;
    border-radius: var(--radius);
    max-width: 80%;
}

.chat-message.user .message-bubble {
    background: var(--color-primary);
    color: #000;
}

.message-content {
    font-size: 0.875rem;
}

.message-meta {
    font-size: 0.75rem;
    color: var(--color-text-muted);
    margin-top: 0.25rem;
}

.chat-input-container {
    border-top: 1px solid var(--color-border);
    padding: 1rem;
}

.chat-input {
    width: 100%;
    background: var(--color-bg-tertiary);
    border: 1px solid var(--color-border);
    border-radius: var(--radius);
    padding: 0.75rem;
    color: var(--color-text);
    font-family: var(--font-sans);
    resize: none;
    margin-bottom: 0.5rem;
}

.chat-input:focus {
    outline: none;
    border-color: var(--color-primary);
}

.chat-actions {
    display: flex;
    justify-content: flex-end;
    gap: 0.5rem;
}

/* Proposals */
.proposals-summary {
    padding: 1rem;
    display: grid;
    grid-template-columns: 1fr 1fr;
    gap: 0.5rem;
}

.proposal-card {
    background: var(--color-bg-tertiary);
    padding: 1rem;
    border-radius: var(--radius);
    border: 1px solid var(--color-border);
}

.proposal-card h4 {
    font-size: 0.875rem;
    margin-bottom: 0.5rem;
}

.proposal-card .stat {
    font-size: 1.5rem;
    font-weight: 700;
    color: var(--color-primary);
}

.proposals-detail {
    padding: 1rem;
}

.proposal-item {
    background: var(--color-bg-tertiary);
    border: 1px solid var(--color-border);
    border-radius: var(--radius);
    padding: 1rem;
    margin-bottom: 0.75rem;
}

.proposal-item.voting {
    border-left: 3px solid var(--color-warning);
}

.proposal-item.approved {
    border-left: 3px solid var(--color-success);
}

.proposal-item.rejected {
    border-left: 3px solid var(--color-danger);
}

.proposal-header {
    display: flex;
    justify-content: space-between;
    align-items: flex-start;
    margin-bottom: 0.5rem;
}

.proposal-title {
    font-weight: 600;
}

.proposal-id {
    font-family: var(--font-mono);
    font-size: 0.75rem;
    color: var(--color-text-muted);
}

.proposal-meta {
    display: flex;
    gap: 1rem;
    font-size: 0.75rem;
    color: var(--color-text-muted);
    margin-bottom: 0.5rem;
}

.proposal-votes {
    display: flex;
    gap: 0.5rem;
    margin-top: 0.5rem;
}

.vote-bar {
    flex: 1;
    height: 6px;
    background: var(--color-border);
    border-radius: 3px;
    overflow: hidden;
}

.vote-bar-fill {
    height: 100%;
    background: var(--color-primary);
    transition: width 0.3s;
}

.vote-bar-fill.for { background: var(--color-success); }
.vote-bar-fill.against { background: var(--color-danger); }

/* Consensus */
.consensus-overview {
    display: grid;
    grid-template-columns: 1fr 1fr 1fr;
    gap: 0.5rem;
    padding: 1rem;
}

.consensus-metric {
    background: var(--color-bg-tertiary);
    padding: 1rem;
    border-radius: var(--radius);
    text-align: center;
}

.metric-label {
    display: block;
    font-size: 0.75rem;
    color: var(--color-text-muted);
    margin-bottom: 0.25rem;
}

.metric-value {
    display: block;
    font-size: 1.25rem;
    font-weight: 700;
    color: var(--color-primary);
}

.consensus-list {
    padding: 1rem;
}

.consensus-item {
    background: var(--color-bg-tertiary);
    border: 1px solid var(--color-border);
    border-radius: var(--radius);
    padding: 1rem;
    margin-bottom: 0.75rem;
}

.consensus-status {
    display: inline-block;
    padding: 0.125rem 0.5rem;
    border-radius: 999px;
    font-size: 0.625rem;
    font-weight: 600;
    text-transform: uppercase;
}

.consensus-status.pending {
    background: var(--color-warning);
    color: #000;
}

.consensus-status.approved {
    background: var(--color-success);
    color: #fff;
}

.consensus-status.rejected {
    background: var(--color-danger);
    color: #fff;
}

/* Activity Feed */
.activity-feed {
    padding: 1rem;
}

.activity-item {
    display: flex;
    gap: 0.75rem;
    padding: 1rem 0;
    border-bottom: 1px solid var(--color-border);
}

.activity-item:last-child {
    border-bottom: none;
}

.activity-icon {
    width: 32px;
    height: 32px;
    border-radius: 50%;
    background: var(--color-bg-tertiary);
    display: flex;
    align-items: center;
    justify-content: center;
    font-size: 0.875rem;
    flex-shrink: 0;
}

.activity-content {
    flex: 1;
}

.activity-title {
    font-size: 0.875rem;
    margin-bottom: 0.25rem;
}

.activity-time {
    font-size: 0.75rem;
    color: var(--color-text-muted);
}

/* Modal */
.modal {
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    background: rgba(0, 0, 0, 0.75);
    display: flex;
    align-items: center;
    justify-content: center;
    z-index: 1000;
}

.modal-content {
    background: var(--color-bg-secondary);
    border-radius: var(--radius);
    border: 1px solid var(--color-border);
    width: 90%;
    max-width: 600px;
    max-height: 90vh;
    overflow-y: auto;
}

.modal-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    padding: 1.5rem;
    border-bottom: 1px solid var(--color-border);
}

.modal-header h2 {
    font-size: 1.25rem;
}

.modal-body {
    padding: 1.5rem;
}

.modal-footer {
    padding: 1rem 1.5rem;
    border-top: 1px solid var(--color-border);
    display: flex;
    justify-content: flex-end;
    gap: 0.5rem;
}

/* Form */
.form-group {
    margin-bottom: 1rem;
}

.form-group label {
    display: block;
    margin-bottom: 0.5rem;
    font-size: 0.875rem;
    font-weight: 500;
}

.form-control {
    width: 100%;
    padding: 0.625rem;
    background: var(--color-bg-tertiary);
    border: 1px solid var(--color-border);
    border-radius: var(--radius);
    color: var(--color-text);
    font-family: var(--font-sans);
}

.form-control:focus {
    outline: none;
    border-color: var(--color-primary);
}

.form-text {
    display: block;
    margin-top: 0.25rem;
    font-size: 0.75rem;
    color: var(--color-text-muted);
}

/* Voting Modal */
.voting-details {
    padding: 1rem;
    background: var(--color-bg-tertiary);
    border-radius: var(--radius);
    margin-bottom: 1rem;
}

.voting-options {
    display: grid;
    grid-template-columns: 1fr 1fr 1fr;
    gap: 0.5rem;
    margin-bottom: 1rem;
}

.voting-sliders {
    padding: 1rem;
    background: var(--color-bg-tertiary);
    border-radius: var(--radius);
}

.slider-group {
    margin-bottom: 0.5rem;
}

.slider-group label {
    display: flex;
    justify-content: space-between;
    font-size: 0.875rem;
    margin-bottom: 0.5rem;
}

input[type="range"] {
    width: 100%;
}

/* Toast Notifications */
.toast-container {
    position: fixed;
    bottom: 1rem;
    right: 1rem;
    z-index: 2000;
    display: flex;
    flex-direction: column;
    gap: 0.5rem;
}

.toast {
    background: var(--color-bg-secondary);
    border: 1px solid var(--color-border);
    border-radius: var(--radius);
    padding: 1rem;
    min-width: 300px;
    box-shadow: var(--shadow-lg);
    animation: slideIn 0.3s ease;
}

.toast.success {
    border-left: 3px solid var(--color-success);
}

.toast.error {
    border-left: 3px solid var(--color-danger);
}

.toast.warning {
    border-left: 3px solid var(--color-warning);
}

.toast-content {
    font-size: 0.875rem;
}

@keyframes slideIn {
    from {
        transform: translateX(100%);
        opacity: 0;
    }
    to {
        transform: translateX(0);
        opacity: 1;
    }
}

/* Scrollbar */
::-webkit-scrollbar {
    width: 8px;
    height: 8px;
}

::-webkit-scrollbar-track {
    background: var(--color-bg);
}

::-webkit-scrollbar-thumb {
    background: var(--color-border);
    border-radius: 4px;
}

::-webkit-scrollbar-thumb:hover {
    background: var(--color-text-muted);
}

/* Responsive */
@media (max-width: 1200px) {
    .main-container {
        grid-template-columns: 200px 1fr 300px;
    }
}

@media (max-width: 900px) {
    .main-container {
        grid-template-columns: 1fr;
    }

    .sidebar {
        display: none;
    }

    .right-panel {
        position: fixed;
        right: 0;
        top: 60px;
        bottom: 0;
        width: 350px;
        transform: translateX(100%);
        transition: transform 0.3s;
        z-index: 200;
    }

    .right-panel.open {
        transform: translateX(0);
    }
}

/* Diff highlighting */
.diff-add {
    background: rgba(16, 185, 129, 0.2);
}

.diff-remove {
    background: rgba(239, 68, 68, 0.2);
}

/* Mermaid diagram placeholder */
.mermaid-placeholder {
    background: var(--color-bg-tertiary);
    border: 1px dashed var(--color-border);
    border-radius: var(--radius);
    padding: 2rem;
    text-align: center;
    color: var(--color-text-muted);
}

/* Loading spinner */
.spinner {
    display: inline-block;
    width: 20px;
    height: 20px;
    border: 2px solid var(--color-border);
    border-top-color: var(--color-primary);
    border-radius: 50%;
    animation: spin 0.8s linear infinite;
}

@keyframes spin {
    to { transform: rotate(360deg); }
}

/* ============================================
   PRIVACY STYLES
   ============================================ */

/* Privacy Toggle Container */
#privacyToggleContainer {
    display: flex;
    align-items: center;
    gap: 0.5rem;
}

/* Privacy Toggle Button */
.btn-privacy {
    display: flex;
    align-items: center;
    gap: 0.5rem;
    background: var(--color-bg-tertiary);
    border: 1px solid var(--color-border);
    color: var(--color-text);
    padding: 0.5rem 1rem;
    border-radius: 20px;
    transition: all 0.2s ease;
    cursor: pointer;
    font-size: 0.875rem;
}

.btn-privacy:hover {
    background: var(--color-bg-secondary);
    border-color: var(--color-primary);
}

.btn-privacy.active {
    background: rgba(0, 212, 255, 0.15);
    border-color: var(--color-primary);
    color: var(--color-primary);
}

.privacy-icon {
    font-size: 1.2rem;
}

.privacy-label {
    font-weight: 500;
}

/* Privacy Panel */
.privacy-panel {
    background: var(--color-bg-secondary);
    border: 1px solid var(--color-border);
    border-radius: var(--radius);
    padding: 1.5rem;
    margin-top: 1rem;
    animation: fadeIn 0.3s ease;
}

.privacy-panel.hidden {
    display: none;
}

@keyframes fadeIn {
    from {
        opacity: 0;
        transform: translateY(-10px);
    }
    to {
        opacity: 1;
        transform: translateY(0);
    }
}

.privacy-panel h3 {
    margin-bottom: 1rem;
    display: flex;
    align-items: center;
    gap: 0.5rem;
}

/* Privacy Sections */
.privacy-section {
    margin-bottom: 1.5rem;
    padding-bottom: 1.5rem;
}

.privacy-section:last-of-type {
    margin-bottom: 0;
    padding-bottom: 0;
}

.privacy-section h4 {
    margin-bottom: 0.75rem;
    color: var(--color-primary);
    font-size: 1rem;
}

.privacy-warning {
    font-size: 0.875rem;
    color: var(--color-warning);
    margin-bottom: 1rem;
    padding: 0.75rem;
    background: rgba(245, 158, 11, 0.1);
    border-radius: 6px;
    border-left: 3px solid var(--color-warning);
}

/* Privacy Divider */
.privacy-divider {
    height: 1px;
    background: var(--color-border);
    margin: 1.5rem 0;
}

/* Privacy Form Elements */
.privacy-panel .form-group {
    margin-bottom: 1rem;
}

.privacy-panel label {
    display: block;
    margin-bottom: 0.5rem;
    font-size: 0.875rem;
    color: var(--color-text-muted);
}

.privacy-panel select,
.privacy-panel input[type="text"],
.privacy-panel textarea {
    width: 100%;
    padding: 0.625rem 0.75rem;
    background: var(--color-bg-tertiary);
    border: 1px solid var(--color-border);
    border-radius: 6px;
    color: var(--color-text);
    font-size: 0.875rem;
    transition: border-color 0.2s;
}

.privacy-panel select:focus,
.privacy-panel input[type="text"]:focus,
.privacy-panel textarea:focus {
    outline: none;
    border-color: var(--color-primary);
}

.privacy-panel textarea {
    font-family: var(--font-mono);
    resize: vertical;
    min-height: 80px;
}

#privacyNoteDisplay {
    font-family: var(--font-mono);
    font-size: 0.75rem;
    word-break: break-all;
    background: rgba(0, 212, 255, 0.05);
    border-color: rgba(0, 212, 255, 0.3);
}

/* Privacy Buttons */
.privacy-actions {
    display: flex;
    gap: 0.5rem;
    flex-wrap: wrap;
    margin-top: 1rem;
}

.btn-privacy-action {
    padding: 0.5rem 1rem;
    font-size: 0.875rem;
    border-radius: 6px;
}

/* Privacy Fee Estimate */
#privacyFeeEstimate {
    font-size: 0.875rem;
    color: var(--color-text-muted);
    margin-top: 0.5rem;
}

/* Privacy Info Box */
.privacy-info {
    background: rgba(107, 70, 193, 0.1);
    border: 1px solid rgba(107, 70, 193, 0.3);
    border-radius: 6px;
    padding: 1rem;
    font-size: 0.875rem;
    margin-top: 1rem;
}

.privacy-info h5 {
    margin-bottom: 0.5rem;
    color: var(--color-secondary);
}

.privacy-info ul {
    padding-left: 1.25rem;
}

.privacy-info li {
    margin-bottom: 0.25rem;
    color: var(--color-text-muted);
}

/* Privacy Disclaimer */
.privacy-disclaimer {
    background: rgba(245, 158, 11, 0.1);
    border: 1px solid rgba(245, 158, 11, 0.3);
    border-radius: 6px;
    padding: 1rem;
    font-size: 0.875rem;
    margin-top: 1rem;
}

.privacy-disclaimer strong {
    color: var(--color-warning);
    display: block;
    margin-bottom: 0.5rem;
}

.privacy-disclaimer ul {
    padding-left: 1.25rem;
    margin: 0;
}

.privacy-disclaimer li {
    margin-bottom: 0.25rem;
    color: var(--color-text-muted);
}

/* Note Validation */
#noteValidationResult {
    display: flex;
    align-items: center;
    gap: 0.75rem;
    padding: 0.75rem;
    background: var(--color-bg-tertiary);
    border-radius: 6px;
    margin-top: 0.5rem;
}

.validation-valid {
    color: var(--color-success);
    font-weight: 500;
}

.validation-invalid {
    color: var(--color-danger);
    font-weight: 500;
}

/* Saved Notes List */
#savedNotesList {
    max-height: 200px;
    overflow-y: auto;
}

.saved-note-item {
    display: grid;
    grid-template-columns: 1fr auto auto auto;
    gap: 0.5rem;
    align-items: center;
    padding: 0.5rem;
    background: var(--color-bg-tertiary);
    border-radius: 4px;
    margin-bottom: 0.5rem;
    font-size: 0.75rem;
}

.note-date {
    color: var(--color-text-muted);
}

.note-preview {
    font-family: var(--font-mono);
    color: var(--color-primary);
}

.note-status.used {
    color: var(--color-success);
}

.note-status.unused {
    color: var(--color-warning);
}

/* Privacy Status Indicator */
.privacy-status {
    display: inline-flex;
    align-items: center;
    gap: 0.375rem;
    padding: 0.25rem 0.625rem;
    background: var(--color-bg-tertiary);
    border-radius: 12px;
    font-size: 0.75rem;
}

.privacy-status-dot {
    width: 8px;
    height: 8px;
    border-radius: 50%;
    background: var(--color-warning);
}

.privacy-status-dot.active {
    background: var(--color-success);
}

/* Responsive */
@media (max-width: 768px) {
    .privacy-actions {
        flex-direction: column;
    }

    .privacy-actions button {
        width: 100%;
    }

    .saved-note-item {
        grid-template-columns: 1fr;
        gap: 0.25rem;
    }
}
</file>

<file path="frontend/TOR_FINALLIKA_MAPPING.md">
# Tor  Finallica Mapping Reference

This document provides a complete analogy mapping between Tor's onion router architecture and Finallica's financial privacy network.

---

## Component-Level Mapping

| **Tor Concept** | **Finallica Analogue** | **Key Similarities** | **Key Differences** |
|----------------|------------------------|---------------------|---------------------|
| **Onion Router (OR)** | **Validator-Router (VR)** |  Relay encrypted cells<br/> 3-hop paths<br/> Persistent mesh connections |  VRs stake BLF tokens<br/> VRs earn fees<br/> Economic incentives |
| **Onion Proxy (OP)** | **Finallica Proxy (FP)** |  Local client software<br/> Pathfinding engine<br/> Manages circuits/channels |  FP manages payment streams<br/> HTLC balance tracking<br/> Liquidity management |
| **Directory Authority (9)** | **Consensus Notary (8)** |  Trusted infrastructure<br/> Sign network state<br/> Distributed trust |  Notaries sign state roots<br/> HotStuff BFT consensus<br/> 10-sec finality |
| **Guard Node** | **Guard VR (Entry)** |  First hop, persistent<br/> Anti-profiling<br/> High-capacity selection |  90-day persistence<br/> Stake-weighted selection<br/> Entry only (no exit) |
| **Middle Node** | **Middle VR** |  Pure forwarding<br/> No external identity<br/> 2nd hop in path |  Identical role<br/> Same cryptography |
| **Exit Node** | **Settlement Executor (SE)** |  Bridge to external networks<br/> See plaintext metadata<br/> Policy-based routing |  SE connects to fiat rails<br/> Economic settlement<br/> 2-of-3 redundancy |
| **Circuit** | **Payment Channel** |  3-hop encrypted path<br/> Timeout-based expiry<br/> Tear-down on close |  Channels have HTLC balances<br/> 6-hour lifetime<br/> Homomorphic commitments |
| **Stream** | **Payment Stream** |  Multiplexed within circuit/channel<br/> Identified by stream_id<br/> Independent lifecycle |  Payments have amounts<br/> HTLC lock/unlock<br/> Settlement finality |
| **Cell (514 bytes)** | **Cell (1,024 bytes)** |  Fixed-size network packets<br/> Command-based routing<br/> Relay encrypted payload |  2 size for commitments<br/> BLS signatures (96 bytes)<br/> Pedersen commitments |
| **CREATE/CREATED** | **OPEN/OPENED** |  Circuit/channel initiation<br/> Diffie-Hellman handshake<br/> Key derivation |  Noise_XX (vs TAP/NTor)<br/> BLS stake binding<br/> Faster (230s vs 1.2ms) |
| **RELAY_DATA** | **PAY** |  Data-bearing cells<br/> End-to-end encrypted<br/> Stream multiplexing |  Payment amounts<br/> Pedersen commitments<br/> HTLC locking |
| **RELAY_SENDME** | **Channel Window** |  Flow control window<br/> End-to-end acknowledgments<br/> Prevent overrun |  Capacity-based ($25K)<br/> HTLC slot limits<br/> Liquidity rebalancing |
| **Padding** | **Payment Padding** |  Constant-rate traffic<br/> Obfuscates timing<br/> Dummy cells |  Monetary cost ($0.01)<br/> Dust payments<br/> 1 cell/sec minimum |
| **Consensus (none)** | **HotStuff BFT** |  N/A (Tor has no state) |  200ms finality<br/> State root commitment<br/> Global ledger |
| **Free to use** | **0.3% avg fee** |  N/A |  Economic incentives<br/> Stake required<br/> Fee revenue |

---

## Cryptographic Mapping

| **Tor Cryptography** | **Finallica Analogue** | **Purpose** | **Performance** |
|---------------------|------------------------|------------|-----------------|
| **RSA-1024** | **BLS12-381** | Identity signatures | BLS: 2ms sign, 0.15ms batch verify |
| **NTor (X25519)** | **Noise_XX (X25519)** | Handshake ECDH | Same curve, different pattern |
| **AES-128-CTR** | **ChaCha20-Poly1305** | Symmetric encryption | ChaCha20: 1.2s vs AES: 2s |
| **SHA1 (digest)** | **BLAKE2s** | Hash function | BLAKE2s: 25s vs SHA1: 10s |
| **SHA256** | **SHA256** (same) | Payment hashes | Identical |
| **Ed25519** | **Ed25519** (same) | Rekey signatures | Identical |
| **N/A** | **Pedersen Commitment** | Amount hiding | Commit: 45s |
| **N/A** | **Bulletproofs+** | Range proofs | Prove: 780s, Verify: 5ms (batch: 0.5ms) |

---

## Protocol Mapping

### Handshake Comparison

**Tor TAP (Theorem 1)**:
```
Client  Server: RSA(PK_or, g^x)
Server  Client: g^y, K = SHA1(g^xy)
```

**Tor NTor**:
```
Client  Server: g^x
Server  Client: g^y, g^xy
Client  Server: MAC(K, g^xy)
```

**Finallica Noise_XX**:
```
Client  Server: e (ephemeral X25519)
Server  Client: e, ee, s, es (BLS stake binding)
Client  Server: s, se, psk (client BLS auth)
```

### Cell Command Mapping

| Tor Command | Value | Finallica Command | Value | Purpose |
|-------------|-------|-------------------|-------|---------|
| PADDING | 0x00 | PADDING | 0x00 | Dummy cell |
| CREATE | 0x01 | OPEN | 0x01 | Initiate path |
| CREATED | 0x02 | OPENED | 0x02 | Path acknowledgment |
| RELAY | 0x03 | PAY | 0x02 | Data/payment |
| DESTROY | 0x04 | DESTROY | 0x06 | Teardown |
| RELAY_BEGIN | 0x01 | N/A | - | TCP connect (not used) |
| RELAY_DATA | 0x02 | FORWARD | 0x01 | Forward payment |
| RELAY_END | 0x03 | SETTLE | 0x03 | Settlement |
| RELAY_EXTEND | 0x06 | EXTEND | 0x04 | Extend path |
| N/A | - | REKEY | 0x05 | Rotate keys |

---

## Performance Comparison

| Metric | Tor | Finallica | Ratio |
|--------|-----|-----------|-------|
| **Network Size** | 7,000 relays | 12,000 VRs | 1.7 |
| **Circuit/Channel Build** | 200-500ms | 127-340ms | 0.63 |
| **Cell Processing** | 2ms/hop | 0.8s/hop | 0.0004 |
| **Total Throughput** | 350 Gbps | 500 Gbps | 1.4 |
| **Anonymity Set** | ~3,000 | ~1,200 | 0.4 |
| **Finality** | None (best-effort) | 200ms | N/A |
| **Cost to Use** | Free | 0.3% fee | N/A |
| **Staking Required** | No (volunteer) | Yes ($2.25M min) | N/A |
| **Settlement Time** | Instant (TCP) | 1-3 days (SWIFT) | N/A |

---

## Economic Model Comparison

| Aspect | Tor | Finallica |
|--------|-----|-----------|
| **Funding** | Donations, grants | Transaction fees |
| **Operator Incentives** | Altruism | Fee revenue |
| **Entry Cost** | $0 | $2.25M (500K BLF) |
| **Slashable** | No | Yes (up to 100%) |
| **Revenue per VR** | $0 | $2,697/epoch (avg) |
| **APY** | N/A | ~12% (guard) |
| **Inflation** | None | 4% annually |

---

## Anonymity Model Comparison

| Property | Tor | Finallica |
|----------|-----|-----------|
| **Adversary Model** | Global passive | Global passive + economic |
| **Anonymity Definition** | Probable innocence | Untraceable indistinguishability |
| |AS| Size** | ~3,000 | ~1,200 |
| **Timing Resistance** | Padding (weak) | Padding + quantization |
| **Amount Hiding** | N/A | Pedersen commitments |
| **Exit Compromise** | See plaintext | See plaintext + can censor |
| **Guard Discovery** | 1/7000 per guard | 0.31% per guard (stake-weighted) |

---

## Routing Algorithm Comparison

### Tor Path Selection

```
weight = bandwidth_fraction

where:
  bandwidth_fraction = node_bandwidth / total_bandwidth

Guard selection:
  - Persistent for 2-3 months
  - Bandwidth-weighted random
  - Exclude same /16 subnet
```

### Finallica Path Selection

```
weight = stake^0.7  uptime_factor / fee_bps^2

where:
  stake_fraction = node_stake / shard_stake
  uptime_factor = min(uptime_days / 30, 1.0)
  fee_bps = configured_routing_fee

Guard selection:
  - Persistent for 90 days
  - Stake-weighted random
  - Exclude same family (operator)
  - Higher-stake guards preferred
```

---

## Summary Table: Side-by-Side

```

 Tor                   Finallica            Difference          

 7,000 relays          12,000 VRs           1.7 larger         
 Volunteer-run         Stake-required       Economic incentives 
 RSA-1024/Ed25519      BLS12-381/Ed25519    Aggregate sigs      
 AES-128-CTR           ChaCha20-Poly1305    Different cipher    
 514-byte cells        1,024-byte cells     2 size             
 3 hops                3 hops               Same                
 No state              HTLC balances        Financial state     
 No finality           200ms finality       BFT consensus       
 Free                  0.3% fee             Paid service        
 Instant               1-3 days (SWIFT)     Settlement delay    
 ~3,000 anonymity set  ~1,200 anonymity set Smaller set         
 Directory (9)         Notaries (8)         BFT vs voting       

```

---

## Key Insight

Finallica adapts Tor's layered encryption and path diversity architecture to financial value transfer, but adds:

1. **Economic security**: Stake slashing reduces Sybil attacks
2. **Settlement finality**: BFT consensus provides irreversible transactions
3. **Amount privacy**: Pedersen commitments hide payment values
4. **Liquidity management**: Channel windows and rebalancing
5. **Regulatory compliance**: 127 shards for jurisdictional partitioning

The tradeoff: **smaller anonymity set (1,200 vs 3,000)** due to stake-weighted routing and payment timing correlation.

---

*Back to [README.md](./README.md)*
</file>

<file path="package.json">
{
  "name": "finallica-webapp",
  "version": "1.0.0",
  "description": "Finallica Documentation System with AI Chat & Blockchain Consensus",
  "scripts": {
    "dev": "concurrently \"npm run dev:frontend\" \"npm run dev:backend\"",
    "dev:frontend": "cd frontend && python -m http.server 8080",
    "dev:backend": "cd backend && node server.js",
    "install:contracts": "cd contracts && npm install",
    "deploy:contracts": "cd contracts && npx hardhat compile",
    "test": "cd backend && npm test",
    "repomix": "repomix",
    "repomix:code": "repomix --config .repomix.code.json",
    "repomix:contracts": "repomix contracts/",
    "repomix:frontend": "repomix frontend/",
    "repomix:backend": "repomix backend/"
  },
  "dependencies": {
    "express": "^4.18.2",
    "cors": "^2.8.5",
    "ws": "^8.14.2",
    "simple-git": "^3.19.1",
    "diff": "^5.1.0",
    "markdown-it": "^13.0.2",
    "axios": "^1.6.0"
  },
  "devDependencies": {
    "concurrently": "^8.2.2",
    "nodemon": "^3.0.1",
    "repomix": "^1.11.0"
  }
}
</file>

<file path="README.md">
# Finallica Documentation Webapp

A collaborative documentation system for the Finallica global financial privacy network, featuring:

- **Document Management**: View, edit, and version control all Finallica architecture docs
- **AI Chat Assistant**: Ask questions about the system and get instant answers
- **Proposal System**: Create and vote on changes using blockchain-based governance
- **Consensus Voting**: HotStuff BFT-inspired voting mechanism with stake-weighted decisions
- **Git Integration**: Automatic commits and version tracking
- **Real-time Updates**: WebSocket-powered live collaboration

## Quick Start

### Prerequisites

- Node.js 18+
- Python 3.x (for simple HTTP server)
- Git

### Installation

```bash
# Clone the repository
cd /c/Users/VIVIM.inc/finallica-webapp

# Install backend dependencies
cd backend
npm install

# Install contract dependencies (optional, for blockchain features)
cd ../contracts
npm install
```

### Running the Application

```bash
# Terminal 1: Start the backend API
cd backend
node server.js

# Terminal 2: Start the frontend
cd frontend
python -m http.server 8080

# Or install and run with a proper web server:
npx serve -l 8080
```

Then open your browser to:
- **Frontend**: http://localhost:8080
- **API**: http://localhost:3000

## Architecture

```

                         Browser                               
            
   Documents    AI Chat    Proposals   Consensus     
            

                                       
                                       

                      Frontend (app.js)                        
  - Tab navigation, Document rendering, Modal dialogs          
  - WebSocket client, Wallet connection (MetaMask)              

                              
                              

                      Backend API (server.js)                    
  - REST endpoints, Git operations, Proposal management           
  - AI chat integration, Activity tracking                         

                                             
                                             
        
   Git Repository              Smart Contracts (Solidity)
   (docs/finallica)            - FinallicaGovernance    
   - Version control             - FinallicaProposals     
   - Commits on edit            - FinallicaConsensus      
        
```

## API Endpoints

### Documents
- `GET /api/documents` - List all documents
- `GET /api/documents/:docName` - Get document content
- `PUT /api/documents/:docName` - Update document
- `GET /api/documents/:docName/history` - Get version history

### Proposals
- `GET /api/proposals` - List all proposals
- `POST /api/proposals` - Create new proposal
- `GET /api/proposals/:id` - Get proposal details

### Voting
- `POST /api/vote` - Cast vote on proposal

### Consensus
- `GET /api/consensus` - Get consensus state

### AI Chat
- `POST /api/chat` - Send chat message

### Git
- `GET /api/git/status` - Get git status
- `POST /api/git/commit` - Commit changes
- `POST /api/git/merge` - Merge approved proposal

## Smart Contracts

### FinallicaGovernanceToken (BLF)
- ERC20 token with staking functionality
- Minimum stake: 500K BLF for VR, 2M BLF for Settlement Executor
- 30-day unbonding period

### FinallicaProposals
- Create and vote on documentation changes
- 7-day voting period
- 67% quorum threshold
- Proposal types: DOCUMENT_EDIT, NEW_SECTION, PROTOCOL_CHANGE, PARAMETER_UPDATE

### FinallicaConsensus
- HotStuff BFT-inspired consensus
- 8 notary nodes
- 4-phase protocol (PREPARE  PRE-COMMIT  COMMIT  DECIDE)
- State root finalization every 10 seconds

### FinallicaDocumentRegistry
- On-chain document hash storage
- Version history tracking
- Content verification

### FinallicaStaking
- Validator-Router registration
- Stake-based slashing conditions:
  - Double-sign: 100% slash
  - Censorship: 10% slash
  - Downtime: 1% slash

## Consensus Mathematics

The voting system uses **stake-weighted quadratic voting**:

```
Weighted Vote = stake^0.7  (vote_weight / 100)

where:
  stake = user's staked BLF tokens
  vote_weight = percentage commitment (1-100)

Quorum = 67% of total staked tokens

Approval requires:
  votesFor > votesAgainst
  AND
  totalVotes  Quorum
```

### Block Time & Finality

- **Block/Epoch**: Every 10 seconds (state root publication)
- **Voting Period**: 7 days per proposal
- **Finality**: 200ms (4 RTTs  50ms)
- **Leader Rotation**: Every 8 blocks

## File Structure

```
finallica-webapp/
 frontend/
    index.html          # Main HTML
    styles.css           # Styles
    app.js               # Frontend logic
    *.md                # Documentation files
 backend/
    server.js           # Express API server
    package.json        # Backend dependencies
 contracts/
    FinallicaGovernance.sol
    FinallicaProposals.sol
    FinallicaConsensus.sol
    FinallicaDocumentRegistry.sol
    FinallicaStaking.sol
    hardhat.config.js
    package.json
 README.md               # This file
```

## Development

### Adding New Features

1. **Backend**: Add routes to `server.js`
2. **Frontend**: Modify `app.js` for UI changes
3. **Contracts**: Update Solidity files in `contracts/`
4. **Styles**: Edit `styles.css` for theming

### Git Workflow

When users propose changes:

1. User creates proposal with Git diff
2. Stakeholders vote (67% quorum required)
3. If approved, changes auto-merge via Git commit
4. State root updated on-chain
5. All clients receive update via WebSocket

## Security Considerations

- **Wallet Connection**: MetaMask or demo mode
- **Stake Requirements**: Minimum 1000 BLF to propose
- **Slashing**: Misbehaving validators lose stake
- **Rate Limiting**: Token bucket per user
- **Input Validation**: All diffs and proposals validated

## License

MIT

---

*Built for the Finallica Project - A Global Financial Privacy Network*
</file>

</files>
